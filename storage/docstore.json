{"docstore/metadata": {"2229d434-593e-479c-be51-13e40767a5bf": {"doc_hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76"}, "e2ab657e-8ac1-43f7-945b-9980a8e9ee95": {"doc_hash": "3ccbb700050d207c687b2f5c787fc41740ff215ab40d53230572ee2b0218052c"}, "6c6354d0-ff8f-40c4-aee4-4bbe56da614f": {"doc_hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3"}, "e657955d-e382-43b6-a770-a2989aba17d6": {"doc_hash": "5f8c67bc1636cb942744744d986deb7bbf69fd04c4f2acf0808914d079e8f96d", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "f470cb9c-12af-42b9-a00f-ad172f5b1fb2": {"doc_hash": "129d5cf62e4e9124100261065d41c4a989a5fc6a17cf33584458261ba8eecfb2", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "9c8b165f-ab9a-4afe-9c8b-865ae6f3b8be": {"doc_hash": "a5403cd82701da4860f1e63a134ef1cf1fe50bfb4f87de35c1a9df5eccebdc4d", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "ad315987-3f1a-4bf1-ba0b-452f06637632": {"doc_hash": "69f85ba5a67dcf822fe88b684f034dbe5d11b43a0f532b714d0e3fd7ce347a87", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "507c9155-ded2-4f44-8b53-54979f10d12e": {"doc_hash": "41d84bbc87d032aab32aa46d9ba0e473976f0f25fbe04a08cb2e8fbdfaa61b60", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "343ef3be-59a7-4954-b099-001167dc48af": {"doc_hash": "70a4e450a96356b4e6ed558a45b99e6c93bdd82ec648f45275b43066a69bee9d", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "0a3e4c0a-8853-4be7-997b-a94b5af462e8": {"doc_hash": "066c59087e8d8bf48b4274528c778757ef3b0c55f63ee5a94ac42d0f0ced4296", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "cbc6ae2d-29ff-494a-84a4-c8a8f3b1b5f8": {"doc_hash": "30841c28ec35fea4d32d570a52ebabf29025c6bf84862b6e42ca22dd77d50bf2", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "42a43ed8-4330-48df-b1b7-6697b74ec1e1": {"doc_hash": "ae43ffbba17cde3f8e3713ec1d27d08a902b6939700d2ca27ac082316c88b549", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "46f35381-9992-4633-92fb-eaee689dc4a0": {"doc_hash": "b440fd0942fa5f413151116233bca22af515cc5d4d2fd974ac42d7fb0e09f04b", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "7e0211b5-0d38-4907-b61c-c2daf80b6d3b": {"doc_hash": "9d78cd3310b6407f49743951b771411cb59dc0cca73f3da3bbceb2443be22825", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "63ad5fb8-79b0-437f-b378-0d8b9d10d1ea": {"doc_hash": "b15e21b2be52b90edde15c003d1da311fab7d074c3e94b3f4866729563f2fc6c", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "2c28ae6a-d489-47a6-b3d7-3a5fc587be1f": {"doc_hash": "daa4f0715550fd637b8bf96df50c6a3c31e70374813054fc4cd99c0bef938f49", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "58a3c753-e220-4fb1-8011-3ced243a5231": {"doc_hash": "d740280955bf07e35b2868fbc44cfc8d8f650bb81644e5f2388ba4de3267c5ef", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "2cde69d0-9b5d-4724-809b-a3dde0b87c0f": {"doc_hash": "80c5a0ba69f7e4b6c224cb47c9936a0e71755c6df3f64fe158eff2948db9e0d0", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "37d262ac-2700-4276-941b-4f4a02489f36": {"doc_hash": "2204e449fd23aa0f5aaee7a67e80928106a9d4ac80efc83a78b2ae2536c1c831", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "c0aae4eb-1537-402d-a0b6-c82722b038f5": {"doc_hash": "41793607cf2aa2419219bcf9d0f1c383cbd6eb228b2c085802be839cd7e7dcfa", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "9f063266-4aaf-4e97-b1ec-7be5f1307f01": {"doc_hash": "a97cbf15a8fd0615068f10a10c12137b1cb8e530ddbba22c4a75e21bc3d73e37", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "d4e32535-5cc8-4d3d-a87f-aba20f49bfa4": {"doc_hash": "63678cc7b03ce62d321bf39cfa228c946d50ed761607f8b5e75cf284787caedc", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "565ebbeb-d36c-47b9-a23d-1f1ff25ab89f": {"doc_hash": "0b170ba92619efefd7dd708e7f8d89681121644e47ccbce623d74b8e152caad1", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "cc28e627-2bff-4733-a2b6-ad62bff01b4a": {"doc_hash": "2d8b0628c0ba2849ecf2b1f0db27cea1210ba2546ac692f2b9bc91684d6de9f2", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "6a6c8417-944f-4929-b34b-653523fd3386": {"doc_hash": "1d3d46be58dd13232e859e2565e9fe73e99aa09d5e35094e39d2539b3d54af73", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "7dce949b-f4c3-4e48-83da-4da2558e6ac4": {"doc_hash": "9f93bd055c726fa3aa7959a486cad55ab9be942a47c0cd30336a7ea27542d08b", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "7afae2f4-a76a-4c8a-a2d4-186db18ce484": {"doc_hash": "25cc8e7e3240c43a8403595d67d3b6a99880e72c8f590d490382ba245cb7c1ee", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "e5411dac-0ace-4c41-a99e-891d51767b53": {"doc_hash": "6e33c20d029b8f7dd55260b116fa138851abd1c90554ed6f59db883875231d4e", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "9f35c193-e93d-4ed1-b44d-08ff36ddaf5d": {"doc_hash": "c1bca3ae8568000082118b2325cbb3534e7e9f45581648fa3504097e192ef36f", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "773ae079-133c-45a2-b9c6-9d9799aa8ca8": {"doc_hash": "7895d2f233342e81ee1b692f72ea0faa9c4e822e8ab29914d5ce964c451375e1", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "329712ee-34d4-40e5-9b3e-8d3ff7d3c4a5": {"doc_hash": "038002f14a77ba7f220e000bb3015312ecb5e19e46bbaff304ad9afddcfe4b55", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "356ed351-a55d-4634-9808-d78e3d9d6722": {"doc_hash": "2d3f9e4ba46b0db8108f82ea5f7a5b1f3496d18c18ea0de90290a29d702a05e3", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "c61c661f-ac4d-4b01-ac47-3b80110b890b": {"doc_hash": "03a06029dab9b28a50f800fbc18954623b943a822081779e0577855a618544e0", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "a2479684-4814-470c-9420-c20402220582": {"doc_hash": "57eb05c04fdc1c35b961ae41737bc8c7f3e4e2012d2135161cbc3c848ae203f9", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "9d451dcf-3b3d-47ac-9929-82d912828895": {"doc_hash": "aa24fce2324982e286604b8fdd69f1a348b1fdb184611819c244eb689961ca4b", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "200a6b73-4e93-4166-8e90-a9fe08eed9d5": {"doc_hash": "2f30baf7123fe38f7ff8e083d415474864bf2b7903765557c5fae0dd75689ed6", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "32a8ce53-0e3e-4f8a-85eb-90a089c13a76": {"doc_hash": "1a8dae73951173e6a4a1691dbbd38cff7b525211a2752f81b14e06aa634f2116", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "53879d22-d433-4dce-9474-137cc79d7e18": {"doc_hash": "8ecc67efec1da7ce44d7cc41d5b2f60799c4d29d12b0f3d252374acf157322e8", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "29a3d521-dc7f-488a-a8da-20de05f13d35": {"doc_hash": "7eb21aa5ec03c74f8919a57fa3f4c2e21a38ca31aa70d2474cc61e10780d2c1f", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "2a0038d3-bf63-4179-8128-4bf07fcfffdf": {"doc_hash": "71e090f22b7ba770d6b296c89283f69cb0a30db4e8eb985c77c0b21cbc0b49a8", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "cb5bdcd9-9026-436c-b5ed-231f334b54dc": {"doc_hash": "4ca7b9517577198395e13ae28169cd7ee9728b1461146b60cf957752f89a4155", "ref_doc_id": "2229d434-593e-479c-be51-13e40767a5bf"}, "4d57d10d-dec3-4319-b09e-079568c71b15": {"doc_hash": "a13722b1a709deb1533974490b4c67d1acf5200b13367c6cef4bffb6645be8ac", "ref_doc_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95"}, "9ac97102-5be5-4db4-bf81-15c660cf7a0e": {"doc_hash": "ce9bb5137bf2d1750b2569e1b8acf3da3028a9ff1f128a286f8a9e575ab499e8", "ref_doc_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95"}, "6ad8952e-6aa3-4e4d-823b-57e157185095": {"doc_hash": "19fbf8fe47b6daaf385766bc0426afceda7fa946c97dc9ac8e3cf24f789d7a96", "ref_doc_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95"}, "0a4a161c-c208-43e5-97a8-8f75231f94de": {"doc_hash": "de5eb7f677ab88f3c441befb20655789bd7a294e91e7b11325e9b062636a26bb", "ref_doc_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95"}, "654e52b6-0538-4305-b719-8f25f1b96a93": {"doc_hash": "9b600b03c8aadc6a082826abb46c99d21b298fd936a87e96883ab4569813e904", "ref_doc_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95"}, "017cf284-efa9-43f8-8efb-3438ca8ab526": {"doc_hash": "afc688d4cf8e583639e7fc074a13ccc0c1fa4803ff22fdb0d6e0af1a5b25f1a0", "ref_doc_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95"}, "7b7434ef-61f7-4853-83c9-5a42376ad2df": {"doc_hash": "fb26798bbe45c36d2063d9d5cf64ecb4bb146744879de715425ff72f72fcf1f8", "ref_doc_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95"}, "7f28a954-ea6c-4e44-b783-9c8346113e18": {"doc_hash": "9ed54d778289ffa0debd2b417db9ead65e06d44f15ce03ed845c458664d80db2", "ref_doc_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95"}, "fccfd992-163e-445e-9391-a027dbd18a04": {"doc_hash": "182506fa55a8f380c1a89287d2d31cb0d23f3361c11e1efaf80235a838c1a575", "ref_doc_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95"}, "4bce771b-8c79-4401-a0e4-5a6a8e334227": {"doc_hash": "b5d2d8699bf4a685161b3281130b1765f8fa9828a46461aa04d13fc7ef4ce106", "ref_doc_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95"}, "8bff7753-8211-4486-9469-29cc002ff212": {"doc_hash": "3b12092745146b9a77ed9058a750668ffdca894d4463040076aadd1dd3c05aa1", "ref_doc_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95"}, "da6eb826-48f7-4546-826b-d5a9e2c85d65": {"doc_hash": "74a77cbd0db77a07d19069a189e10d3e1c929def77cdbb879b0909d4b72bdc87", "ref_doc_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95"}, "225ab9dd-740d-4894-84d1-6b9dc362d3ac": {"doc_hash": "80591bc3d396ac178bc7e20f1655e6b07e292912bef0ddf198dd436e3503b78d", "ref_doc_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95"}, "7d19aff2-ace2-467e-800a-686d47ab519b": {"doc_hash": "f4332abe435f78931e517781d22a3e6b7f60f2336c164a4864505d891181400d", "ref_doc_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95"}, "d03f4b53-cdfb-420b-b0c3-67a326a87a8b": {"doc_hash": "071b7c4a591beee60bc9fbb306ac75c9ac0a09c9521689f0f4e632f3276714ad", "ref_doc_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95"}, "ec18cb2e-8f9e-4c3a-9fe1-98a404dca07f": {"doc_hash": "93911979e299c4d40ced2fb862a071f2812a5215cab7613677fd32d47efef5e3", "ref_doc_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95"}, "2b7ca07d-a1ac-4b2f-889a-cce7b1d390b3": {"doc_hash": "93c716511407eb8b8b7bae4596efb8410b10e1370c3c80f59ee7e76b90260a92", "ref_doc_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95"}, "1695f3cd-7f0c-45cf-b40e-fffeb198943d": {"doc_hash": "01273f60cb19935a9bd665e15b7e101d1f412d62777c48b91fe317a19f861c48", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "9bfb63cb-3192-435e-96d4-ed9c95aba53f": {"doc_hash": "a4f454d1e2b5269ee951e996440b66ba2be4d048a24be2477ebca6226ae3fb21", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "86b17884-16bb-46d7-92d3-094ec8dcfcc7": {"doc_hash": "4ae8386bcf72a7db67472704c7014bf2ec0de5b2fd514e46a61a77e0274e79c7", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "480cb991-6583-422d-8cd9-ba9cb55fe9a8": {"doc_hash": "fa8f78da68615ec12b79a1664181c95196b33c5b1c37da98a768406a615a98cb", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "9f916a12-0c72-426d-8ddb-487b25506219": {"doc_hash": "51d4118a51a4fe5166e9889cd68ef1c648e5902edfb5354f1524660a3f38c726", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "220c3479-912f-465d-a016-8163e001695b": {"doc_hash": "855d93e52b8f587f68c628b2961fd2902672f0f7b4d7de383fb6a1e990e7a00e", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "4b75fde5-91b7-46f0-82e6-6d369703c068": {"doc_hash": "068b4f6472edbda278d92d5dc6cf82038644876a584ba99f8c0bd184fccd20b9", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "420add2b-8a70-4fbb-b98d-d06feeb0f9b8": {"doc_hash": "37f8cf802b57f73d6bdf76632b71c0f7d91a33773cbc4f4062fedef90d38f0ab", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "0e5d4827-a298-4c37-a190-3cd6d53468a6": {"doc_hash": "aadfa6a86fdc0937fd09807e8c2c436166cca239c004df06e867db1c186ff136", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "353be917-9355-4d06-bed0-5d0955221b6c": {"doc_hash": "8162baf65f53dc9b76d1b5b240bbe1aa6b288533651dc7cd73708281a89fe332", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "e4eaa9e0-751e-455e-9690-ac6e13af67b4": {"doc_hash": "8d43eec5dc6280bd9c7d14e12f5fa35733a62e883b4a1bd29532574a07f0a26c", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "168b23cc-f5d4-4b27-b89b-5888022719c4": {"doc_hash": "a8f306bb0041155432a933a7f8e8fb6005bac69b91a365d50414b82249cf1097", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "1b9baa5e-f17a-4668-9317-d777f61eba07": {"doc_hash": "29ed64d22eccc61c969ef4860146a372f917b9a87c57fd7ecd29b203b4dce5b7", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "879028d7-6a5e-4ff5-8475-277216851565": {"doc_hash": "efdc3dd4bac95495c7bd69d531efbfb6393e754654faae977b9d7d97d0cbed80", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "c867cd2f-a109-4341-a075-173704be328b": {"doc_hash": "140e54c24a641554d2f875fad55028c7ecd06b9026542aef5417caebeeb88f44", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "e18b633f-9838-4a7b-973a-5c2a06fb1121": {"doc_hash": "64ab8acf924eedaf8d4676da69937ef5334496b95837dc5a0ecf5f479acdb1ae", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "7cb5625b-c285-4efc-83c4-59a0bd212154": {"doc_hash": "cfedbf047abcee07d51ad0bd5b26a73c3d8024c68492b12c9af2661053e1bc19", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "e51166be-9e55-4a7c-9d56-7363dbb8805f": {"doc_hash": "9bad33d3e9c0a108932f97e2ac1adb89a284540f30b8007377ec49eeb29f71bc", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "2e81daf5-96cb-474a-9bb0-946e584387ff": {"doc_hash": "fc6579dec2cc9aa5e4dc813a06e73eab05e3133c08abf0460ee42a1f0d3298ad", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "3c5f30ad-86a0-48d1-bd46-a4bd21f0a1eb": {"doc_hash": "48422daa4eef81d09b2370bb5ec00d8f0bd8642fb44d1f042e938595d6d7bd35", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "6bd9c571-702b-4b4e-bdcf-b1b6f10369d0": {"doc_hash": "fba11dab5c377b2433e542ab5a4c57003d626119e8fe3a607f851b4e69295017", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "c0417223-e681-4a65-b403-2970cfd41540": {"doc_hash": "97331dc1db18cc82058ce2eca4a404189d9c3388862037253034c535c19d0604", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "4081bba7-26db-4870-8b94-14ca780d9f39": {"doc_hash": "c671e88d394ac882ac170602c1e84880beb0307431e6f76b3eb6db0be07c521f", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "d12f10c0-f1d5-4b34-8688-c66f3d11cbf5": {"doc_hash": "ea1700d9b2b77101890af78e8f9a0b70866e3e79908355a07bc115893ed89768", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "7e8ac85d-c80b-484c-a206-d779e8e6dc07": {"doc_hash": "44a1710a45ce578f9cd249059ac227f09bec660e764f13fb09e9fc19fe7dc79d", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "9eb92c92-5e1b-45a1-9f4a-7ec310567818": {"doc_hash": "609ac17e4b73f00797b7e37050dab926ebb50d47889e2d0aefe06b4f3c7f2f9a", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "fb56e114-803e-4063-a803-a95bbaa198fa": {"doc_hash": "b7e2c865108939a2069b490c1f5b1f943c7ef83a86902c323dcb9b685762d6e0", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "b7afd206-c9cd-4137-844c-076e2a9a6b0b": {"doc_hash": "434e31aeeb856032640a042516fa9f1abf8484d02825b148ade315463e5d2317", "ref_doc_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f"}, "482c0c20-8dda-4301-b468-d3924227fe3a": {"doc_hash": "ecfd0d7ce905d6207d297ef02796c07544aa1fe70710dd96cd5f2c278331bfa6", "ref_doc_id": "doc_0"}, "b06720f1-3105-424a-99b9-e8d0ab76344a": {"doc_hash": "1fd76c800f2156fd9899a38a2bd056db25f5c90579bc5ecec31bed77ca2d88d6", "ref_doc_id": "doc_0"}, "722b2acf-3ecd-44e5-aa5c-c90727c597d2": {"doc_hash": "bc6893f1e8ca9ef0c221531a86c33bbf7ae8190ae7c3e0c89f03c30721199b0e", "ref_doc_id": "doc_0"}, "f0127283-2c54-4b9d-8462-35224105c0b4": {"doc_hash": "d3cb9c60b0c8605f488b3a8c50589b3a456f15a79573b0039a43833e4c46a8fa", "ref_doc_id": "doc_0"}, "adae4129-8643-4794-bbe6-da452a809df6": {"doc_hash": "8bf7857f36cffcba0500d3215a9d485cabaf9f79ad889f17fd20752d784c86e5", "ref_doc_id": "doc_0"}, "15bd2350-b0d8-4938-a1d1-0c8c1f870da6": {"doc_hash": "529b67be9afdd859be88be9aa989825ddd4b4c507fc5252b32de7a9e7c977008", "ref_doc_id": "doc_0"}, "678f81fc-05b3-4b72-8520-e7220d9072a7": {"doc_hash": "9571d620f46d494009839638c2ebef66c11da8fef063a404d57e282772361cf3", "ref_doc_id": "doc_0"}, "27a24b71-8d27-45f6-895b-424ab6677414": {"doc_hash": "844cb489449129c05ff969411b3b1f65dbdc388d0d21d891d6a10ccf69de483e", "ref_doc_id": "doc_0"}, "efb6ce26-bd58-4ed5-8b8f-a060af19ed32": {"doc_hash": "2a0497357531c8f21167de565d57c838522fde4343e8799dd39c52cdf079e79b", "ref_doc_id": "doc_0"}, "0550f2aa-307a-4030-919f-ee71eca47ea6": {"doc_hash": "290a1e479ccf3e784f8a5714440f18c39eebd795fe172f4171dc27523c721684", "ref_doc_id": "doc_0"}, "3870e041-1120-4781-a9d7-ee9415b27279": {"doc_hash": "a2e82b524275778566d7f33eab2f66fcd0184c50ba1973abc4f7e0f70c76bb31", "ref_doc_id": "doc_0"}, "2fb3cce2-0f85-4f27-8479-d5295ab6d602": {"doc_hash": "5bbdfdea7c83e0a610701a8276b956fba42bcb39c5862f0c9a13668dfb7f9bd1", "ref_doc_id": "doc_0"}, "8c054816-9f6f-4d49-99c6-e20eb5d9f0dc": {"doc_hash": "8d5ee6bb385e30a0f2890257e31b575e7473df6555ff533b70ef9484fa8dac0e", "ref_doc_id": "doc_0"}, "9259b7cc-24f2-4a5f-a46f-920ab240b145": {"doc_hash": "92494807cf8b2aadd65ced925fbde0932ce03dd8f62a4549c9d58d84a423bb38", "ref_doc_id": "doc_0"}, "2b114964-bbb9-46ec-8661-bd77abd649df": {"doc_hash": "67996efe4f9696a5678391bfcbda97715edd7aef2cbbb21e8e7482f62681eea8", "ref_doc_id": "doc_0"}, "b388a9bc-7500-414b-b43b-094f50d1e0af": {"doc_hash": "545e4d519c5f93ef461599c150f15ffa01fbe2eb13c036fb19092067abea0025", "ref_doc_id": "doc_0"}, "f4669fd1-425f-4bfa-89b8-59b195bea2d7": {"doc_hash": "5b9801d577f7f0006d305ec9444419cb87ff9bf050006172361a376af965c88e", "ref_doc_id": "doc_0"}, "4ef2e707-ffbb-432d-873f-7ef7eea7c719": {"doc_hash": "58ecf9a1a72b11f6e6a760705fe15e13c52b8ed874c86e03a932a9807bb6d560", "ref_doc_id": "doc_0"}, "b4ae219e-5363-4915-9710-92ed1e012a35": {"doc_hash": "ce1e7cc32037d8108a69e7615a0fc56947e104e1f742e60d37e5847e498ffc2b", "ref_doc_id": "doc_0"}, "11b0240c-3a23-41d3-b80b-2f09143a93d7": {"doc_hash": "d3a524ec0a4d24f0274652e243d3ffcab7973f81a93136194e3690b25063522d", "ref_doc_id": "doc_0"}, "0222e374-7a00-422e-b042-99c7dc877346": {"doc_hash": "80bfa31a792ebea9b1f10efb9d16f47ff79f0c4025d7710b9ab6ec7de9d55414", "ref_doc_id": "doc_0"}, "8c52318f-0801-491e-9c9e-aa194cc7cb41": {"doc_hash": "3cce64cf05a487193a72192ddc1648efb8562e641ec9f2d61e3ab810b50240aa", "ref_doc_id": "doc_0"}, "4ae261cd-e675-421b-a243-9dc092fe5600": {"doc_hash": "f31bbe4c7cba6bdc858205ed5ae288888afb8485a5e6b1cc4f16d1c396b50bd9", "ref_doc_id": "doc_0"}, "55708d71-a64a-41b8-b5d6-c6b75a8abc9f": {"doc_hash": "6dca88c143169be5ec241b3979c30774f425c496dad651c5005bc691b8e948f0", "ref_doc_id": "doc_0"}, "doc_0": {"doc_hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524"}}, "docstore/data": {"e657955d-e382-43b6-a770-a2989aba17d6": {"__data__": {"id_": "e657955d-e382-43b6-a770-a2989aba17d6", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f470cb9c-12af-42b9-a00f-ad172f5b1fb2", "node_type": "1", "metadata": {}, "hash": "fb3c61a61ebe53db67872dc1cf02b72c50fc311c20f1a07ac00fef64b06638d6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "International Review of Financial Analysis 97 (2025) 103810\r\n\r\nContents lists available at ScienceDirect\r\n\r\nInternational Review of Financial Analysis\r\n\r\njournal homepage: www.elsevier.com/locate/irfa\r\n\r\nMarket impact of the bitcoin ETF introduction on bitcoin futures\r\n\r\nYu-Lun Chen a,*, Ke Xu b, J. Jimmy Yang c\r\na Department of Finance, College of Business, Chung Yuan Christian University, Taiwan\r\nb Department of Economics, University of Victoria, Canada\r\nc School of Accounting, Finance, and Information Systems, College of Business, Oregon State University, United States\r\n\r\nA R T I C L E I N F O\r\n\r\nA B S T R A C T\r\n\r\nJEL Classification:\r\nG10\r\nG14\r\nG20\r\n\r\nKeywords:\r\nBitcoin futures\r\nProShares bitcoin strategy ETF (BITO)\r\nEfficiency\r\nLiquidity\r\n\r\n1. Introduction\r\n\r\nWe investigate the introduction effect of ProShares bitcoin strategy ETF (BITO) on investor structure and market\r\nquality in Chicago Mercantile Exchange bitcoin futures. We find that the BITO introduction significantly changes\r\nthe investor structure in bitcoin futures, with ETF asset managers being the major long-side participants against\r\nthe short-side hedge funds. Furthermore, market participants become more concentrated and the market\r\nliquidity improves in the bitcoin futures after the BITO introduction. The change in investor structure hurts\r\nfutures\u2019 price efficiency during the first three days of BITO introduction, but it then returns to the normal level.\r\nThe BITO introduction does not appear to affect long-run market efficiency and volatility of bitcoin futures.\r\n\r\nBitcoin is the first and most famous cryptocurrency. The first US\r\nbitcoin exchange-traded fund (ETF), \u201cBITO\u201d, issued by ProShares, began\r\ntrading on October 19, 2021. BITO holds bitcoin futures contracts rather\r\nthan the spot bitcoin. According to the Hajric (2021), BITO is the second-\r\nmost heavily traded fund on its debut day on record, with more than 24\r\nmillion shares changed hands. In August 2021, the Securities and Ex-\r\nchange Commission (SEC) Chairman Gary Gensler expressed a prefer-\r\nence for ETFs that hold bitcoin futures because they are traded on\r\nregulated venues such as the Chicago Mercantile Exchange (CME).1 Spot\r\nbitcoin, on the contrary, is predominantly traded on non-regulated ex-\r\nchanges and large bitcoin price dispersions exist among these exchanges\r\n(Makarov & Schoar, 2020Cong et al., 2023). However, the futures-based\r\n\r\nBITO may be subject to potentially larger tracking errors and the\r\noccurrence of the futures rolling cost.2 In addition, the introduction of\r\nBITO may affect market liquidity, volatility, and price efficiency in the\r\nunderlying bitcoin futures market, which has not been explored. We\r\nattempt to fill this gap in the literature.\r\n\r\nBitcoin market is notoriously volatile, far from being efficient, and\r\nwith high information asymmetry (Makarov & Schoar, 2020 Tini\u00e7 et al.,\r\n2022) but is still attractive to many investors. CME\u2019s bitcoin futures, a\r\nUSD cash-settled contract, gives investors exposure to bitcoin without\r\nhaving to hold spot bitcoin. In addition, bitcoin futures market provides\r\ninvestors with higher trading transparency, better price discovery, and\r\nhedging opportunities (Kapar & Olmo, 2019 Wu et al., 2021).3 If the\r\nintroduction of futures-based BITO affects market liquidity, volatility,\r\nand price efficiency in bitcoin futures, these impacts may spill over to\r\n\r\n* Corresponding author at: 200 Chung Pei Rd., Jhongli, Taoyuan 32023, Taiwan.\r\n\r\nE-mail addresses: yoloom@cycu.edu.tw (Y.-L. Chen), kexu@uvic.ca (K. Xu), Jimmy.Yang@bus.oregonstate.edu (J.J. Yang).\r\n\r\n1 The U.S. SEC has approved 11 spot bitcoin ETFs and their trading began on January 11, 2024. The SEC stated that bitcoin is primarily a speculative, volatile asset\r\nthat\u2019s also used for illicit activity including ransomware, money laundering, sanction evasion, and terrorist financing. While the SEC approved the listing and trading\r\nof certain spot bitcoin exchange-traded products, the SEC did not approve or endorse bitcoin. Spot trading in bitcoin takes place on a broad variety of largely\r\nunregulated exchanges.\r\n\r\n2 BITO needs to roll the CME bitcoin futures contract, which means BITO issuer will sell the near futures contract it holds and buy a contract with a later expiration\r\ndate, when the futures contract is nearing expiration.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4350, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f470cb9c-12af-42b9-a00f-ad172f5b1fb2": {"__data__": {"id_": "f470cb9c-12af-42b9-a00f-ad172f5b1fb2", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e657955d-e382-43b6-a770-a2989aba17d6", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "5f8c67bc1636cb942744744d986deb7bbf69fd04c4f2acf0808914d079e8f96d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9c8b165f-ab9a-4afe-9c8b-865ae6f3b8be", "node_type": "1", "metadata": {}, "hash": "372ea35f5d6312a58b82961a3d7096f5075711a3b6b134a76fb5d58b224325e4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Chen), kexu@uvic.ca (K. Xu), Jimmy.Yang@bus.oregonstate.edu (J.J. Yang).\r\n\r\n1 The U.S. SEC has approved 11 spot bitcoin ETFs and their trading began on January 11, 2024. The SEC stated that bitcoin is primarily a speculative, volatile asset\r\nthat\u2019s also used for illicit activity including ransomware, money laundering, sanction evasion, and terrorist financing. While the SEC approved the listing and trading\r\nof certain spot bitcoin exchange-traded products, the SEC did not approve or endorse bitcoin. Spot trading in bitcoin takes place on a broad variety of largely\r\nunregulated exchanges.\r\n\r\n2 BITO needs to roll the CME bitcoin futures contract, which means BITO issuer will sell the near futures contract it holds and buy a contract with a later expiration\r\ndate, when the futures contract is nearing expiration. Rolling bitcoin futures contracts will regularly incur some costs for BITO. In addition, BITO invests in bitcoin\r\nfutures and may assume the tracking errors. Thus, BITO may not fully capture the performance of spot bitcoin.\r\n\r\n3 Kapar and Olmo (2019) and Wu et al., 2021 find that bitcoin futures market dominates the spot market in the price discovery process.\r\n\r\nhttps://doi.org/10.1016/j.irfa.2024.103810\r\nReceived 27 February 2024; Received in revised form 3 November 2024; Accepted 19 November 2024\r\nAvailable online 22 November 2024\r\n1057-5219/\u00a9 2024 Elsevier Inc. All rights are reserved, including those for text and data mining, AI training, and similar technologies.\r\n\r\n\fY.-L. Chen et al.\r\n\r\nInternational Review of Financial Analysis 97 (2025) 103810\r\n\r\nthe spot bitcoin prices across exchanges and affect price integration\r\namong these exchanges.4\r\n\r\nIn this research, we investigate how the introduction of BITO affects\r\nthe market quality of bitcoin futures and the trading positions of various\r\ntypes of traders.5 While the impact of ETF introductions on market\r\nquality has been extensively studied (Park & Switzer, 1995 Ackert &\r\nTian, 1998 Switzer et al., 2000 Ackert & Tian, 2001 Kurov & Lasser,\r\n2002 Hegde & McDermott, 2004 Israeli et al., 2017 Glosten et al., 2021\r\nBox et al., 2021), these empirical investigations have primarily focused\r\non equity ETFs such as SPDRS, QQQ, and DIAMONDS. BITO, however, is\r\ndifferent because it holds futures contracts instead of spot or physical\r\nassets. The higher volatility and asymmetric information in the bitcoin\r\nmarket may lead to a unique market shock from BITO\u2019s introduction\r\ncompared to equity ETFs. This study specifically examines changes in\r\nthe investor structure, highlighting the roles of ETF asset managers and\r\nhedge funds post-BITO introduction, to provide a nuanced understand-\r\ning of its market impact.\r\n\r\nMakarov and Schoar (2020) find that order flow explains about 85 %\r\nof returns in the cryptocurrency market, compared with about 15 %\u201330\r\n% in stock or treasury markets and up to 50 % in foreign exchange\r\nmarkets. The strong relation between order flow and returns highlights\r\nthe high asymmetric information or inventory-holding cost in the\r\ncryptocurrency market. Many investors may face a lack of sufficient\r\ninformation about what bitcoin is and how it works (Zhang et al.,\r\n2023).6 In addition, the history of cryptocurrency is marked by\r\nnumerous hack attacks and thefts, and it is heavily influenced by\r\ninvestor attention and sentiment (Zhu et al., 2021). Hence, investors\r\nmay feel uncomfortable trading spot bitcoin in unregulated exchanges\r\ndirectly and turn to bitcoin ETFs in the regulated environment for se-\r\ncurity reasons. The BITO introduction may transfer the bitcoin demand\r\nof retail investors into bitcoin futures, which should be reflected on BITO\r\nasset managers\u2019 trading positions in bitcoin futures and affect the mar-\r\nket liquidity of bitcoin futures.\r\n\r\nFig. 1 plots the time-varying bitcoin futures prices and open interest.\r\nIt is noticeable that the futures prices and open interest rise substantially\r\nafter March 17, 2020 (COVID-19 pandemic and the U.S. Federal Reserve\r\nstimulus program shocks), as shown in the first dashed vertical line.7\r\nMore importantly, after the second dashed vertical line (Oct.", "mimetype": "text/plain", "start_char_idx": 3530, "end_char_idx": 7676, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9c8b165f-ab9a-4afe-9c8b-865ae6f3b8be": {"__data__": {"id_": "9c8b165f-ab9a-4afe-9c8b-865ae6f3b8be", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f470cb9c-12af-42b9-a00f-ad172f5b1fb2", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "129d5cf62e4e9124100261065d41c4a989a5fc6a17cf33584458261ba8eecfb2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ad315987-3f1a-4bf1-ba0b-452f06637632", "node_type": "1", "metadata": {}, "hash": "29197f7f53cf0422789523c630dfb72651e73e00cec4ba03b64fc4840c50b3c4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Hence, investors\r\nmay feel uncomfortable trading spot bitcoin in unregulated exchanges\r\ndirectly and turn to bitcoin ETFs in the regulated environment for se-\r\ncurity reasons. The BITO introduction may transfer the bitcoin demand\r\nof retail investors into bitcoin futures, which should be reflected on BITO\r\nasset managers\u2019 trading positions in bitcoin futures and affect the mar-\r\nket liquidity of bitcoin futures.\r\n\r\nFig. 1 plots the time-varying bitcoin futures prices and open interest.\r\nIt is noticeable that the futures prices and open interest rise substantially\r\nafter March 17, 2020 (COVID-19 pandemic and the U.S. Federal Reserve\r\nstimulus program shocks), as shown in the first dashed vertical line.7\r\nMore importantly, after the second dashed vertical line (Oct. 19, 2021,\r\nthe introduction date of BITO), the open interest spiked initially and\r\nthen gradually decreased along with the bitcoin futures price. This figure\r\nsupports that the introduction of BITO attracts more trading in the\r\n\r\n4 Makarov and Schoar (2020) point out that, in the cryptocurrency market,\r\nthere are many nonintegrated exchanges that are independently owned and\r\nexist in parallel across countries. They show the amount of price dispersion and\r\narbitrage profit between these exchanges, suggesting that the cryptocurrency\r\nmarket is far from efficient. In addition, Augustin et al. (2023) find that the\r\nintroduction of bitcoin futures is beneficial to the bitcoin spot market by\r\nmaking the underlying prices more informative.\r\n\r\n5 Market quality refers to a market\u2019s ability to meet its dual goals of liquidity\r\n\r\nand price discovery (O\u2019Hara & Ye, 2011).\r\n\r\n6 Zhang et al. (2023) find that most bitcoin participants are actually new to\r\nthe blockchain technology. Therefore, the Plus Token Ponzi scheme was able to\r\neasily fool these participants with their key white paper marketing claims.\r\n\r\n7 The U.S. Federal Reserve announced its full range of tools (LSAPs) to sup-\r\nport households, businesses, and the overall U.S. economy against the coro-\r\nnavirus pandemic on March 23, 2020. For example, the FOMC decided to\r\npurchase Treasury securities and agency mortgage-backed securities in the\r\namount needed to support smooth market functioning and effective trans-\r\nmission of monetary policy to broader financial conditions and the economy.\r\n\r\nbitcoin futures. In addition, Fig. 2 plots the time-varying bitcoin futures\r\nreturn volatility and shows that the largest volatility jump occurred on\r\nMarch 17, 2020 (the first dashed vertical line), but there are no obvious\r\nchanges in volatility after the BITO introduction. The second and third\r\nlargest jumps of futures volatility occurred in January and May of 2021.8\r\nBITO introduction does not seem to increase bitcoin futures volatility.\r\nOur research is underpinned by the market microstructure literature,\r\nwhich provides insights into how the introduction of BITO ETF may\r\ninfluence market liquidity, efficiency, and volatility (Switzer et al., 2000\r\nKurov & Lasser, 2002 Ben-David et al., 2018 O\u2019Hara, 2020). According\r\nto these studies, the introduction of an ETF can impact market partici-\r\npants and subsequently alter trading dynamics and market quality\r\nmetrics. Ben-David et al. (2018) further explore the liquidity trading\r\nhypothesis and price discovery hypothesis to illustrate the impact of ETF\r\ntrading on the prices of underlying securities. Additionally, we consider\r\ntheories of investor behavior to analyze how different types of investors,\r\nspecifically ETF asset managers and hedge funds (Chen & Yang, 2021),\r\ncontribute to changes in market structure and quality.\r\n\r\nTo explore changes in the market quality of CME bitcoin futures, we\r\nuse high-frequency trading data of bitcoin futures to measure the time-\r\nvarying liquidity, realized volatility, Hasbrouck (1993) pricing error,\r\nand variance ratio. In addition, we adopt the Traders in Financial Fu-\r\ntures (TFF) report from the U.S. Commodity Futures Trading Commis-\r\nsion (CFTC) to classify traders into five categories, including asset\r\nmanagers, dealers, leveraged funds, other reportable traders, and non-\r\nreportable traders, in the bitcoin futures market.\r\n\r\nOur analysis yields some interesting results. First, we find compelling\r\nnew evidence on the changes of trader structure in bitcoin futures after\r\nthe BITO introduction.", "mimetype": "text/plain", "start_char_idx": 6902, "end_char_idx": 11259, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ad315987-3f1a-4bf1-ba0b-452f06637632": {"__data__": {"id_": "ad315987-3f1a-4bf1-ba0b-452f06637632", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9c8b165f-ab9a-4afe-9c8b-865ae6f3b8be", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "a5403cd82701da4860f1e63a134ef1cf1fe50bfb4f87de35c1a9df5eccebdc4d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "507c9155-ded2-4f44-8b53-54979f10d12e", "node_type": "1", "metadata": {}, "hash": "5c544acc687e6f41d2031a83a47f09d5cfe245135db137f86a792b634e769bb6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "To explore changes in the market quality of CME bitcoin futures, we\r\nuse high-frequency trading data of bitcoin futures to measure the time-\r\nvarying liquidity, realized volatility, Hasbrouck (1993) pricing error,\r\nand variance ratio. In addition, we adopt the Traders in Financial Fu-\r\ntures (TFF) report from the U.S. Commodity Futures Trading Commis-\r\nsion (CFTC) to classify traders into five categories, including asset\r\nmanagers, dealers, leveraged funds, other reportable traders, and non-\r\nreportable traders, in the bitcoin futures market.\r\n\r\nOur analysis yields some interesting results. First, we find compelling\r\nnew evidence on the changes of trader structure in bitcoin futures after\r\nthe BITO introduction. Leveraged funds (i.e., hedge funds) play an\r\nimportant role in the bitcoin futures market as, before the introduction\r\nof BITO, they exhibit the highest participation rate on both long and\r\nshort sides. Especially, their trading position on the short side ranged\r\nfrom 50 %\u201380 %. After the BITO introduction, the trading position of\r\nETF asset managers on the long side increases dramatically from 8 % to\r\nabout 50 %, making them the major long-side participants against the\r\nshort-side leveraged funds. Dealers (or large banks) who serve as market\r\nmakers in the market play a rather small role in bitcoin futures, unlike\r\ntheir participation in other futures markets. We also find that the per-\r\ncentage of long positions held by the largest four (eight) traders in-\r\ncreases from 30 % to 60 % (50 % to 70 %) after the introduction of BITO,\r\nsuggesting that the bitcoin futures market becomes more concentrated\r\non fewer institutional traders. Market concentration is apparently higher\r\nin bitcoin futures than in equity index, bond, and other commodity\r\nfutures.\r\n\r\nSecond, to check whether the BITO introduction alters dynamic\r\ntrading interactions among the different types of traders in bitcoin fu-\r\ntures, we employ the Diebold and Yilmaz (2012 and 2014) method and\r\nTVP-VAR method (Antonakakis et al., 2020) to examine the trading\r\nspillovers among these traders. The results of Diebold and Yilmaz and\r\nTVP-VAR spillover methods show that leveraged funds play the major\r\ntransmitter role in trading spillover to others, while asset managers are\r\nthe major recipients. However, the BITO introduction increases the\r\nmagnitude of asset managers\u2019 trading against leveraged funds. It is\r\nplausible that the increased long positions of asset managers after the\r\nBITO introduction may entice leveraged funds to bet against them and\r\ntake more short positions in bitcoin futures.\r\n\r\nThird, for market quality, we find that market liquidity of the bitcoin\r\n\r\n8 According to CNBC news on January 29, 2021, Tesla CEO Elon Musk added\r\nthe phrase \u201c#bitcoin\u201d to his Twitter bio, alongside a cryptic tweet reading: \u201cIn\r\nretrospect, it was inevitable.\u201d In the immediate aftermath of this simple signal\r\nof Musk\u2019s attention, the valuation of bitcoin shot up 20 %. According to CNN\r\nBusiness on May 13, 2021, the price of bitcoin has nosedived after Musk said his\r\ncompany was suspending plans to accept the cryptocurrency as payment for\r\nelectric vehicles.\r\n\r\n2\r\n\r\n\fY.-L. Chen et al.\r\n\r\nInternational Review of Financial Analysis 97 (2025) 103810\r\n\r\nFig. 1. CME bitcoin futures prices and its open interest.\r\nNote: The first dashed vertical line indicates on March 17, 2020 and the second dashed vertical line indicates the introduction day of BITO (10/19/2021).\r\n\r\nFig. 2. CME bitcoin futures return volatility.\r\nNote: The first dashed vertical line indicates on March 17, 2020 and the second dashed vertical line indicates the introduction day of BITO (10/19/2021). Return\r\nvolatility is measured by the standard deviation of one-, five-, and twenty- minutes bitcoin futures return on a weekly basis.\r\n\r\nfutures improves while efficiency and volatility remain unchanged after\r\nthe BITO introduction. The improved liquidity can be a result of the\r\nBITO fund inflow from the demand of retail traders to take long positions\r\nin bitcoin futures indirectly through BITO, leading to the increased\r\ntrading positions of asset managers in bitcoin futures. Since retail traders\r\nare essentially analogous to \u201cuninformed traders\u201d, their increased\r\nparticipation in bitcoin futures through BITO may attract leveraged\r\nfunds to take advantage of their uninformed trades.", "mimetype": "text/plain", "start_char_idx": 10538, "end_char_idx": 14911, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "507c9155-ded2-4f44-8b53-54979f10d12e": {"__data__": {"id_": "507c9155-ded2-4f44-8b53-54979f10d12e", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ad315987-3f1a-4bf1-ba0b-452f06637632", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "69f85ba5a67dcf822fe88b684f034dbe5d11b43a0f532b714d0e3fd7ce347a87", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "343ef3be-59a7-4954-b099-001167dc48af", "node_type": "1", "metadata": {}, "hash": "544720bc90b8499d2f3c18df65eb1b863709b81696cf6175de803f0e0f7df71f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fig. 2. CME bitcoin futures return volatility.\r\nNote: The first dashed vertical line indicates on March 17, 2020 and the second dashed vertical line indicates the introduction day of BITO (10/19/2021). Return\r\nvolatility is measured by the standard deviation of one-, five-, and twenty- minutes bitcoin futures return on a weekly basis.\r\n\r\nfutures improves while efficiency and volatility remain unchanged after\r\nthe BITO introduction. The improved liquidity can be a result of the\r\nBITO fund inflow from the demand of retail traders to take long positions\r\nin bitcoin futures indirectly through BITO, leading to the increased\r\ntrading positions of asset managers in bitcoin futures. Since retail traders\r\nare essentially analogous to \u201cuninformed traders\u201d, their increased\r\nparticipation in bitcoin futures through BITO may attract leveraged\r\nfunds to take advantage of their uninformed trades. Baur and Smales\r\n(2022) find that leveraged funds play a key role in the bitcoin futures\r\nmarket (\u201csmart money\u201d) and display better market timing ability\r\n(\u201cinformed traders\u201d). Hence, both uninformed and informed traders\r\nmay increase their positions after the BITO introduction, enhancing the\r\n\r\nbitcoin futures market liquidity but having insignificant impact on the\r\nmarket efficiency. In addition, the BITO introduction does not increase\r\nthe volatility of bitcoin futures, which differs from the finding of Ben-\r\nDavid et al. (2018) on equity ETFs.\r\n\r\nFourth, to better understand the BITO effect, we analyze the\r\nliquidity, volatility, and price efficiency in bitcoin futures at a daily\r\nfrequency around the BITO introduction day. About $1.2 billion flowed\r\ninto BITO during its first three days on the market, according to the\r\nstatistics of ETF.com database. Thus, we focus on short-term liquidity,\r\nvolatility, informed trading, and price efficiency in bitcoin futures dur-\r\ning the five trading days before and after the BITO introduction. We find\r\nthat fund inflow of BITO enhanced the liquidity in bitcoin futures during\r\n\r\n3\r\n\r\n\fY.-L. Chen et al.\r\n\r\nInternational Review of Financial Analysis 97 (2025) 103810\r\n\r\nthe first five days. However, the BITO introduction hurts bitcoin futures\u2019\r\nprice efficiency on the first three days, but the efficiency reverts back to\r\nthe normal level soon after.\r\n\r\nWe contribute to the literature in several ways. First, we investigate\r\nthe impact of BITO introduction on investor structure in bitcoin futures.\r\nWe document the small role of dealers, the closely related trading\r\ninteraction between asset managers and leveraged funds, and the\r\nextremely high market concentration in bitcoin futures, which differ\r\nfrom other futures markets. Second, this is the first work to provide\r\nempirical evidence of the BITO introduction effect on market quality of\r\nthe underlying bitcoin futures. In addition, we also check the intro-\r\nduction of the ProShares Bitcoin Short ETF (BITI) and find insignificant\r\nimpact on market quality of bitcoin futures.9 Finally, we find that BITO\r\ntrading may affect bitcoin futures\u2019 price efficiency, but the impact is\r\nshort-lived. Makarov and Schoar (2020) argue that cryptocurrencies are\r\nstill at their early stage in the finance and economics literature. Hope-\r\nfully, our work will inspire more studies to investigate the effects of\r\nbitcoin ETFs on the bitcoin spot and derivative markets to enhance our\r\nunderstanding of cryptocurrencies.\r\n\r\nThe remainder of this paper is organized as follows. We review the\r\nprevious ETFs literature and pose the research hypotheses in Section 2\r\nand 3, followed by Section 4 of data description and trading position\r\nanalysis. We analyze the impact of BITO introduction on trading posi-\r\ntion spillover in bitcoin futures in Section 5 and market quality in Sec-\r\ntion 6. We analyze the short-term market quality around the BITO\r\nintroduction in Section 7. Finally, we present the conclusions drawn\r\nfrom this study in Section 8.\r\n\r\n2. Literature review\r\n\r\nUnderstanding the market impact of ETFs trading is crucial for aca-\r\ndemic researchers, policymakers, and investors, so a rich literature has\r\ninvestigated the effect of equity ETFs trading on index futures, index\r\noptions, and the underlying stocks (Park & Switzer, 1995 Ackert & Tian,\r\n1998 Switzer et al., 2000 Ackert & Tian, 2001 Kurov & Lasser, 2002\r\nHegde & McDermott, 2004 Israeli et al., 2017 Glosten et al., 2021 Box\r\net al., 2021).", "mimetype": "text/plain", "start_char_idx": 14017, "end_char_idx": 18432, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "343ef3be-59a7-4954-b099-001167dc48af": {"__data__": {"id_": "343ef3be-59a7-4954-b099-001167dc48af", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "507c9155-ded2-4f44-8b53-54979f10d12e", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "41d84bbc87d032aab32aa46d9ba0e473976f0f25fbe04a08cb2e8fbdfaa61b60", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0a3e4c0a-8853-4be7-997b-a94b5af462e8", "node_type": "1", "metadata": {}, "hash": "3f2bdc9f1fd28c5f6a8fe06c70cb85ae39716536145d66f333f62eecb707d65a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We analyze the short-term market quality around the BITO\r\nintroduction in Section 7. Finally, we present the conclusions drawn\r\nfrom this study in Section 8.\r\n\r\n2. Literature review\r\n\r\nUnderstanding the market impact of ETFs trading is crucial for aca-\r\ndemic researchers, policymakers, and investors, so a rich literature has\r\ninvestigated the effect of equity ETFs trading on index futures, index\r\noptions, and the underlying stocks (Park & Switzer, 1995 Ackert & Tian,\r\n1998 Switzer et al., 2000 Ackert & Tian, 2001 Kurov & Lasser, 2002\r\nHegde & McDermott, 2004 Israeli et al., 2017 Glosten et al., 2021 Box\r\net al., 2021). We separate these studies into two branches: 1) exploring\r\nthe impact of equity ETFs introduction on the underlying derivative\r\nmarket and 2) exploring the impact of equity ETFs trading on the un-\r\nderlying stocks.\r\n\r\nIn the first line of research, Park and Switzer (1995) find that the\r\nintroduction of Toronto 35 Index Participation Units (TIPs) enhances the\r\nprice efficiency of Toronto 35 index futures and Ackert and Tian (1998)\r\nfind similar result for Toronto 35 index options. Switzer et al. (2000) and\r\nChu and Hsieh (2002) find that S&P 500 index futures\u2019 pricing efficiency\r\nenhances after the introduction of Standard and Poor\u2019s Depository Re-\r\nceipts (SPDRs). Ackert and Tian (2001) also find similar result for S&P\r\n500 index options. Additionally, Kurov and Lasser (2002) find that\r\nNasdaq-100 index futures\u2019 pricing efficiency improves after the intro-\r\nduction of QQQ. These studies argue that equity ETFs allow investors to\r\ntrack the performance of stock portfolios efficiently, avoid the short-sale\r\nconstraint, and incur lower transaction cost. Therefore, equity ETFs\r\nprovide better engagement in index arbitrage with index futures or\r\noptions, leading to their improved price efficiency.\r\n\r\nIn the second line of research, researchers focus on ETFs trading and\r\ntheir underlying stocks\u2019 liquidity, volatility, and pricing efficiency.\r\nHegde and McDermott (2004) find the liquidity of the Dow Jones In-\r\ndustrial Average 30 (NASDAQ 100) index component stocks improves\r\nafter the introduction of the DIAMONDS (QQQ), largely because of a\r\n\r\n9 Nowadays, there are several bitcoin ETFs which invest Bitcoin futures\r\ncontracts and the largest assets under management (AUM) of these ETFs is BITO\r\n(about $ 1.1 billion USD), followed by BITI (about $ 70 million USD). Relatively\r\nsmaller AUM of BITI or other bitcoin ETFs may have caused their insignificant\r\nimpact on bitcoin futures.\r\n\r\n4\r\n\r\ndecline in the adverse selection cost of the underlying stocks. Israeli\r\net al. (2017) find that an increase in ETF ownership is accompanied by a\r\ndecline in pricing efficiency for the underlying stocks. Ben-David et al.\r\n(2018) argue that, due to equity ETFs\u2019 low trading costs, ETFs could\r\nattract short-horizon liquidity traders and the liquidity shocks can\r\npropagate to the underlying stocks through the arbitrage channel (i.e.,\r\nthe creation and redemption).10 Then, the arbitrage trading of ETFs may\r\nincrease the non-fundamental volatility of the underlying stocks and\r\nhave no effect on the pricing efficiency. By contrast, Glosten et al. (2021)\r\nfind the greater ETF trading is associated with improvement in short-run\r\ninformational efficiency for the underlying stocks. Box et al. (2021) find\r\nlittle support that ETFs trading transmits noise to the underlying stocks\r\nand present strong evidence that ETF prices are more likely to follow the\r\nunderlying stock returns. They find, rather than transmitting non-\r\nfundamental shocks, ETFs trading would improve the liquidity of the\r\nunderlying stocks.\r\n\r\nIn sum, these studies support that ETFs trading improves the\r\nliquidity of their underlying stocks, but the effect of ETFs trading on\r\npricing efficiency of the underlying stocks is not well settled in the\r\nliterature.", "mimetype": "text/plain", "start_char_idx": 17806, "end_char_idx": 21676, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0a3e4c0a-8853-4be7-997b-a94b5af462e8": {"__data__": {"id_": "0a3e4c0a-8853-4be7-997b-a94b5af462e8", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "343ef3be-59a7-4954-b099-001167dc48af", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "70a4e450a96356b4e6ed558a45b99e6c93bdd82ec648f45275b43066a69bee9d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cbc6ae2d-29ff-494a-84a4-c8a8f3b1b5f8", "node_type": "1", "metadata": {}, "hash": "f526a58e05e671e76cf3d0c6b27e091afeaa150f83035d61019009a82ac63995", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "By contrast, Glosten et al. (2021)\r\nfind the greater ETF trading is associated with improvement in short-run\r\ninformational efficiency for the underlying stocks. Box et al. (2021) find\r\nlittle support that ETFs trading transmits noise to the underlying stocks\r\nand present strong evidence that ETF prices are more likely to follow the\r\nunderlying stock returns. They find, rather than transmitting non-\r\nfundamental shocks, ETFs trading would improve the liquidity of the\r\nunderlying stocks.\r\n\r\nIn sum, these studies support that ETFs trading improves the\r\nliquidity of their underlying stocks, but the effect of ETFs trading on\r\npricing efficiency of the underlying stocks is not well settled in the\r\nliterature. Some argue that ETFs trading enhances pricing efficiency of\r\nthe underlying stocks (Hegde & McDermott, 2004 Glosten et al., 2021),\r\nwhile others reveal that ETFs noise trading do not improve pricing ef-\r\nficiency of the underlying stocks (Israeli et al., 2017 Ben-David et al.,\r\n2018).\r\n\r\n3. Research hypotheses\r\n\r\nBesides the equity ETFs, some studies focus on market impact of VIX\r\nindex, bond, and commodity ETFs (Zhang, 2015 Chen & Yang, 2021\r\nTodorov, 2021a). Chen and Yang (2021) find that, after the introduction\r\nof VIX exchange-traded products (ETPs), large-scale hedging activities\r\nof ETPs issuers drive the underlying VIX futures prices away from their\r\nequilibrium level. Todorov (2021a) argues that the creation and\r\nredemption mechanism, which keeps bond ETFs prices aligned with the\r\nNAV of the underlying bonds, operates differently from that of equity\r\nETFs. This difference makes it harder for arbitrageurs to exploit price\r\ngaps and impacts ETFs premium and tracking errors in stress times.\r\nZhang (2015) shows that, after the introduction of gold ETF (GLD), the\r\nliquidity of gold company stocks declined and their adverse-selection\r\nrisk increased. Da et al. (2023) find that commodity ETF arbitrage, as\r\na specific form of index trading, can inject unrelated noise into futures\r\nprices and diminish price efficiency.\r\n\r\nThe VIX, bond, and commodity ETFs have some different properties\r\nthan equity ETFs (i.e., SPDRs, QQQ, and DIAMONDS). (1) It may be\r\ndifficult to execute the creation and redemption arbitrage for some of\r\nthose ETFs, so they need an arbitrage mechanism to keep their share\r\nprices aligned with the NAV, especially in the stress times. Hence, some\r\nprevious studies focus on the ETFs premium/discount or tracking error.\r\n(2) Some of the underlying spot assets are difficult to be stored (i.e.,\r\nenergy commodities) or traded (i.e., VIX), so those ETFs issuers would\r\nuse the related futures contracts to track the performance of these un-\r\nderlying assets. Since those trading of ETFs issuers may directly affect\r\nthe market quality in the related futures, the shock of those ETFs would\r\nbe different from the market impact of equity ETFs (Park & Switzer,\r\n1995 Ackert & Tian, 1998 Switzer et al., 2000 Ackert & Tian, 2001\r\nKurov & Lasser, 2002).\r\n\r\n10 ETFs are traded in the secondary market but ETF shares can be created and\r\nredeemed in the primary market. When the secondary market price of ETF\r\ndiverges from the value of the underlying securities (i.e., net asset value, NAV),\r\narbitrageurs can create new ETF shares by buying the underlying securities of\r\nthe ETF and transferring them to the ETF sponsor. Similarly, arbitrageurs can\r\nredeem ETF shares and receive the underlying securities of the ETF. Through\r\nthe creation and redemption, the secondary market price of ETF would move\r\nclose to the NAV of ETF.\r\n\r\n\fY.-L. Chen et al.\r\n\r\nInternational Review of Financial Analysis 97 (2025) 103810\r\n\r\nBITO clearly belongs to the futures-based ETF category, so its\r\nstructure is also different from equity ETFs. Essentially, BITO framework\r\nis similar to that of commodity or VIX ETFs (Todorov, 2021b). There-\r\nfore, we first hypothesize that the trading of futures-based BITO would\r\nimpact market liquidity, volatility, and pricing efficiency in the under-\r\nlying bitcoin futures.", "mimetype": "text/plain", "start_char_idx": 20963, "end_char_idx": 25004, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cbc6ae2d-29ff-494a-84a4-c8a8f3b1b5f8": {"__data__": {"id_": "cbc6ae2d-29ff-494a-84a4-c8a8f3b1b5f8", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0a3e4c0a-8853-4be7-997b-a94b5af462e8", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "066c59087e8d8bf48b4274528c778757ef3b0c55f63ee5a94ac42d0f0ced4296", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "42a43ed8-4330-48df-b1b7-6697b74ec1e1", "node_type": "1", "metadata": {}, "hash": "a0d24bbf6119c4740d5dcf0640c755bbf3969ed406431d474383415fec3f0376", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Similarly, arbitrageurs can\r\nredeem ETF shares and receive the underlying securities of the ETF. Through\r\nthe creation and redemption, the secondary market price of ETF would move\r\nclose to the NAV of ETF.\r\n\r\n\fY.-L. Chen et al.\r\n\r\nInternational Review of Financial Analysis 97 (2025) 103810\r\n\r\nBITO clearly belongs to the futures-based ETF category, so its\r\nstructure is also different from equity ETFs. Essentially, BITO framework\r\nis similar to that of commodity or VIX ETFs (Todorov, 2021b). There-\r\nfore, we first hypothesize that the trading of futures-based BITO would\r\nimpact market liquidity, volatility, and pricing efficiency in the under-\r\nlying bitcoin futures. Additionally, the fund inflow of BITO may corre-\r\nspond to positions held by ETF asset managers in bitcoin futures.\r\nSubsequently, other institutional investors would interact with ETF asset\r\nmanagers\u2019 positions and engage in trading in the bitcoin futures. Thus,\r\nour second hypothesis posits that the introduction of BITO would in-\r\nfluence trading transmissions among major types of traders in the bit-\r\ncoin futures. Investigating the impact of BITO introduction on the\r\ninvestor structure and market quality of bitcoin futures will provide new\r\ninsights in the literature on ETFs and cryptocurrencies.11\r\n\r\n4. Data and trading position analysis\r\n\r\nWe illustrate the CME bitcoin futures data, the TFF report, descrip-\r\ntive statistics of these data, and trading position analysis in this section.\r\n\r\n4.1. CME bitcoin futures data\r\n\r\nWe collect the intra-day trading data of CME bitcoin futures from\r\nTick Data, Inc. for the period of January 1, 2018 to October 31, 2022.\r\nAlthough both the Chicago Board Options Exchange (CBOE) and CME\r\nlaunched Bitcoin futures in December 2017, Hung et al. (2021) find that\r\nCME\u2019s bitcoin futures exhibit superior price discovery than CBOE\u2019s.\r\nSince the CBOE delisted all the bitcoin future derivatives from its futures\r\nmarket in June 2019, we only focus on CME bitcoin futures (ticker\r\nsymbol BTC), which is a USD cash-settled contract based on the CME CF\r\nBitcoin Reference Rate (BRR) that serves as a once-a-day reference rate\r\nof the U.S. dollar price of bitcoin. We provide detailed contract speci-\r\nfications for the CME bitcoin futures in Appendix A. For our empirical\r\nanalyses, we use the prices of the most actively traded nearest-to-\r\nmaturity futures contracts.\r\n\r\nTo analyze the market quality of bitcoin futures, we focus on three\r\ndifferent aspects: (1) liquidity, (2) volatility, and (3) price efficiency. We\r\nemploy various methods to measure these aspects, utilizing different\r\nfrequencies of intra-day bitcoin futures data. Specifically, we use one-\r\nminute, five-minute, and twenty-minute bitcoin futures returns over a\r\nweek to calculate realized variances. This approach follows Andersen\r\net al. (2001) and Andersen et al. (2003), who use five-minute returns to\r\ncompute weekly realized volatility. For the pricing error measurement\r\n(Hasbrouck, 1993), we use one-minute bitcoin futures returns over a\r\nweek, following Chen and Xu (2021). We analyze variance ratios by\r\nadopting one-minute, five-minute, twenty-minute, and one-hour bitcoin\r\n\r\n11 Our paper differs from the existing literature in several crucial ways: (1)\r\nAsset Class and Instrument Focus: While much of the existing research focuses\r\non equity ETFs and their impact on traditional financial instruments such as\r\nindex futures and options, our study is among the first to examine a bitcoin\r\nfutures ETF and its effect on the underlying bitcoin futures market. This pro-\r\nvides novel insights into the rapidly evolving cryptocurrency markets. (2)\r\nInvestor Structure Analysis: Our study delves deeply into the changes in the\r\ninvestor structure, specifically highlighting the roles of ETF asset managers and\r\nhedge funds. This detailed analysis of market participants provides a nuanced\r\nunderstanding of how the introduction of a bitcoin futures ETF reshapes the\r\nmarket landscape. (3) Short-term vs. Long-term Effects: We differentiate be-\r\ntween the short-term disruption in price efficiency observed in the first three\r\ndays post-BITO introduction and the long-term effects, where the market effi-\r\nciency and volatility return to normal levels. This temporal analysis offers a\r\nmore comprehensive view of the ETF\u2019s impact, which is often not addressed in\r\nthe equity ETF literature.", "mimetype": "text/plain", "start_char_idx": 24331, "end_char_idx": 28720, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "42a43ed8-4330-48df-b1b7-6697b74ec1e1": {"__data__": {"id_": "42a43ed8-4330-48df-b1b7-6697b74ec1e1", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cbc6ae2d-29ff-494a-84a4-c8a8f3b1b5f8", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "30841c28ec35fea4d32d570a52ebabf29025c6bf84862b6e42ca22dd77d50bf2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "46f35381-9992-4633-92fb-eaee689dc4a0", "node_type": "1", "metadata": {}, "hash": "829979a3b9399e599fb05676a9b5585e41698cb4b7656d03b3857e8bf116796a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This pro-\r\nvides novel insights into the rapidly evolving cryptocurrency markets. (2)\r\nInvestor Structure Analysis: Our study delves deeply into the changes in the\r\ninvestor structure, specifically highlighting the roles of ETF asset managers and\r\nhedge funds. This detailed analysis of market participants provides a nuanced\r\nunderstanding of how the introduction of a bitcoin futures ETF reshapes the\r\nmarket landscape. (3) Short-term vs. Long-term Effects: We differentiate be-\r\ntween the short-term disruption in price efficiency observed in the first three\r\ndays post-BITO introduction and the long-term effects, where the market effi-\r\nciency and volatility return to normal levels. This temporal analysis offers a\r\nmore comprehensive view of the ETF\u2019s impact, which is often not addressed in\r\nthe equity ETF literature. (4) Specific Market Dynamics: Our findings highlight\r\nthe concentration of market participants and the implications for market\r\nquality and liquidity, providing unique insights into how these dynamics play\r\nout in the context of bitcoin futures.\r\n\r\nfutures price data, in line with Boehmer and Kelley (2009). The choice of\r\nfrequency is determined by the need to capture short-term market dy-\r\nnamics and effectively avoid microstructure noise in bitcoin futures\r\nprices, as supported by related previous studies.\r\n\r\n4.2. Traders in financial futures (TFF) report and trading positions\r\n\r\nThe CFTC publishes weekly TFF reports to add transparency to the\r\nfinancial futures markets, in addition to the legacy \u2018Commitments of\r\nTraders\u2019 (COT) report. The TFF reports of bitcoin futures are available\r\ngoing back to April 10, 2018, so we focus on the sample period from\r\nApril 10, 2018 to October 31, 2022 in this study. The TFF report clas-\r\nsifies large traders in the bitcoin futures into four reportable categories,\r\nincluding (1) asset managers/institutional\r\ntraders, (2) dealers/in-\r\ntermediaries, (3) leveraged funds, and (4) other- reportable traders.\r\nLarge traders in all four categories of the TFF report may be drawn from\r\neither the commercial or non-commercial categories of traders in the\r\ntraditional COT report.\r\n\r\nTFF reports provide a breakdown of open interest positions held by\r\ntraders on each Tuesday for futures markets. According to the explan-\r\natory notes on the TFF reports (obtained from the CFTC website), all\r\nfinancial futures market participants are divided into sell and buy sides,\r\nwith the category entitled \u201cdealers\u201d representing sell-side participants.\r\nTypically, these market participants are dealers and intermediaries\r\nearning commission on the sale of financial products, capturing bid/\r\noffer spreads and accommodating the needs of their clients. This cate-\r\ngory includes large banks (U.S. and non-U.S.) as well as dealers in se-\r\ncurities, swaps and other derivatives.\r\n\r\nThe three remaining categories represent buy-side participants. All\r\nof them are essentially the clients of the sell-side participants and use the\r\nfutures contracts to invest, hedge, or speculate. \u201cAsset managers\u201d\r\ninclude ETFs asset managers, insurance firms, mutual fund managers,\r\nand all portfolio/investment managers whose clients are predominantly\r\ninstitutional investors. \u201cLeveraged funds\u201d typically comprise hedge\r\nfunds and various types of money managers, including registered com-\r\nmodity trading advisors, registered commodity pool operators, and\r\nunregistered fund managers identified by the CFTC. The strategies\r\nadopted by these traders may involve taking outright positions or\r\narbitrage within and across markets. They may also be engaged in\r\nmanaging and conducting proprietary futures trading and trading on\r\nbehalf of speculative clients. Any traders who do not belong to one of the\r\nabove categories fall into the category of \u201cother reportable traders\u201d,\r\nincluding corporate treasuries, central banks, smaller banks, mortgage\r\noriginators, credit unions, and any other reportable traders not assigned\r\nto the other three categories.\r\n\r\nThe TFF reports disclose open interest positions, both long and short,\r\nof these four categories of traders and non-reportable traders. In addi-\r\ntion, it discloses the concentration ratio of reportable long and short\r\npositions for the largest four and eight traders\u2019 open interests. We\r\nconstruct two trading position measures for these categories of traders to\r\nproxy their trading activities: (1) Percentage trading positions (PTPi\r\nt)\r\nt) held by type i, where i = AS, DE, LE,\r\nand (2) Net trading positions (NTPi\r\nOT, and NO, which respectively refer to asset managers, dealers,\r\nleveraged funds, other-reportable traders, and non-reportable traders.", "mimetype": "text/plain", "start_char_idx": 27894, "end_char_idx": 32551, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "46f35381-9992-4633-92fb-eaee689dc4a0": {"__data__": {"id_": "46f35381-9992-4633-92fb-eaee689dc4a0", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "42a43ed8-4330-48df-b1b7-6697b74ec1e1", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "ae43ffbba17cde3f8e3713ec1d27d08a902b6939700d2ca27ac082316c88b549", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7e0211b5-0d38-4907-b61c-c2daf80b6d3b", "node_type": "1", "metadata": {}, "hash": "435cc7b27e1ee72cd9fe848037fe73e7101ebd678de270884fbe7e15d9678057", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The TFF reports disclose open interest positions, both long and short,\r\nof these four categories of traders and non-reportable traders. In addi-\r\ntion, it discloses the concentration ratio of reportable long and short\r\npositions for the largest four and eight traders\u2019 open interests. We\r\nconstruct two trading position measures for these categories of traders to\r\nproxy their trading activities: (1) Percentage trading positions (PTPi\r\nt)\r\nt) held by type i, where i = AS, DE, LE,\r\nand (2) Net trading positions (NTPi\r\nOT, and NO, which respectively refer to asset managers, dealers,\r\nleveraged funds, other-reportable traders, and non-reportable traders.\r\nBoth measures are defined as follows:\r\n\r\nPTPi\r\nt\r\n\r\n=\r\n\r\n(\r\nLongi\r\nt\r\n\r\n+ Shorti\r\nt\r\n\r\n+ 2 \u2022 Spreadingi\r\nt\r\n\r\nMTOIt\r\n\r\n)/\r\n\r\nNTPi\r\nt\r\n\r\n= Longi\r\nt\r\n\r\n(cid:0) Shorti\r\nt\r\n\r\n,\r\n\r\n(1)\r\n\r\n(2)\r\n\r\nt and Shorti\r\n\r\nwhere Longi\r\nt refer to the long and short positions held by type i\r\ntraders on t. MTOIt is the market\u2019s total open interest. Spreadingi\r\nt mea-\r\nsures the extent to which type i traders hold equal long and short futures\r\npositions. PTPi\r\nt measures the participation ratio of type i traders in the\r\nwhole market, regardless of their standing on long- or short- sides, while\r\n\r\n5\r\n\r\n\fY.-L. Chen et al.\r\n\r\nInternational Review of Financial Analysis 97 (2025) 103810\r\n\r\nNTPi\r\n\r\nt measures the net long trading position of the type i traders.\r\n\r\n4.3. Trading position analysis before and after BITO introduction\r\n\r\nTo analyze whether the trader positions in bitcoin futures are\r\naffected by the BITO introduction, we plot the long and short trading\r\nposition percentage of different types of traders against the total position\r\nin Fig. 3. Leveraged funds have the highest participation proportion on\r\nboth long and short sides (i.e., dark red line), with their percentages on\r\nthe short side ranging from 50 % to 80 %. In Fig. 3.1, after the intro-\r\nduction of BITO (i.e., the dashed vertical line), the trading percentage of\r\nasset manager on the long side increases dramatically from 8 % to about\r\n50 % (i.e., dark blue line). In Fig. 3.2, after the introduction of BITO, the\r\ntrading percentages of all traders on the short side do not seem to exhibit\r\nnoticeable changes. Fig. 3 shows that asset managers become the major\r\nlong-side participants against the short-side leveraged funds after the\r\nBITO introduction.\r\n\r\nThen, we plot percentages of long and short open interest held by the\r\nlargest four and eight traders against total open interest (market con-\r\ncentration) in Fig. 4. We find the blue line in Fig. 4.1 rises significantly\r\nafter the dashed vertical line, showing that the percentage of long po-\r\nsitions held by the largest four traders increases from 30 % to 60 %\r\nacross the BITO introduction. For the red line, we find the percentage of\r\nshort positions held by the largest four traders decreases slightly. In\r\nFig. 4.2, for the percentages of long and short open interest held by the\r\nlargest eight traders, we find a similar pattern to Fig. 4.1. Overall, Fig. 4\r\nshows that the bitcoin futures market becomes more concentrated on the\r\nlong side after the introduction of BITO. The market concentration of\r\nbitcoin futures is apparently higher than those in equity index, bond,\r\nand commodity futures.\r\n\r\nTo check whether the increased trading percentage of asset managers\r\non the long side comes from the BITO trading and induces high market\r\nconcentration of largest four traders, we plot the net-long position of\r\nasset managers (i.e., the blue line), the market concentration of the\r\nlargest four traders (i.e., the green line), and the accumulated fund flow\r\nof BITO (i.e., the red line) in Fig. 5. Major fund inflow of BITO con-\r\ncentrates on the first three days of BITO introduction and then gradually\r\nincreases to a stable level. These variable series all jump on the BITO\r\nintroduction day and co-move together.", "mimetype": "text/plain", "start_char_idx": 31895, "end_char_idx": 35803, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7e0211b5-0d38-4907-b61c-c2daf80b6d3b": {"__data__": {"id_": "7e0211b5-0d38-4907-b61c-c2daf80b6d3b", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "46f35381-9992-4633-92fb-eaee689dc4a0", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "b440fd0942fa5f413151116233bca22af515cc5d4d2fd974ac42d7fb0e09f04b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "63ad5fb8-79b0-437f-b378-0d8b9d10d1ea", "node_type": "1", "metadata": {}, "hash": "9ea1d154258c3b7270283f086a7d3aab45660d6dc6184f3eff42f36dc95021d9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4.1. Overall, Fig. 4\r\nshows that the bitcoin futures market becomes more concentrated on the\r\nlong side after the introduction of BITO. The market concentration of\r\nbitcoin futures is apparently higher than those in equity index, bond,\r\nand commodity futures.\r\n\r\nTo check whether the increased trading percentage of asset managers\r\non the long side comes from the BITO trading and induces high market\r\nconcentration of largest four traders, we plot the net-long position of\r\nasset managers (i.e., the blue line), the market concentration of the\r\nlargest four traders (i.e., the green line), and the accumulated fund flow\r\nof BITO (i.e., the red line) in Fig. 5. Major fund inflow of BITO con-\r\ncentrates on the first three days of BITO introduction and then gradually\r\nincreases to a stable level. These variable series all jump on the BITO\r\nintroduction day and co-move together. In addition, we find that the\r\npairwise correlation coefficient between the net-long position of asset\r\nmanagers (the market concentration of the largest four traders on long\r\npositions) and the accumulated fund flow of BITO is about 0.80 (0.85).\r\nThese findings in Fig. 5 confirm that fund inflow of BITO increases the\r\nlong position of asset managers and market concentration in bitcoin\r\nfutures.\r\n\r\nIn Table 1, we present the summary statistics of bitcoin futures re-\r\nturn, percentage trading positions (PTPi\r\nt), and net trading positions\r\n(NTPi\r\nt) for the entire sample period (Panel A) and the two sub-periods\r\nseparated by the BITO introduction (before in Panel B and after in\r\nPanel C). We also test the hypotheses on the equality of bitcoin futures\r\nreturn, PTPi\r\nt in the two sub-periods and present results in\r\nPanel D.\r\n\r\nt, and NTPi\r\n\r\nPanel A of Table 1 shows that leveraged funds take more positions in\r\nbitcoin futures than others, with an average trading percentage of about\r\n55.1 %. Leveraged funds are major net-short traders, whereas asset\r\nmanagers and non-reportable traders hold net-long positions. In Panels\r\nB and C of Table 1, we find that on average, the trading percentage of\r\nasset managers increases from 4.28 % to 28.12 % and their net-long\r\nposition increases from 53.7 to 5032.4, a level near the net-short posi-\r\ntion of leveraged funds. This result implies that the increased long po-\r\nsitions of asset managers after the BITO introduction are mostly matched\r\nby the increased short positions of leveraged funds from (cid:0) 1643.6 to\r\n(cid:0) 5334.3. That is, when asset managers increase their positions in bit-\r\ncoin futures because of BITO, leveraged funds stand to take the opposite\r\nside of the transactions.\r\n\r\nOn the contrary, the trading percentage of non-reportable traders\r\ndecreases from 19.34 % to 9.05 % and their long position also drops\r\nfrom 1262.4 to 479 after the BITO introduction. This finding supports\r\nthe conjecture that some retail traders may reduce their trading in bit-\r\ncoin futures and turn to BITO for their bitcoin exposure without the need\r\nto deal with the contract expiration issue in futures. Lastly, in Panel D of\r\nTable 1, we find that bitcoin futures return, PTPi\r\nt all exhibit\r\nsignificant changes after the BITO introduction. These results suggest\r\nthat the BITO introduction alters trader positions and investor structure\r\nin bitcoin futures.\r\n\r\nt, and NTPi\r\n\r\n5. Analysis of trading position spillover in CME bitcoin futures\r\n\r\nTo further understand the intertemporal trading interactions among\r\ndifferent types of traders in bitcoin futures, especially from the BITO\r\nshock, we use the spillover measure of Diebold and Yilmaz (2012 and\r\n2014) and of TVP-VAR methodology (Antonakakis et al., 2020) to\r\nexamine the trading spillovers among these traders. The Diebold and\r\nYilmaz (2012 and 2014) measurement is well established for examining\r\nreturn or volatility spillover transmissions or network connectedness in\r\nvarious financial markets. For instance, Ji et al. (2019) adopt the same\r\nmeasure to analyze trading position spillover transmissions in futures\r\nmarkets.", "mimetype": "text/plain", "start_char_idx": 34923, "end_char_idx": 38954, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "63ad5fb8-79b0-437f-b378-0d8b9d10d1ea": {"__data__": {"id_": "63ad5fb8-79b0-437f-b378-0d8b9d10d1ea", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7e0211b5-0d38-4907-b61c-c2daf80b6d3b", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "9d78cd3310b6407f49743951b771411cb59dc0cca73f3da3bbceb2443be22825", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2c28ae6a-d489-47a6-b3d7-3a5fc587be1f", "node_type": "1", "metadata": {}, "hash": "9352d4e2c1b108c8ea97e90362b6db6918242e7c41f2d7a355cdf10458336619", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "These results suggest\r\nthat the BITO introduction alters trader positions and investor structure\r\nin bitcoin futures.\r\n\r\nt, and NTPi\r\n\r\n5. Analysis of trading position spillover in CME bitcoin futures\r\n\r\nTo further understand the intertemporal trading interactions among\r\ndifferent types of traders in bitcoin futures, especially from the BITO\r\nshock, we use the spillover measure of Diebold and Yilmaz (2012 and\r\n2014) and of TVP-VAR methodology (Antonakakis et al., 2020) to\r\nexamine the trading spillovers among these traders. The Diebold and\r\nYilmaz (2012 and 2014) measurement is well established for examining\r\nreturn or volatility spillover transmissions or network connectedness in\r\nvarious financial markets. For instance, Ji et al. (2019) adopt the same\r\nmeasure to analyze trading position spillover transmissions in futures\r\nmarkets. Likewise, we employ the vector autoregression (VAR) model\r\nt), where i = AS, DE, LE,\r\nfor the changes in net trading positions (\u0394NTPi\r\nOT, and NO, which respectively refer to asset managers, dealers,\r\nleveraged funds, other-reportable traders, and non-reportable traders.12\r\nHowever, rolling-window VAR-based dynamic spillover measures is\r\nsensitive to the window size choices, besides the initial loss of obser-\r\nvations equal to the window size. Antonakakis et al. (2020), point out\r\nthat the advantages of the TVP-VAR spillover model include: (1) no need\r\nto arbitrarily set the rolling-window size, (2) no loss of observations, and\r\n(3) no outlier sensitivity. Hence, we consider both TVP-VAR-based and\r\nrolling-window VAR-based dynamic spillover measures in this study.\r\n\r\nHere, we illustrate the TVP-VAR(p) model and estimate a TVP-VAR\r\nmodel with one lag (p = 1) as suggested by the Bayesian information\r\ncriterion (BIC) as follows:\r\n\r\nYt = \u03b2tYt(cid:0) 1 + \u03b5t, where \u03b5t \u223c\r\n\r\n(cid:0)\r\n\r\n)\r\n\r\n0, \u03a31,t\r\n\r\nvec(\u03b2t\r\n\r\n) = vec(\u03b2t(cid:0) 1\r\n\r\n) + vt, where vt \u223c\r\n\r\n(cid:0)\r\n\r\n)\r\n\r\n0, \u03a32,t\r\n\r\n(3)\r\n\r\n(4)\r\n\r\nwhere Yt represents a m \u00d7 1 net trading positions changes (\u0394NTPt)\r\nvector, \u03b2t is a m \u00d7 m dimensional coefficient matrix and \u03b5t is a m \u00d7 1\r\ndimensional error disturbance vector with a m \u00d7 m variance-covariance\r\nmatrix, \u03a31,t. vec(\u03b2t\r\n) and vt denote m2 \u00d7 1 dimensional vectors. Moreover,\r\n\u03a32,t. is a m2 \u00d7 m2 variance-covariance matrix.\r\n\r\nIn order to calculate the generalized impulse response functions\r\n(GIRF) and generalized forecast error variance decompositions\r\n(GFEVD), we transform the TVP-VAR to its vector moving average\r\n(VMA) representation based on the Wold representation theorem, ac-\r\ncording to Antonakakis et al. (2020). VMA is as follows:\r\n\r\nYt =\r\n\r\n\u2211\u221e\r\n\r\nj=0\r\n\r\nBjt\u03b5t(cid:0) j,\r\n\r\n(5)\r\n\r\nwhere Bjt is an m \u00d7 m dimensional matrix. The (scaled) GFEVD nor-\r\nmalizes the (unscaled) \u03c6g\r\n(H), in order that each row sums up to uni-\r\n\u2148j,t\r\nty. \u0303\u03c6g\r\n(H) represents the pairwise directional connectedness from j to i\r\nij,t\r\nand illustrates the influence variable j has on variable i in terms of its\r\nforecast error variance share. These variance shares are then\r\n\r\n12 Due to the space constraint, please refer to the studies by Diebold and\r\nYilmaz (2012 and 2014) for a detailed explanation of this method and the\r\nrelated measures.\r\n\r\n6\r\n\r\n\fY.-L. Chen et al.\r\n\r\nInternational Review of Financial Analysis 97 (2025) 103810\r\n\r\nFig. 3. Time-varying percent of different traders\u2019 open interest against the total open interest.\r\nNote: The dashed vertical line indicates the introduction day of BITO (10/19/2021).\r\n\r\nnormalized, so that each row sums up to one, meaning that all variables\r\ntogether explain 100 % of variable i\u2019s forecast error variance.", "mimetype": "text/plain", "start_char_idx": 38109, "end_char_idx": 41716, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2c28ae6a-d489-47a6-b3d7-3a5fc587be1f": {"__data__": {"id_": "2c28ae6a-d489-47a6-b3d7-3a5fc587be1f", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "63ad5fb8-79b0-437f-b378-0d8b9d10d1ea", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "b15e21b2be52b90edde15c003d1da311fab7d074c3e94b3f4866729563f2fc6c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "58a3c753-e220-4fb1-8011-3ced243a5231", "node_type": "1", "metadata": {}, "hash": "d366d78dbbab19bc7c44a0b190303413582c9a38ccd38d0471004d3f3184fa68", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\u0303\u03c6g\r\n(H) represents the pairwise directional connectedness from j to i\r\nij,t\r\nand illustrates the influence variable j has on variable i in terms of its\r\nforecast error variance share. These variance shares are then\r\n\r\n12 Due to the space constraint, please refer to the studies by Diebold and\r\nYilmaz (2012 and 2014) for a detailed explanation of this method and the\r\nrelated measures.\r\n\r\n6\r\n\r\n\fY.-L. Chen et al.\r\n\r\nInternational Review of Financial Analysis 97 (2025) 103810\r\n\r\nFig. 3. Time-varying percent of different traders\u2019 open interest against the total open interest.\r\nNote: The dashed vertical line indicates the introduction day of BITO (10/19/2021).\r\n\r\nnormalized, so that each row sums up to one, meaning that all variables\r\ntogether explain 100 % of variable i\u2019s forecast error variance. This is\r\ncalculated as follows:\r\n\r\nH stands for the forecast horizon.\r\n\r\nBased on the GFEVD, Diebold & Yilmaz, 2012, Diebold & Yilmaz,\r\n2014), and Antonakakis et al. (2020), we can construct the total trading\r\nspillover (TS) index of all trading positions as follows:\r\n\r\n\u03c6g\r\n\u2148j,t\r\n\r\n(H) =\r\n\r\n\u2211H(cid:0) 1\r\n\r\n(cid:0)\r\n\r\n\u03c3(cid:0) 1\r\njj,t\r\n\r\nt=1\r\n(cid:0)\r\n\u2211H(cid:0) 1\r\n\r\n\u2211m\r\n\r\nj=1\r\n\r\nt=1\r\n\r\n)\r\n\r\n2\r\n\r\n\u02b9\r\niBt\u03a31,tej\r\ne\r\n\r\n\u02b9\r\n\u02b9\r\niBt\u03a31,tB\r\ne\r\ntei\r\n\r\n, \u0303\u03c6g\r\nij,t\r\n)\r\n\r\n(H) =\r\n\r\n(H)\r\n\r\n\u03c6g\r\nij,t\r\n\u2211m\r\n\r\n\u03c6g\r\nij,t\r\n\r\n(H)\r\n\r\nj=1\r\n\r\n\u0303\u03c6g\r\nij\r\n\r\n(H) =\r\n\r\n\u03c6g\r\nij\r\n\u2211N\r\n\r\n(H)\r\n\r\n.\r\n(H)\r\n\r\n\u03c6g\r\nij\r\n\r\nj=1\r\n\r\n(6)\r\n\r\nTSt(H) =\r\n\r\n\u2211m\r\n\r\ni,j=1\r\n\r\ni\u2215=j\r\n\u2211m\r\n\r\ni,j=1\r\n\r\n\u0303\u03c6g\r\nij\r\n\r\n(H)\r\n\r\n\u2022 100.\r\n\r\n\u0303\u03c6g\r\nij\r\n\r\n(H)\r\n\r\n(7)\r\n\r\n\u2211\r\n\r\n\u2211\r\n\r\nm\r\nj=1\r\n\r\n\u0303\u03c6g\r\nij,t\r\n\r\n(H) = 1 and\r\n\r\n\u0303\u03c6g\r\n(H) = m. In addition, \u03c3jj is the\r\nwith\r\nij,t\r\nstandard deviation of the error term for the jth equation; ei (ej) is the\r\nselection vector, with one being the ith (jth) element and zero otherwise.\r\n\r\nm\r\ni,j=1\r\n\r\nFurthermore, we employ two spillover measurements, including the\r\nnet directional spillover (NDSi) and net pairwise directional spillover\r\n\r\n7\r\n\r\n\fY.-L. Chen et al.\r\n\r\nInternational Review of Financial Analysis 97 (2025) 103810\r\n\r\nFig. 4. Time-varying percent of open interest held by the largest four and eight reportable traders.\r\nNote: The dashed vertical line indicates the introduction day of BITO (10/19/2021). We show the percent of open interest held by the largest four and eight\r\nreportable traders (market concentration), without regard to whether they are classified as dealer, asset managers, or etc.\r\n\r\n(NPDSij) in the Diebold and Yilmaz method and Antonakakis et al.\r\n(2020). NDSi captures the directional spillover of trading positions from\r\ntype i traders to other types and from other traders to type i trader. A\r\npositive (negative) NDSi indicates that the trading position of type i\r\ntrader represents a transmitter (receiver) in the whole market. Similarly,\r\nNPDSij captures the pairwise directional spillover of trading positions\r\nfrom type j to type i traders. A positive (negative) NPDSij indicates that\r\nthe trading position of type j(i) transmits information to the trading\r\nposition of type i (j).", "mimetype": "text/plain", "start_char_idx": 40914, "end_char_idx": 43899, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "58a3c753-e220-4fb1-8011-3ced243a5231": {"__data__": {"id_": "58a3c753-e220-4fb1-8011-3ced243a5231", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2c28ae6a-d489-47a6-b3d7-3a5fc587be1f", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "daa4f0715550fd637b8bf96df50c6a3c31e70374813054fc4cd99c0bef938f49", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2cde69d0-9b5d-4724-809b-a3dde0b87c0f", "node_type": "1", "metadata": {}, "hash": "5d641ba988613b233f96a16e17a54653f6fa936047db293c3552688f777f9002", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We show the percent of open interest held by the largest four and eight\r\nreportable traders (market concentration), without regard to whether they are classified as dealer, asset managers, or etc.\r\n\r\n(NPDSij) in the Diebold and Yilmaz method and Antonakakis et al.\r\n(2020). NDSi captures the directional spillover of trading positions from\r\ntype i traders to other types and from other traders to type i trader. A\r\npositive (negative) NDSi indicates that the trading position of type i\r\ntrader represents a transmitter (receiver) in the whole market. Similarly,\r\nNPDSij captures the pairwise directional spillover of trading positions\r\nfrom type j to type i traders. A positive (negative) NPDSij indicates that\r\nthe trading position of type j(i) transmits information to the trading\r\nposition of type i (j).\r\n\r\nThe results of static trading spillovers of the TVP-VAR based measure\r\n\r\nare presented in Table 2.13 The \u201cnet directional spillover\u201d in NET row\r\nshows that (1) Asset managers serve as the major receiver (Net direc-\r\ntional spillover = 10.19 % - 18.15 % = (cid:0) 7.96 %); (2) Leveraged funds\r\nserve as the major trading transmitters to others (Net directional spill-\r\nover = 50.83 % - 42.85 % = 7.98 %), consistent with the findings of Ji\r\net al. (2019) that leveraged funds play a trading transmitter (spillover)\r\nrole in the futures market; (3) Dealers play a relatively small role in\r\ntrading interaction with others (Net directional spillover = 15.57 % -\r\n17.30 % = (cid:0) 1.73 %).\r\n\r\nMost importantly, we focus on the time variation in TVP-VAR-based\r\n\r\n13 We thank an anonymous reviewer for suggesting the use of the TVP-VAR\r\nmodel to conduct the trading position spillover analysis. The static and dy-\r\nnamic (rolling-window) analyses of the Diebold and Y\u0131lmaz (2012, 2014)\r\ntrading spillover measures are consistent with those obtained using the TVP-\r\nVAR based measures. Due to space constraints, we do not report the results\r\nof Diebold and Y\u0131lmaz (2012, 2014) trading spillovers here, but they are\r\navailable upon request.\r\n\r\n8\r\n\r\n\fY.-L. Chen et al.\r\n\r\nInternational Review of Financial Analysis 97 (2025) 103810\r\n\r\nFig. 5. Net-long position of asset managers, market concentration of the largest four traders on long position, and accumulated fund flow of BITO.\r\nNote: In the sub-sample period (after the introduction day of BITO), the pairwise correlation coefficient between the net-long position of asset managers and the\r\naccumulated fund flow of BITO is about 0.80. The pairwise correlation coefficient between the market concentration of the largest traders on long position and the\r\naccumulated fund flow of BITO is about 0.85.\r\n\r\ntrading spillover measurements across all types of traders. Due to the\r\nspace constraint and the major participants being asset managers and\r\nleveraged funds, we only plot time-varying NPDSij from leveraged funds\r\nto asset managers in Fig. 6.14 It shows that, on average, leveraged funds\r\ntransmit more trading information to asset managers (i.e., Positive\r\nNPDSij) than they receive from them. Obviously, NPDSij becomes smaller\r\nafter the dashed vertical line (the introduction day of BITO). Especially,\r\nat the beginning of BITO introduction, asset managers suddenly trans-\r\nform to information transmitters. This result indicates that the BITO\r\nintroduction alters dynamic trading interactions between asset man-\r\nagers and leveraged funds in bitcoin futures. The increased trading po-\r\nsition of asset managers from BITO trading may trigger leveraged funds\r\n\r\nto also increase their participation by taking the opposite position dur-\r\ning the beginning of BITO introduction.\r\n\r\n6. Market quality and trading positions in CME bitcoin futures\r\n\r\nIn this section, we investigate the impact of the BITO introduction on\r\nmarket liquidity, volatility, and price efficiency in bitcoin futures.\r\nMarket liquidity and price discovery are the two most important func-\r\ntions of financial markets and thus have naturally been a focus of\r\nmicrostructure research (O\u2019Hara, 2003).", "mimetype": "text/plain", "start_char_idx": 43092, "end_char_idx": 47123, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2cde69d0-9b5d-4724-809b-a3dde0b87c0f": {"__data__": {"id_": "2cde69d0-9b5d-4724-809b-a3dde0b87c0f", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "58a3c753-e220-4fb1-8011-3ced243a5231", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "d740280955bf07e35b2868fbc44cfc8d8f650bb81644e5f2388ba4de3267c5ef", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "37d262ac-2700-4276-941b-4f4a02489f36", "node_type": "1", "metadata": {}, "hash": "a6a133e510a1da19c0c17f6ecfae896bd5bfb76d119feaf470693d50732e38d3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Obviously, NPDSij becomes smaller\r\nafter the dashed vertical line (the introduction day of BITO). Especially,\r\nat the beginning of BITO introduction, asset managers suddenly trans-\r\nform to information transmitters. This result indicates that the BITO\r\nintroduction alters dynamic trading interactions between asset man-\r\nagers and leveraged funds in bitcoin futures. The increased trading po-\r\nsition of asset managers from BITO trading may trigger leveraged funds\r\n\r\nto also increase their participation by taking the opposite position dur-\r\ning the beginning of BITO introduction.\r\n\r\n6. Market quality and trading positions in CME bitcoin futures\r\n\r\nIn this section, we investigate the impact of the BITO introduction on\r\nmarket liquidity, volatility, and price efficiency in bitcoin futures.\r\nMarket liquidity and price discovery are the two most important func-\r\ntions of financial markets and thus have naturally been a focus of\r\nmicrostructure research (O\u2019Hara, 2003). We explore the relation be-\r\ntween net trading position and bitcoin futures return before and after the\r\nBITO introduction, and then focus on the impact of BITO introduction on\r\nmarket quality in CME bitcoin futures.\r\n\r\n14 Due to space constraints, we do not report the results of dynamic NDS and\r\nNPDS for other traders here, but they are available on request.\r\n\r\n9\r\n\r\n\fY.-L. Chen et al.\r\n\r\nInternational Review of Financial Analysis 97 (2025) 103810\r\n\r\nTable 1\r\nSummary statistics on the CME bitcoin futures return, percentage trading positions, and net trading positions.\r\nThis table reports the summary statistics of CME bitcoin futures return and the trading positions of the different types of traders over the full sample period (10 April\r\n\u00d7\r\n2018\u201331 October 2022) and the two sub-periods (before and after 19 October 2021). RB\r\nt, which refer to the percentage trading positions held by type i traders on t, where i = AS, DE, LE, OT, and NO, which respectively refer to asset managers,\r\n100. PTPi\r\n(\r\n=\r\ndealers, leveraged funds, other-reportable traders, and non-reportable traders. PTPi\r\nLongi\r\nt refer to the\r\nt\r\nt\r\nlong and short positions held by type i traders on t, MTOIt is the market\u2019s total open interest, and Spreadingi\r\nand short futures positions. NTPi\r\nstandard deviation, skewness, and kurtosis of the time series. ***, **, and * indicate significance at the 1 %, 5 %, and 10 % levels, respectively.\r\n\r\nt measures the extent to which type i traders holds equal long\r\nt. Std. Dev., Skew., and Kurt. refer to the\r\n\r\nt, which refer to the net trading positions held by type i traders on t; NTPi\r\nt\r\n\r\nt represent the return of CME bitcoin futures (time 100) on t; RB\r\nt\r\n\r\n)\r\n/MTOIt, where Longi\r\n\r\n+ 2 \u2022 Spreadingi\r\nt\r\n\r\nt and Shorti\r\n\r\n+ Shorti\r\nt\r\n\r\n= Longi\r\nt\r\n\r\n(cid:0) Shorti\r\n\r\n= d ln\r\n\r\nPB\r\nt\r\n\r\n)\r\n\r\n(cid:0)\r\n\r\nPercentage trading positions (%)\r\n\r\nNet trading positions\r\n\r\nPTPOT\r\nt\r\n\r\nPTPNO\r\nt\r\n\r\nNTPAS\r\n\r\nt\r\n\r\nNTPDE\r\nt\r\n\r\nNTPLE\r\nt\r\n\r\nNTPOT\r\nt\r\n\r\nNTPNO\r\nt\r\n\r\nRB\r\nt\r\n\r\nPanel A. Full sample period\r\n\r\nMean\r\nMedian\r\nStd. Dev.\r\nSkew.\r\nKurt.\r\n\r\n0.46\r\n0.28\r\n10.49\r\n(cid:0) 0.37\r\n4.48\r\n\r\nPTPAS\r\nt\r\n\r\n9.76\r\n4.85\r\n10.49\r\n1.33\r\n3.01\r\n\r\nPanel B. Period 1: Before 19 October 2021\r\n\r\nMean\r\nMedian\r\nStd. Dev.\r\nSkew.\r\nKurt.\r\n\r\n1.15\r\n1.18\r\n10.66\r\n(cid:0) 0.37\r\n4.47\r\n\r\n4.28\r\n4.05\r\n1.80\r\n0.43\r\n3.00\r\n\r\nPanel C. Period 2: After 19 October 2021\r\nMean\r\nMedian\r\nStd. Dev.\r\nSkew.\r\nKurt.", "mimetype": "text/plain", "start_char_idx": 46148, "end_char_idx": 49516, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "37d262ac-2700-4276-941b-4f4a02489f36": {"__data__": {"id_": "37d262ac-2700-4276-941b-4f4a02489f36", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2cde69d0-9b5d-4724-809b-a3dde0b87c0f", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "80c5a0ba69f7e4b6c224cb47c9936a0e71755c6df3f64fe158eff2948db9e0d0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c0aae4eb-1537-402d-a0b6-c82722b038f5", "node_type": "1", "metadata": {}, "hash": "360bc02375d0393bc43b8c4d72bd83a78edc26927058a87b97a0f8cfc03861e5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Dev.\r\nSkew.\r\nKurt.\r\n\r\n0.46\r\n0.28\r\n10.49\r\n(cid:0) 0.37\r\n4.48\r\n\r\nPTPAS\r\nt\r\n\r\n9.76\r\n4.85\r\n10.49\r\n1.33\r\n3.01\r\n\r\nPanel B. Period 1: Before 19 October 2021\r\n\r\nMean\r\nMedian\r\nStd. Dev.\r\nSkew.\r\nKurt.\r\n\r\n1.15\r\n1.18\r\n10.66\r\n(cid:0) 0.37\r\n4.47\r\n\r\n4.28\r\n4.05\r\n1.80\r\n0.43\r\n3.00\r\n\r\nPanel C. Period 2: After 19 October 2021\r\nMean\r\nMedian\r\nStd. Dev.\r\nSkew.\r\nKurt.\r\n\r\n(cid:0) 1.88\r\n(cid:0) 1.69\r\n9.60\r\n(cid:0) 0.59\r\n4.60\r\n\r\n28.12\r\n29.50\r\n5.42\r\n(cid:0) 2.44\r\n10.56\r\n\r\nPTPDE\r\nt\r\n\r\n2.99\r\n2.15\r\n2.81\r\n0.94\r\n2.94\r\n\r\n1.84\r\n1.40\r\n1.70\r\n0.86\r\n3.23\r\n\r\n6.88\r\n7.55\r\n2.31\r\n(cid:0) 0.36\r\n2.16\r\n\r\nPTPLE\r\nt\r\n\r\n55.10\r\n55.85\r\n8.12\r\n0.11\r\n2.70\r\n\r\n58.16\r\n58.23\r\n6.47\r\n0.31\r\n3.73\r\n\r\n44.87\r\n44.95\r\n3.25\r\n0.08\r\n2.25\r\n\r\n15.15\r\n14.80\r\n4.31\r\n0.20\r\n2.55\r\n\r\n16.37\r\n16.03\r\n3.95\r\n0.10\r\n2.68\r\n\r\n11.06\r\n11.15\r\n2.64\r\n0.33\r\n4.44\r\n\r\n16.97\r\n17.50\r\n6.02\r\n0.26\r\n3.10\r\n\r\n19.34\r\n18.50\r\n4.55\r\n1.06\r\n4.46\r\n\r\n9.05\r\n8.70\r\n2.60\r\n1.99\r\n7.98\r\n\r\n1199.4\r\n112.0\r\n2166.8\r\n1.33\r\n2.96\r\n\r\n53.7\r\n1.0\r\n293.0\r\n0.66\r\n3.45\r\n\r\n5032.4\r\n5124.0\r\n983.0\r\n(cid:0) 2.65\r\n12.68\r\n\r\nPanel D. Tests for equality of means before and after 19 October 2021 returns and trading positions variables\r\nt-test\r\n\r\n(cid:0) 17.70***\r\n\r\n(cid:0) 51.15***\r\n\r\n14.68***\r\n\r\n15.99***\r\n\r\n9.35***\r\n\r\n1.87*\r\n\r\n(cid:0) 60.52***\r\n\r\nTable 2\r\nTrading positions spillover analysis in the TVP-VAR model.\r\nThis table reports spillovers of net trading positions of each trader by using the\r\n10-day-ahead forecast error variance decomposition of the TVP-VAR model. The\r\nij-th entry of the upper-left 5 \u00d7 5 net positions submatrix gives the ij-th pairwise\r\ndirectional spillover (i.e., the percentage of 10-day-ahead forecast error variance\r\nof net positions i in response of shocks arising from net positions j). The right-\r\nmost (FROM) column gives total directional spillover (from) (i.e., summation of\r\nrow [from all others to i]). The bottom (TO) row gives total directional spillover\r\n(i.e., summation of column [to all others from j]). The bottommost (NET) row\r\ngives the difference in total directional spillover (which is calculated as TO\r\nminus FROM). The bottom-right element is total spillover index (%).", "mimetype": "text/plain", "start_char_idx": 49170, "end_char_idx": 51267, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c0aae4eb-1537-402d-a0b6-c82722b038f5": {"__data__": {"id_": "c0aae4eb-1537-402d-a0b6-c82722b038f5", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "37d262ac-2700-4276-941b-4f4a02489f36", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "2204e449fd23aa0f5aaee7a67e80928106a9d4ac80efc83a78b2ae2536c1c831", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9f063266-4aaf-4e97-b1ec-7be5f1307f01", "node_type": "1", "metadata": {}, "hash": "7702cfd00bb57e5769ce49d84c3da6200fefffed74b8dc964afe42f74f6c1fab", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This table reports spillovers of net trading positions of each trader by using the\r\n10-day-ahead forecast error variance decomposition of the TVP-VAR model. The\r\nij-th entry of the upper-left 5 \u00d7 5 net positions submatrix gives the ij-th pairwise\r\ndirectional spillover (i.e., the percentage of 10-day-ahead forecast error variance\r\nof net positions i in response of shocks arising from net positions j). The right-\r\nmost (FROM) column gives total directional spillover (from) (i.e., summation of\r\nrow [from all others to i]). The bottom (TO) row gives total directional spillover\r\n(i.e., summation of column [to all others from j]). The bottommost (NET) row\r\ngives the difference in total directional spillover (which is calculated as TO\r\nminus FROM). The bottom-right element is total spillover index (%).\r\n\r\n(cid:0) 284.1\r\n0.0\r\n633.9\r\n(cid:0) 1.98\r\n6.13\r\n\r\n(cid:0) 47.2\r\n0.0\r\n229.8\r\n(cid:0) 0.89\r\n4.19\r\n\r\n(cid:0) 1076.6\r\n(cid:0) 875.0\r\n872.4\r\n(cid:0) 0.06\r\n1.52\r\n\r\n(cid:0) 2492.9\r\n(cid:0) 2048.0\r\n2139.3\r\n(cid:0) 0.32\r\n1.61\r\n\r\n(cid:0) 1643.6\r\n(cid:0) 1046.0\r\n1635.6\r\n(cid:0) 0.85\r\n2.67\r\n\r\n(cid:0) 5334.3\r\n(cid:0) 5454.0\r\n651.0\r\n0.70\r\n3.34\r\n\r\n495.5\r\n129.0\r\n1107.5\r\n0.72\r\n2.74\r\n\r\n374.7\r\n(cid:0) 21.0\r\n1117.9\r\n0.90\r\n2.95\r\n\r\n899.6\r\n904.0\r\n976.7\r\n0.44\r\n2.93\r\n\r\n1082.1\r\n910.0\r\n831.7\r\n0.96\r\n3.27\r\n\r\n1262.4\r\n1087.5\r\n796.7\r\n0.81\r\n2.74\r\n\r\n479.0\r\n372.0\r\n645.1\r\n3.12\r\n15.80\r\n\r\n14.47***\r\n\r\n16.33***\r\n\r\n(cid:0) 3.14***\r\n\r\n6.66***\r\n\r\n\u0394NTPAS\r\n\r\nt\r\n\r\n\u0394NTPDE\r\n\r\nt\r\n\r\n\u0394NTPLE\r\nt\r\n\r\n\u0394NTPNO\r\n\r\nt\r\n\r\n\u0394NTPOT\r\n\r\nt\r\n\r\nFROM\r\n\r\n81.85\r\n\r\n1.34\r\n2.42\r\n\r\n3.01\r\n\r\n3.41\r\n\r\n10.19\r\n(cid:0) 7.96\r\n\r\n4.10\r\n\r\n82.70\r\n2.76\r\n\r\n3.46\r\n\r\n5.24\r\n\r\n15.57\r\n(cid:0) 1.73\r\n\r\n3.59\r\n\r\n5.52\r\n57.15\r\n\r\n17.73\r\n\r\n23.98\r\n\r\n50.83\r\n7.98\r\n\r\n3.81\r\n\r\n2.59\r\n17.12\r\n\r\n70.83\r\n\r\n2.45\r\n\r\n25.97\r\n(cid:0) 3.20\r\n\r\n6.65\r\n\r\n7.84\r\n20.55\r\n\r\n4.96\r\n\r\n64.91\r\n\r\n40.00\r\n4.91\r\n\r\n18.15\r\n\r\n17.30\r\n42.85\r\n\r\n29.17\r\n\r\n35.09\r\n\r\n28.51\r\n\r\nt\r\n\r\n\u0394NTPAS\r\n\u0394NTPDE\r\nt\r\n\u0394NTPLE\r\nt\r\n\u0394NTPNO\r\n\u0394NTPOT\r\nTO\r\nNET\r\n\r\nt\r\n\r\nt\r\n\r\n6.1. Net trading positions in CME bitcoin futures\r\n\r\nThe bilateral correlation coefficients between the bitcoin futures\r\nreturn and the net trading positions of the five types of traders, along\r\nwith their significance levels, are shown in Table 3. The bilateral cor-\r\nrelation analysis provides some preliminary insights into the relation-\r\nships between the trading activities of various traders and the bitcoin\r\nfutures returns. Table 3 shows that bitcoin futures returns are negatively\r\ncorrelated with the net trading positions of dealers and leveraged funds,\r\nbut they are positively correlated with the net trading positions of asset\r\n\r\n10\r\n\r\nFig. 6. Time-varying net pairwise directional spillover (NPDS) from leveraged\r\nfunds to asset managers.", "mimetype": "text/plain", "start_char_idx": 50460, "end_char_idx": 53138, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9f063266-4aaf-4e97-b1ec-7be5f1307f01": {"__data__": {"id_": "9f063266-4aaf-4e97-b1ec-7be5f1307f01", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c0aae4eb-1537-402d-a0b6-c82722b038f5", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "41793607cf2aa2419219bcf9d0f1c383cbd6eb228b2c085802be839cd7e7dcfa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d4e32535-5cc8-4d3d-a87f-aba20f49bfa4", "node_type": "1", "metadata": {}, "hash": "c296b3356f27568fde8abab803afc0600f9410645d6577f1d9eca4cbcc61ccc5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Net trading positions in CME bitcoin futures\r\n\r\nThe bilateral correlation coefficients between the bitcoin futures\r\nreturn and the net trading positions of the five types of traders, along\r\nwith their significance levels, are shown in Table 3. The bilateral cor-\r\nrelation analysis provides some preliminary insights into the relation-\r\nships between the trading activities of various traders and the bitcoin\r\nfutures returns. Table 3 shows that bitcoin futures returns are negatively\r\ncorrelated with the net trading positions of dealers and leveraged funds,\r\nbut they are positively correlated with the net trading positions of asset\r\n\r\n10\r\n\r\nFig. 6. Time-varying net pairwise directional spillover (NPDS) from leveraged\r\nfunds to asset managers.\r\nNote: The dashed vertical line indicates the introduction day of BITO.\r\n\r\nmanagers and non-reportable traders (retail traders). Since trading po-\r\nsitions of asset managers reflect their crated ETFs fund flow and demand\r\nof some retail traders, more bitcoin ETFs fund inflow would increase net-\r\nlong positions of asset managers in bitcoin futures. The net-long trading\r\npositions of asset managers, on top of the net-long trading positions of\r\nnon-reportable traders, would then push bitcoin futures prices up. In\r\ncontrast, dealers and leveraged funds provide liquidity for the demand\r\nof retail traders and hence generally stand on the opposite side (i.e., net-\r\nshort positions) in bitcoin futures.\r\n\r\n\fY.-L. Chen et al.\r\n\r\nInternational Review of Financial Analysis 97 (2025) 103810\r\n\r\nTable 3\r\nPairwise correlation analyses in the CME bitcoin futures return and net trading\r\npositions.\r\nThis table reports the correlation coefficients among the CME bitcoin futures\r\nreturn and the changes in net trading positions All of the variables are as defined\r\nin the notes to Table 1. Correlation coefficients are reported first and their p-\r\nvalues are reported in the following parentheses.\r\n\r\n\u0394NTPAS\r\n\r\nt\r\n\r\n\u0394NTPDE\r\n\r\nt\r\n\r\n\u0394NTPLE\r\nt\r\n\r\n\u0394NTPOT\r\n\r\nt\r\n\r\n\u0394NTPNO\r\n\r\nt\r\n\r\nRB\r\nt\r\n\r\n0.21\r\n(0.00)\r\n(cid:0) 0.21\r\n(0.00)\r\n(cid:0) 0.23\r\n(0.00)\r\n(cid:0) 0.05\r\n(0.46)\r\n0.25\r\n(0.00)\r\n\r\n\u0394NTPAS\r\n\r\nt\r\n\r\n\u0394NTPDE\r\n\r\nt\r\n\r\n\u0394NTPLE\r\nt\r\n\r\n\u0394NTPOT\r\n\r\nt\r\n\r\n(cid:0) 0.14\r\n(0.03)\r\n(cid:0) 0.15\r\n(0.01)\r\n(cid:0) 0.32\r\n(0.00)\r\n(cid:0) 0.15\r\n(0.01)\r\n\r\n0.15\r\n(0.02)\r\n(cid:0) 0.20\r\n(0.00)\r\n(cid:0) 0.17\r\n(0.00)\r\n\r\n(cid:0) 0.57\r\n(0.00)\r\n(cid:0) 0.51\r\n(0.00)\r\n\r\n(cid:0) 0.13\r\n(0.05)\r\n\r\nGiven our earlier findings that the BITO introduction alters trading\r\nactivities of different types of traders, we further investigate whether\r\nthese changes in trading activities affect bitcoin futures prices and the\r\nprice spread between bitcoin futures and spot. Bessembinder (1992), De\r\nRoon et al. (2000), Wang (2003), and Chen and Yang (2021) find that\r\nhedging pressure is a key determinant of futures premiums and contains\r\nexplanatory power for futures returns. The rationale is that hedgers hold\r\nthe underlying asset and thus have the need to hedge by holding short\r\npositions in the corresponding futures. The short positions for hedgers\r\nmay drive down the futures price relative to the expected value of the\r\nspot price. Speculators who enter the market by taking long (opposite)\r\npositions of the corresponding futures expect to be compensated for\r\nbearing risk. Based on the hedging pressure theory, trading activities of\r\nhedgers (speculators) may have negative (positive) impact on the price\r\nof bitcoin futures.\r\n\r\nIn addition, stock index price movements can affect bitcoin futures\r\nprices because changes in stock market indices often reflect broader\r\ninvestor sentiment and risk appetite. During periods of heightened\r\noptimism or pessimism in equity markets, investors may adjust their\r\npositions in alternative assets such as bitcoin futures, influencing their\r\nprices (Nguyen, 2022). Chan et al.", "mimetype": "text/plain", "start_char_idx": 52390, "end_char_idx": 56209, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d4e32535-5cc8-4d3d-a87f-aba20f49bfa4": {"__data__": {"id_": "d4e32535-5cc8-4d3d-a87f-aba20f49bfa4", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9f063266-4aaf-4e97-b1ec-7be5f1307f01", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "a97cbf15a8fd0615068f10a10c12137b1cb8e530ddbba22c4a75e21bc3d73e37", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "565ebbeb-d36c-47b9-a23d-1f1ff25ab89f", "node_type": "1", "metadata": {}, "hash": "1b92428dd372e913354aa9c8cfe44c24bde4bd58ab3f3b8e9897ce81743d7700", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The rationale is that hedgers hold\r\nthe underlying asset and thus have the need to hedge by holding short\r\npositions in the corresponding futures. The short positions for hedgers\r\nmay drive down the futures price relative to the expected value of the\r\nspot price. Speculators who enter the market by taking long (opposite)\r\npositions of the corresponding futures expect to be compensated for\r\nbearing risk. Based on the hedging pressure theory, trading activities of\r\nhedgers (speculators) may have negative (positive) impact on the price\r\nof bitcoin futures.\r\n\r\nIn addition, stock index price movements can affect bitcoin futures\r\nprices because changes in stock market indices often reflect broader\r\ninvestor sentiment and risk appetite. During periods of heightened\r\noptimism or pessimism in equity markets, investors may adjust their\r\npositions in alternative assets such as bitcoin futures, influencing their\r\nprices (Nguyen, 2022). Chan et al. (2019) find that bitcoin can hedge\r\nand diversify against certain assets among S&P 500, Nikkei, Shanghai A-\r\nShare, TSX, and Euro Index. Some traders may use bitcoin futures as part\r\nof their portfolio diversification or hedging strategies. Changes in stock\r\nindex prices can prompt adjustments in these strategies, thereby\r\nimpacting demand and supply dynamics in the bitcoin futures market.\r\nRegarding impact of market uncertainty, VIX index can influence\r\nbitcoin futures prices in several ways. During times of heightened un-\r\ncertainty or risk aversion in traditional financial markets, investors may\r\nseek alternative assets like bitcoin as a store of value or safe-haven asset\r\n(Urom et al., 2020 Mariana et al., 2021). This increased demand may\r\ndrive up bitcoin futures prices. In addition, increased uncertainty in US\r\nstock markets can lead to higher overall market volatility, affecting\r\ntrading patterns, and price dynamics in bitcoin futures markets (i.e., the\r\nvolatility spillovers in different financial assets). In the regression ana-\r\nlyses, we include stock index price movements and market uncertainty\r\nas control variables to statistically account for their potential influence\r\non bitcoin futures prices and futures basis.\r\n\r\nSimilar to De Roon et al. (2000) and Chen and Yang (2021), to\r\nexamine the impact of different trading positions on bitcoin futures, we\r\nemploy the following regression models:\r\n\r\nRB\r\n\r\nt+1\r\n\r\n= \u03b20\r\n\r\n+ \u03b21DBITO\r\n)\r\n\r\nt\r\n\r\n+ \u03b22\u0394NTPi\r\n+ \u03b25RSP\r\n\r\n+ \u03b23\r\n+ \u03b26RB\r\n\r\n\u0394NTPi\r\nt\r\n+ et+1\r\n\r\nt\r\n\r\nt\r\n\r\nt\r\n\r\n+ \u03b24RVIX\r\n\r\nt\r\n\r\n\u2022 DBITO\r\nt\r\n\r\n(cid:0)\r\n\r\nand\r\n\r\n(8)\r\n\r\n11\r\n\r\nBasisB\r\n\r\nt+1\r\n\r\n= \u03b20\r\n\r\n+ \u03b21DBITO\r\n)\r\n\r\nt\r\n\r\n+ \u03b22\u0394NTPi\r\n+ \u03b25RSP\r\n\r\n+ \u03b23\r\n\u0394NTPi\r\nt\r\n+ \u03b26BasisB\r\n\r\nt\r\n\r\nt\r\n\r\nt\r\n\r\n+ \u03b24RVIX\r\n\r\nt\r\n\r\n\u2022 DBITO\r\nt\r\n\r\n(cid:0)\r\n\r\n+ et+1,\r\n\r\n(9)\r\n\r\nwhere RB, RVIX, and RSP represent the return (i.e., log-difference) of CME\r\nbitcoin futures, VIX index, and S&P 500 index futures (times 100),\r\nrespectively. BasisB represents futures basis (i.e., futures price minus\r\nspot price). NTPi refers to the net trading positions held by type i traders\r\n(NTPi = Longi (cid:0) Shorti), where i = AS, DE, LE, OT, and NO, which\r\nrespectively refer to asset managers, dealers, leveraged funds, other\r\nreportable traders, and non-reportable traders. DBITOrepresents the BITO\r\nintroduction dummy which equals to one after the introduction of BITO\r\nand zero otherwise. Price movements of stock index and market un-\r\ncertainty may also affect the bitcoin futures price dynamics and thus are\r\nincluded as control variables. Net trading positions among different\r\ntypes of traders may exhibit a high correlation, so we avoid the collin-\r\nearity issue by considering NTPi for each type i separately in Eqs. (8) and\r\n(9).\r\n\r\nThe estimation results of Eqs. (8) and (9) are reported in Table 4. We\r\nfind that the coefficients of BITO introduction dummy are significantly\r\nnegative, but trading activities of the five types of traders have insig-\r\nnificant impact on subsequent bitcoin futures price movements.", "mimetype": "text/plain", "start_char_idx": 55260, "end_char_idx": 59226, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "565ebbeb-d36c-47b9-a23d-1f1ff25ab89f": {"__data__": {"id_": "565ebbeb-d36c-47b9-a23d-1f1ff25ab89f", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d4e32535-5cc8-4d3d-a87f-aba20f49bfa4", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "63678cc7b03ce62d321bf39cfa228c946d50ed761607f8b5e75cf284787caedc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cc28e627-2bff-4733-a2b6-ad62bff01b4a", "node_type": "1", "metadata": {}, "hash": "91abbd9a8385c2a62921c8918978bdcfd2bfe78824b2a8d6ad4c713cb2e442d8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "DBITOrepresents the BITO\r\nintroduction dummy which equals to one after the introduction of BITO\r\nand zero otherwise. Price movements of stock index and market un-\r\ncertainty may also affect the bitcoin futures price dynamics and thus are\r\nincluded as control variables. Net trading positions among different\r\ntypes of traders may exhibit a high correlation, so we avoid the collin-\r\nearity issue by considering NTPi for each type i separately in Eqs. (8) and\r\n(9).\r\n\r\nThe estimation results of Eqs. (8) and (9) are reported in Table 4. We\r\nfind that the coefficients of BITO introduction dummy are significantly\r\nnegative, but trading activities of the five types of traders have insig-\r\nnificant impact on subsequent bitcoin futures price movements. The\r\nestimated coefficients of interaction terms of BITO introduction and net\r\ntrading positions are also insignificant, suggesting that the BITO intro-\r\nduction does not affect the impact of trading activities on bitcoin futures\r\nreturns.\r\n\r\nIn addition, Table 4 shows that the estimated coefficient of asset\r\nmanagers trading on subsequent bitcoin futures basis is insignificantly\r\nnegative, but the estimated coefficient of the interaction term of BITO\r\nintroduction and asset managers trading is significantly positive. This\r\nresult suggests that the BITO introduction strengthens the trading role of\r\nasset managers and their increased long positions help drive up bitcoin\r\nfutures prices, leading to a higher basis. Zhong et al. (2004), Chau et al.\r\n(2015), Ngene et al. (2018), and Ngene and Wang (2024) highlight the\r\nrole of the basis as a signal of arbitrage opportunities between spot and\r\nfutures markets.15 These studies indicate that rational speculators and\r\nfeedback traders actively participate in both markets to exploit dis-\r\ncrepancies in the basis, thereby influencing trading behavior and prof-\r\nitability. The introduction of BITO ETF, as a new financial instrument,\r\nmay indeed alter the dynamics of arbitrage activities among spot, ETF,\r\nand futures markets. Specifically, BITO ETF could attract asset managers\r\nto trade and change liquidity conditions, which may affect the arbitrage\r\nopportunities in these markets.\r\n\r\nFinally, the coefficients of other variables are not significant,\r\nimplying that the BITO introduction and trading positions of other\r\ntraders do not have significant impact on futures basis. These results\r\nindicate that the trading activities in bitcoin futures may be different\r\nfrom those in traditional futures, such as equity or commodity. The BITO\r\nintroduction and asset managers\u2019 trading positions can affect bitcoin\r\nfutures prices and thus may affect market quality in bitcoin futures.\r\n\r\n6.2. Percent trading positions and market quality in CME bitcoin futures\r\nafter the BITO introduction\r\n\r\nSince the previous literature has documented the effect of ETFs\r\nintroduction on market quality, we analyze the impact of BITO intro-\r\nduction on the market quality of bitcoin futures, focusing on three\r\ndifferent aspects: (1) Liquidity, (2) Volatility, and (3) Price efficiency.\r\nWe use various methods to measure liquidity, volatility, and price effi-\r\nciency to check the robustness of our results. Specifically, we consider\r\n\r\n15 We appreciate an anonymous reviewer for suggesting those relevant studies\r\nto help explain the relation between the basis and arbitrage opportunities in\r\nthese markets.\r\n\r\n\fY.-L. Chen et al.\r\n\r\nInternational Review of Financial Analysis 97 (2025) 103810\r\n\r\nTable 4\r\nPrice changes, futures basis, and trading positions in the CME bitcoin futures\r\nbefore and after the introduction of BITO.", "mimetype": "text/plain", "start_char_idx": 58476, "end_char_idx": 62099, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cc28e627-2bff-4733-a2b6-ad62bff01b4a": {"__data__": {"id_": "cc28e627-2bff-4733-a2b6-ad62bff01b4a", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "565ebbeb-d36c-47b9-a23d-1f1ff25ab89f", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "0b170ba92619efefd7dd708e7f8d89681121644e47ccbce623d74b8e152caad1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6a6c8417-944f-4929-b34b-653523fd3386", "node_type": "1", "metadata": {}, "hash": "3971d5c41ee46d184e6132b9018d8013f1e36aadac53d5963a510a40dee02851", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Percent trading positions and market quality in CME bitcoin futures\r\nafter the BITO introduction\r\n\r\nSince the previous literature has documented the effect of ETFs\r\nintroduction on market quality, we analyze the impact of BITO intro-\r\nduction on the market quality of bitcoin futures, focusing on three\r\ndifferent aspects: (1) Liquidity, (2) Volatility, and (3) Price efficiency.\r\nWe use various methods to measure liquidity, volatility, and price effi-\r\nciency to check the robustness of our results. Specifically, we consider\r\n\r\n15 We appreciate an anonymous reviewer for suggesting those relevant studies\r\nto help explain the relation between the basis and arbitrage opportunities in\r\nthese markets.\r\n\r\n\fY.-L. Chen et al.\r\n\r\nInternational Review of Financial Analysis 97 (2025) 103810\r\n\r\nTable 4\r\nPrice changes, futures basis, and trading positions in the CME bitcoin futures\r\nbefore and after the introduction of BITO.\r\nThis table shows results from individual regressions of bitcoin futures market\r\nprice changes and futures basis on their factors and reports the estimations of the\r\nfollowing model:\r\n+ \u03b21DBITO\r\nRB\r\n\r\n+ \u03b22\u0394NTPi\r\n\r\n+ \u03b24RVIX\r\n\r\n+ \u03b25RSP\r\n\r\n+ \u03b26RB\r\n\r\n+ et+1\r\n\r\n= \u03b20\r\n\r\n\u2022 DBITO\r\nt\r\n\r\n\u0394NTPi\r\nt\r\n\r\n+ \u03b23\r\n\r\nt+1\r\n\r\n)\r\n\r\n(cid:0)\r\n\r\nt\r\n\r\nt\r\n\r\nt\r\n\r\nt\r\n\r\nt\r\n\r\n(and)\r\nBasisB\r\n\r\nt+1\r\n\r\n= \u03b20\r\n\r\n+ \u03b21DBITO\r\n\r\nt\r\n\r\n+ \u03b22\u0394NTPi\r\n\r\nt\r\n\r\n+ \u03b23\r\n\r\n(cid:0)\r\n\r\n\u0394NTPi\r\nt\r\n\r\n\u2022 DBITO\r\nt\r\n\r\n)\r\n\r\n+ \u03b24RVIX\r\n\r\nt\r\n\r\n+ \u03b25RSP\r\n\r\nt\r\n\r\n+ \u03b26BasisB\r\n\r\nt\r\n\r\n+ et+1,\r\n\r\nwhere RB, RVIX, and RSP represent the return of CME bitcoin futures, VIX index,\r\nand S&P 500 index futures (time 100). BasisB represent futures basis. NTPi refer\r\nto the net trading positions held by type i traders (NTPi = Longi (cid:0) Shorti), where\r\ni = AS, DE, LE, OT, and NO, which respectively refer to asset managers, dealers,\r\nleveraged funds, other-reportable traders, and non-reportable traders. Co-\r\nefficients on control variables are estimated but not tabulated. ***, **, and *\r\nindicate significant at the 1 %, 5 %, and 10 % levels, respectively.", "mimetype": "text/plain", "start_char_idx": 61177, "end_char_idx": 63188, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6a6c8417-944f-4929-b34b-653523fd3386": {"__data__": {"id_": "6a6c8417-944f-4929-b34b-653523fd3386", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cc28e627-2bff-4733-a2b6-ad62bff01b4a", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "2d8b0628c0ba2849ecf2b1f0db27cea1210ba2546ac692f2b9bc91684d6de9f2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7dce949b-f4c3-4e48-83da-4da2558e6ac4", "node_type": "1", "metadata": {}, "hash": "84d7b41ddfe4c813b72fa57e8b1037f317e84d1d49433156aaf7e0585843cb2c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "BasisB represent futures basis. NTPi refer\r\nto the net trading positions held by type i traders (NTPi = Longi (cid:0) Shorti), where\r\ni = AS, DE, LE, OT, and NO, which respectively refer to asset managers, dealers,\r\nleveraged funds, other-reportable traders, and non-reportable traders. Co-\r\nefficients on control variables are estimated but not tabulated. ***, **, and *\r\nindicate significant at the 1 %, 5 %, and 10 % levels, respectively.\r\n\r\n(1) Asset managers\r\n\r\n(2) Dealers\r\n\r\nRB\r\n\r\nBasisB\r\n\r\nVariable\r\n\r\nRB\r\n\r\nVariable\r\n\r\nIntercept\r\n\r\nDBITO\r\n\r\n\u0394NTPAS\r\n\r\n\u0394NTPAS \u2022 DBITO\r\n\r\nAdj.R2\r\n\r\n1.28\r\n(0.86)\r\n(cid:0) 3.79***\r\n(1.35)\r\n(cid:0) 0.01\r\n(0.01)\r\n0.01\r\n(0.01)\r\n0.03\r\n\r\n32.57\r\n(25.31)\r\n12.11\r\n(61.38)\r\n(cid:0) 0.06\r\n(0.11)\r\n0.25**\r\n(0.10)\r\n0.07\r\n\r\n(3) Leveraged funds\r\n\r\nIntercept\r\n\r\nDBITO\r\n\r\n\u0394NTPDE\r\n\r\n\u0394NTPDE \u2022 DBITO\r\n\r\nAdj.R2\r\n\r\n1.28\r\n(0.78)\r\n(cid:0) 3.43**\r\n(1.67)\r\n0.01\r\n(0.01)\r\n(cid:0) 0.01\r\n(0.01)\r\n0.03\r\n\r\nBasisB\r\n\r\n31.97\r\n(28.21)\r\n24.19\r\n(59.42)\r\n0.15\r\n(0.24)\r\n(cid:0) 0.35\r\n(0.32)\r\n0.05\r\n\r\n(4) Other-reportable\r\ntraders\r\nRB\r\n1.28\r\n(0.78)\r\n(cid:0) 3.69**\r\n(1.65)\r\n0.01\r\n(0.01)\r\n(cid:0) 0.01\r\n(0.01)\r\n0.03\r\n\r\nBasisB\r\n26.14\r\n(22.93)\r\n17.92\r\n(48.17)\r\n(cid:0) 0.01\r\n(0.05)\r\n(cid:0) 0.04\r\n(0.09)\r\n0.04\r\n\r\nVariable\r\nIntercept\r\n\r\nDBITO\r\n\r\n\u0394NTPLE\r\n\r\n\u0394NTPLE \u2022 DBITO\r\n\r\nAdj.R2\r\n\r\nRB\r\n1.26\r\n(0.78)\r\n(cid:0) 3.49**\r\n(1.64)\r\n0.01\r\n(0.01)\r\n0.01\r\n(0.01)\r\n0.03\r\n\r\nBasisB\r\n25.91\r\n(22.89)\r\n19.27\r\n(48.03)\r\n0.02\r\n(0.04)\r\n(cid:0) 0.05\r\n(0.08)\r\n0.04\r\n\r\nVariable\r\nIntercept\r\n\r\nDBITO\r\n\r\n\u0394NTPOT\r\n\r\n\u0394NTPOT \u2022 DBITO\r\n\r\nAdj.R2\r\n\r\nVariable\r\nIntercept\r\n\r\nDBITO\r\n\r\n\u0394NTPNO\r\n\r\n\u0394NTPNO \u2022 DBITO\r\n\r\nAdj.R2\r\n\r\n(5) Non-reportable\r\ntraders\r\nRB\r\n1.24\r\n(0.78)\r\n(cid:0) 3.48**\r\n(1.65)\r\n(cid:0) 0.01\r\n(0.01)\r\n0.01\r\n(0.01)\r\n0.03\r\n\r\nBasisB\r\n24.91\r\n(20.82)\r\n19.85\r\n(54.96)\r\n(cid:0) 0.04\r\n(0.05)\r\n(cid:0) 0.03\r\n(0.16)\r\n0.04\r\n\r\nt\r\n\r\n(cid:0)\r\n\r\n)\r\n\r\nt(cid:0) 1\r\n\r\n+ ej\r\n\r\n+ \u03b23\r\n\r\nPTPi\r\nt\r\n\r\n+ \u03b26Lj\r\n\r\n\u2022 DBITO\r\nt\r\n\r\n+ \u03b25RSP\r\nt\r\n\r\n+ \u03b24RVIX\r\n\r\n+ \u03b22PTPi\r\nt\r\n\r\n+ \u03b21DBITO\r\nt\r\n\r\nTable 5\r\nMarket liquidity and trading positions in the CME bitcoin futures.\r\nThis table shows results from individual regressions of bitcoin futures market\r\nliquidity on its factors and reports the estimations of the following model: Lj\r\nt =\r\n\u03b20\r\nt, where\r\nLj are the market liquidity measurements of CME bitcoin futures include Ami-\r\nhud\u2019s illquidity (j = Amihud, times 105) and average daily volume (j = Volume,\r\ndivided by 104).", "mimetype": "text/plain", "start_char_idx": 62747, "end_char_idx": 65109, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7dce949b-f4c3-4e48-83da-4da2558e6ac4": {"__data__": {"id_": "7dce949b-f4c3-4e48-83da-4da2558e6ac4", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6a6c8417-944f-4929-b34b-653523fd3386", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1d3d46be58dd13232e859e2565e9fe73e99aa09d5e35094e39d2539b3d54af73", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7afae2f4-a76a-4c8a-a2d4-186db18ce484", "node_type": "1", "metadata": {}, "hash": "b343327ea0701ad9327fc5834c6ffa2b4c9ca1076092b6d09edf361e4d4b2880", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This table shows results from individual regressions of bitcoin futures market\r\nliquidity on its factors and reports the estimations of the following model: Lj\r\nt =\r\n\u03b20\r\nt, where\r\nLj are the market liquidity measurements of CME bitcoin futures include Ami-\r\nhud\u2019s illquidity (j = Amihud, times 105) and average daily volume (j = Volume,\r\ndivided by 104). DBITOrepresent the BITO introduction dummy which equals to\r\none after the introduction of BITO ETF and zero otherwise. PTPi, which refer to\r\nthe percentage trading positions held by type i traders, where i = AS, DE, LE, OT,\r\nand NO, which respectively refer to (1) asset managers, (2) dealers, (3) lever-\r\n=\r\naged funds, (4) other -reportable traders, and (5) non-reportable traders. PTPi\r\n(\r\nt\r\nLongi\r\nt\r\n\r\nt refer to the\r\nlong and short positions held by type i traders on t, MTOIt is the market\u2019s total\r\nopen interest, and Spreadingi\r\nt measures the extent to which type i traders holds\r\nequal long and short futures positions. Coefficients on control variables are\r\nestimated but not tabulated. ***, **, and * indicate significant at the 1 %, 5 %,\r\nand 10 % levels, respectively.\r\n\r\n)", "mimetype": "text/plain", "start_char_idx": 64755, "end_char_idx": 65898, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7afae2f4-a76a-4c8a-a2d4-186db18ce484": {"__data__": {"id_": "7afae2f4-a76a-4c8a-a2d4-186db18ce484", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7dce949b-f4c3-4e48-83da-4da2558e6ac4", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "9f93bd055c726fa3aa7959a486cad55ab9be942a47c0cd30336a7ea27542d08b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e5411dac-0ace-4c41-a99e-891d51767b53", "node_type": "1", "metadata": {}, "hash": "8b1dbefef05f6264b333c6e06ee348a3308b0ac933ecd5f26b68c4b6c671525b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "PTPi, which refer to\r\nthe percentage trading positions held by type i traders, where i = AS, DE, LE, OT,\r\nand NO, which respectively refer to (1) asset managers, (2) dealers, (3) lever-\r\n=\r\naged funds, (4) other -reportable traders, and (5) non-reportable traders. PTPi\r\n(\r\nt\r\nLongi\r\nt\r\n\r\nt refer to the\r\nlong and short positions held by type i traders on t, MTOIt is the market\u2019s total\r\nopen interest, and Spreadingi\r\nt measures the extent to which type i traders holds\r\nequal long and short futures positions. Coefficients on control variables are\r\nestimated but not tabulated. ***, **, and * indicate significant at the 1 %, 5 %,\r\nand 10 % levels, respectively.\r\n\r\n)\r\n/MTOIt, where Longi\r\n\r\n+ 2 \u2022 Spreadingi\r\nt\r\n\r\nt and Shorti\r\n\r\n+ Shorti\r\nt\r\n\r\nVariable\r\n\r\nIntercept\r\n\r\nDBITO\r\n\r\nPTPAS\r\n\r\nPTPAS \u2022 DBITO\r\n\r\nAdj.R2\r\n\r\nVariable\r\nIntercept\r\n\r\nDBITO\r\n\r\nPTPLE\r\n\r\nPTPLE \u2022 DBITO\r\n\r\nAdj.R2\r\n\r\nVariable\r\nIntercept\r\n\r\nDBITO\r\n\r\nPTPNO\r\n\r\nPTPNO \u2022 DBITO\r\n\r\nAdj.R2\r\n\r\n(1) Asset managers\r\n\r\n(2) Dealers\r\n\r\nLAmihud\r\n\r\nLVolume\r\n\r\nVariable\r\n\r\nLAmihud\r\n\r\nLVolume\r\n\r\n3.69***\r\n(0.53)\r\n(cid:0) 2.55**\r\n(1.05)\r\n0.17\r\n(0.10)\r\n(cid:0) 0.20*\r\n(0.11)\r\n0.04\r\n\r\n0.74***\r\n(0.09)\r\n0.23**\r\n(0.11)\r\n(cid:0) 0.04**\r\n(0.02)\r\n0.03**\r\n(0.01)\r\n0.36\r\n\r\nIntercept\r\n\r\nDBITO\r\n\r\nPTPDE\r\n\r\nPTPDE \u2022 DBITO\r\n\r\nAdj.R2\r\n\r\n3.57***\r\n(0.11)\r\n(cid:0) 2.43**\r\n(1.10)\r\n(cid:0) 0.33***\r\n(0.10)\r\n0.18\r\n(0.18)\r\n0.07\r\n\r\n0.51***\r\n(0.05)\r\n0.33***\r\n(0.11)\r\n0.03*\r\n(0.02)\r\n(cid:0) 0.02\r\n(0.02)\r\n0.35\r\n\r\n(4) Other-reportable\r\ntraders\r\nLAmihud\r\n3.74***\r\n(0.08)\r\n(cid:0) 1.78*\r\n(1.00)\r\n(cid:0) 0.05\r\n(0.04)\r\n0.05\r\n(0.14)\r\n0.03\r\n\r\nLVolume\r\n0.55***\r\n(0.11)\r\n0.06\r\n(0.20)\r\n0.01\r\n(0.01)\r\n0.01\r\n(0.01)\r\n0.35\r\n\r\nVariable\r\nIntercept\r\n\r\nDBITO\r\n\r\nPTPOT\r\n\r\nPTPOT \u2022 DBITO\r\n\r\nAdj.R2\r\n\r\n(3) Leveraged funds\r\n\r\nLAmihud\r\n0.49\r\n(1.70)\r\n(cid:0) 4.39***\r\n(1.03)\r\n0.04\r\n(0.03)\r\n(cid:0) 0.10\r\n(0.10)\r\n0.03\r\n\r\nLVolume\r\n\r\n0.27\r\n(0.24)\r\n0.51***\r\n(0.16)\r\n0.01\r\n(0.00)\r\n0.00\r\n(0.01)\r\n0.35\r\n\r\n(5) Non-reportable\r\ntraders\r\nLAmihud\r\n2.53***\r\n(0.84)\r\n(cid:0) 1.89*\r\n(1.02)\r\n0.02\r\n(0.04)\r\n0.03\r\n(0.14)\r\n0.03\r\n\r\nLVolume\r\n0.81***\r\n(0.13)\r\n0.20\r\n(0.20)\r\n(cid:0) 0.01*\r\n(0.00)\r\n0.02\r\n(0.02)\r\n0.35\r\n\r\nthe Amihud\u2019s illiquidity and trading volume to measure market liquidity\r\nand adopt weekly realized volatility based on 1-min, 5-min, and 20-min\r\nbitcoin futures returns variance. We measure price efficiency using two\r\nstandard proxies: pricing error based on Hasbrouck (1993) and variance\r\nratios, which have been adopted by Boehmer and Kelley (2009) and\r\n\r\nChen and Xu (2021).", "mimetype": "text/plain", "start_char_idx": 65229, "end_char_idx": 67705, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e5411dac-0ace-4c41-a99e-891d51767b53": {"__data__": {"id_": "e5411dac-0ace-4c41-a99e-891d51767b53", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7afae2f4-a76a-4c8a-a2d4-186db18ce484", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "25cc8e7e3240c43a8403595d67d3b6a99880e72c8f590d490382ba245cb7c1ee", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9f35c193-e93d-4ed1-b44d-08ff36ddaf5d", "node_type": "1", "metadata": {}, "hash": "889b9109e4b68b057be9afbf9f0f548d18c9207caaa5971192fd077f6ea20b6d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We measure price efficiency using two\r\nstandard proxies: pricing error based on Hasbrouck (1993) and variance\r\nratios, which have been adopted by Boehmer and Kelley (2009) and\r\n\r\nChen and Xu (2021).\r\n\r\n(1) For liquidity (or illiquidity), we utilize Huang (2024) method-\r\nology to assess liquidity indicators for bitcoin futures across three di-\r\nmensions: liquidity depth, resilience, and tightness.16\r\n\r\n16 We thank an anonymous reviewer for suggesting the consideration of\r\ndifferent liquidity indicators such as liquidity depth, tightness, and resilience\r\n(Huang, 2024). Due to space constraint, the estimation results of LRoll\r\nand\r\nLHasbrouck\r\nare not shown here but are available upon request. The estimation\r\nt\r\nresults from these different liquidity indicators are consistent, supporting our\r\nfinding that the BITO introduction strengthens the trading role of asset man-\r\nagers and their increased trading positions improve market liquidity.\r\n\r\nt\r\n\r\n12\r\n\r\n\fY.-L. Chen et al.\r\n\r\nInternational Review of Financial Analysis 97 (2025) 103810\r\n\r\ncoefficients of other traders\u2019 percentage trading positions variables are\r\ninsignificant, except those of dealers, suggesting that dealers\u2019 trading\r\nimproves liquidity in bitcoin futures.\r\n\r\n(2) For volatility, we use one-minute, five-minute, and twenty-\r\nminute futures returns during a week to calculate realized variances.\r\nThese volatility series are highly correlated, as shown in Fig. 2, so we\r\nonly report the analyses of one-minute and five-minute realized vari-\r\nances. We examine the impact of different trading positions on the\r\nvolatility of bitcoin futures by employing the following regression\r\nmodel:\r\n\r\nVj\r\nt\r\n\r\n= \u03b20\r\n\r\n+ \u03b21DBITO\r\n)\r\n\r\nt\r\n\r\n+ \u03b22PTPi\r\n\r\nt\r\n\r\n+ \u03b23\r\n\r\n(cid:0)\r\n\r\nPTPi\r\nt\r\n+ \u03b26Vj\r\n\r\n\u2022 DBITO\r\nt\r\n\r\n+ \u03b24RVIX\r\n\r\nt\r\n\r\n+ \u03b25RSP\r\n\r\nt\r\n\r\n+ ej\r\nt\r\n\r\n,\r\n\r\n(11)\r\n\r\nt(cid:0) 1\r\n\r\nwhere Vj\r\nis the market volatility measure of CME bitcoin futures,\r\nincluding one-minute realized variance (j = 1min, with logarithmic\r\ntransformation) and five-minute realized variance (j = 5min, with log-\r\narithmic transformation). Other factors are the same as those in Eq. (8).\r\nThe estimation results of Eq. (11) are reported in Table 6, which\r\nshows that the coefficients of BITO introduction dummy are all insig-\r\nnificant, and so are the coefficients of percentage trading positions of all\r\ntypes of traders. Only the estimated coefficient of the interaction term of\r\nBITO introduction and dealers\u2019 percentage trading position is signifi-\r\ncantly negative, indicating that dealers may help stabilize bitcoin fu-\r\ntures after the introduction of BITO. Since dealers are large banks,\r\nserving as market makers, the result seems reasonable. However, the\r\nparticipation of dealers in bitcoin futures is still quite low, relative to\r\nother futures markets.\r\n\r\n(3) For price efficiency, we use the pricing error of Hasbrouck (1993)\r\nand variance ratios during a week to measure market efficiency. We\r\nexamine the impact of different trading positions on the price efficiency\r\nof bitcoin futures by employing the following regression model:\r\n(cid:0)\r\n\r\nMEj\r\nt\r\n\r\n= \u03b20\r\n\r\n+ \u03b21DBITO\r\n)\r\n\r\nt\r\n\r\n+ \u03b22PTPi\r\n\r\nt\r\n\r\n+ \u03b23\r\n\r\n\u2022 DBITO\r\nt\r\n\r\n+ \u03b24RVIX\r\n\r\nt\r\n\r\n+ \u03b25RSP\r\n\r\nt\r\n\r\nPTPi\r\nt\r\n+ \u03b26MEj\r\n\r\n+ ej\r\nt\r\n\r\n,\r\n\r\n(12)\r\n\r\nt(cid:0) 1\r\n\r\nwhere MEj are the market efficiency measurements in bitcoin futures,\r\nincluding the pricing error based on Hasbrouck (1993) (j = PE and RPE)\r\nand variance ratios (j = \u22231 (cid:0) VR(n, m)\u2223, times 102). PE is Hasbrouck\u2019s\r\npricing error variance (\u03c32\r\npe), while RPE is the relative pricing error\r\n)\r\n+ \u03c32\r\nm\r\n\r\n, which measures the pricing error variance\r\n\r\ncalculated as \u03c32\r\npe\r\n\r\n(\r\n/\r\n\r\n\u03c32\r\npe\r\n\r\nas a fraction of total price variance. Smaller PE or RPE measure repre-\r\nsents better market efficiency. We discuss Hasbrouck\u2019s pricing error\r\nmethod in detail in Appendix B. Other factors are the same as those in\r\nEq. (8).", "mimetype": "text/plain", "start_char_idx": 67507, "end_char_idx": 71396, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9f35c193-e93d-4ed1-b44d-08ff36ddaf5d": {"__data__": {"id_": "9f35c193-e93d-4ed1-b44d-08ff36ddaf5d", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e5411dac-0ace-4c41-a99e-891d51767b53", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "6e33c20d029b8f7dd55260b116fa138851abd1c90554ed6f59db883875231d4e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "773ae079-133c-45a2-b9c6-9d9799aa8ca8", "node_type": "1", "metadata": {}, "hash": "8bd397f108471f8932ed9d9519710945d5a49984007253d90c51498e7c21a016", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "PE is Hasbrouck\u2019s\r\npricing error variance (\u03c32\r\npe), while RPE is the relative pricing error\r\n)\r\n+ \u03c32\r\nm\r\n\r\n, which measures the pricing error variance\r\n\r\ncalculated as \u03c32\r\npe\r\n\r\n(\r\n/\r\n\r\n\u03c32\r\npe\r\n\r\nas a fraction of total price variance. Smaller PE or RPE measure repre-\r\nsents better market efficiency. We discuss Hasbrouck\u2019s pricing error\r\nmethod in detail in Appendix B. Other factors are the same as those in\r\nEq. (8).\r\n\r\nA random walk implies that the ratio of long-term to short-term re-\r\nturn variances, measured per unit of time, equals 1. We compute |1 (cid:0) VR\r\n(n, m)| for bitcoin futures returns to measure price efficiency, where VR\r\n(n, m) is the ratio of the bitcoin futures return variance over \u201cm\u201d periods\r\nto their return variance over \u201cn\u201d periods, with each divided by the\r\nrespective length of the period. Smaller |1 (cid:0) VR(n, m)| represents better\r\nmarket efficiency. We consider weekly measures based on |1 (cid:0) VR(1,\r\n5)|, |1 (cid:0) VR(1,20)|, and |1 (cid:0) VR(1, 60)| to analyze the price efficiency.\r\nThe estimation results of Eq. (12) are reported in Table 7, which\r\nshows that the coefficients of BITO introduction dummy and those of\r\n\r\n1. Liquidity Depth: This refers to the presence of ample orders on both\r\nsides of the current trading price, reflecting the impact of order flow\r\non prices. We adopt methods from Huang (2024) and Amihud (2002)\r\nto estimate stock illiquidity, measured by the absolute (percentage)\r\nprice change relative to daily trading volume (LAmihud). Additionally,\r\nwe follow Pagano (1989) and Brennan and Subrahmanyam (1995)\r\nby considering average daily trading volume (LVolume) as a measure of\r\nliquidity depth.\r\n\r\nt\r\n\r\n\u221a\r\n\r\n= 2\r\n\r\n\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\r\n(cid:0) COV(\u0394Pt, \u0394Pt(cid:0) 1)\r\n\r\n2. Liquidity Resilience: Liquidity resilience assesses how quickly mar-\r\nkets absorb new orders to correct imbalances, potentially moving\r\nprices away from fundamental values. Following Huang (2024) and\r\nRoll (1984), we calculate resilience through the covariance of suc-\r\ncessive daily returns: LRoll\r\n, where \u201cCOV\u201d is\r\nthe first-order serial covariance of price changes in bitcoin futures.\r\n3. Liquidity Tightness: Tightness in liquidity measures transaction\r\ncosts, such as bid-ask spread and implicit cost. Huang (2024) uses the\r\nrelative bid-ask spread as a proxy for liquidity tightness, which\r\nmeasures market liquidity based on the ratio of the bid-ask spread to\r\nthe average price. Due to unavailability of intra-day bid and ask\r\nquotes data, we use the Gibbs estimate of bid\u2013ask spread (Hasbrouck,\r\n2004) to proxy the bid-ask spread for the bitcoin futures (LHasbrouck\r\n),\r\nfollowing Chen and Yang (2024). Hasbrouck proposes the technique\r\nto examine the bid\u2013ask spread based on Markov chain Monte Carlo\r\nestimation to deal with the absence of bid and ask quotes and, pro-\r\nvides a detailed introduction of the method of the Gibbs estimate.\r\n\r\nt\r\n\r\n=\r\n\r\n\u20d2\r\n\u20d2\r\nRB\r\nt\r\n\r\nThe weekly Amihud illiquidity measure is defined as follows:\r\n\u20d2\r\n\u20d2/Volumet, where RB and Volume represent the weekly re-\r\nLAmihud\r\nt\r\nturn and trading volume in bitcoin futures, respectively. For average\r\ntrading volume, LVolume\r\nrepresents the average value in daily trading\r\nvolume during week t. Following Eqs.", "mimetype": "text/plain", "start_char_idx": 70977, "end_char_idx": 74238, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "773ae079-133c-45a2-b9c6-9d9799aa8ca8": {"__data__": {"id_": "773ae079-133c-45a2-b9c6-9d9799aa8ca8", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9f35c193-e93d-4ed1-b44d-08ff36ddaf5d", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "c1bca3ae8568000082118b2325cbb3534e7e9f45581648fa3504097e192ef36f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "329712ee-34d4-40e5-9b3e-8d3ff7d3c4a5", "node_type": "1", "metadata": {}, "hash": "e53b955e2a669708be27957ca477293401b592341e957febbcf43906eb7f954f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Hasbrouck proposes the technique\r\nto examine the bid\u2013ask spread based on Markov chain Monte Carlo\r\nestimation to deal with the absence of bid and ask quotes and, pro-\r\nvides a detailed introduction of the method of the Gibbs estimate.\r\n\r\nt\r\n\r\n=\r\n\r\n\u20d2\r\n\u20d2\r\nRB\r\nt\r\n\r\nThe weekly Amihud illiquidity measure is defined as follows:\r\n\u20d2\r\n\u20d2/Volumet, where RB and Volume represent the weekly re-\r\nLAmihud\r\nt\r\nturn and trading volume in bitcoin futures, respectively. For average\r\ntrading volume, LVolume\r\nrepresents the average value in daily trading\r\nvolume during week t. Following Eqs. (8) and (9), we examine the\r\nimpact of different trading positions on bitcoin futures\u2019 market liquidity\r\nand employ the following regression model:\r\n\r\nt\r\n\r\nLj\r\nt\r\n\r\n= \u03b20\r\n\r\n+ \u03b21DBITO\r\n)\r\n\r\nt\r\n\r\n+ \u03b22PTPi\r\n\r\nt\r\n\r\n+ \u03b23\r\n\r\n(cid:0)\r\n\r\nPTPi\r\nt\r\n+ \u03b26Lj\r\n\r\n\u2022 DBITO\r\nt\r\n\r\n+ \u03b24RVIX\r\n\r\nt\r\n\r\n+ \u03b25RSP\r\n\r\nt\r\n\r\n+ ej\r\nt\r\n\r\n,\r\n\r\n(10)\r\n\r\nt(cid:0) 1\r\n\r\nwhere Lj represents the market liquidity measure of bitcoin futures,\r\nincluding Amihud\u2019s illquidity (j = Amihud, times 105) and average\r\ntrading volume (j = Volume, divided by 104). Other factors are the same\r\nas those in Eq. (8), except PTPi, which refers to the percentage trading\r\npositions held by type i traders. We consider PTPi, instead of NTPi, to\r\nexamine the effect of trading activities on market liquidity because PTPi\r\ndoes not depend on the trading direction of long or short. The per-\r\ncentage trading positions among different types of traders may exist a\r\nhigh correlation, so we avoid the collinearity issue by considering PTPi\r\nfor each type i separately in the Eq. (10).\r\n\r\nt\r\n\r\nThe estimation results of Eq. (10) are reported in Table 5, which\r\nshows that the coefficients of BITO introduction dummy on Amihud\u2019s\r\nilliquidity measure (LAmihud\r\n) are all significantly negative, suggesting\r\nthat the BITO introduction reduces market illiquidity in bitcoin futures.\r\nIn addition, the coefficients of BITO introduction dummy on LVolume\r\nare\r\nall positive, although two of them are not significant. These results\r\nindicate that the market liquidity in the bitcoin futures improves after\r\nthe BITO introduction.\r\n\r\nt\r\n\r\nOn the other side, the estimated coefficient of percentage trading\r\npositions of asset managers on Amihud\u2019s illiquidity measure is insig-\r\nnificantly positive, but the estimated coefficient of the interaction term\r\nof BITO introduction and their trading percentage is significantly\r\nnegative. In addition, the coefficient of the interaction term of BITO\r\nintroduction and asset managers\u2019 percentage trading positions on\r\ntrading volume is significantly positive. These results suggest that the\r\nBITO introduction strengthens the trading role of asset managers and\r\ntheir increased trading positions improve market liquidity. Finally, the\r\n\r\n13\r\n\r\n\fY.-L. Chen et al.\r\n\r\nInternational Review of Financial Analysis 97 (2025) 103810\r\n\r\n(cid:0)\r\n\r\n)\r\n\r\nPTPi\r\nt\r\n\r\n+ \u03b23\r\n\r\n\u2022 DBITO\r\nt\r\n\r\n+ \u03b22PTPi\r\nt\r\n\r\nTable 6\r\nMarket volatility and trading positions in the CME bitcoin futures.\r\nThis table shows results from individual regressions of bitcoin futures market volatility on its factors and reports the estimations of the following model: Vj\r\n\u03b21DBITO\r\nt, where Vj are the market volatility measurements of CME bitcoin futures include one-minute\r\nt\r\nrealized variance (j = 1min, with logarithmic transformation) and five-minute realized variance(j = 5min, with logarithmic transformation). DBITOrepresent the\r\nBITO introduction dummy which equals to one after the introduction of BITO ETF and zero otherwise. PTPi, which refer to the percentage trading positions held by\r\ntype i traders, where i = AS, DE, LE, OT, and NO, which respectively refer to (1) asset managers, (2) dealers, (3) leveraged funds, (4) other-reportable traders, and (5)\r\nnon-reportable traders. PTPi\r\nt\r\nis the market\u2019s total open interest, and Spreadingi\r\nvariables are estimated but not tabulated. ***, **, and * indicate significant at the 1 %, 5 %, and 10 % levels, respectively.", "mimetype": "text/plain", "start_char_idx": 73662, "end_char_idx": 77654, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "329712ee-34d4-40e5-9b3e-8d3ff7d3c4a5": {"__data__": {"id_": "329712ee-34d4-40e5-9b3e-8d3ff7d3c4a5", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "773ae079-133c-45a2-b9c6-9d9799aa8ca8", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "7895d2f233342e81ee1b692f72ea0faa9c4e822e8ab29914d5ce964c451375e1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "356ed351-a55d-4634-9808-d78e3d9d6722", "node_type": "1", "metadata": {}, "hash": "1dba4dd352d8f1573baedd9eb9ba528087743842fa6cdbe3b73b109f8d0f9564", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "DBITOrepresent the\r\nBITO introduction dummy which equals to one after the introduction of BITO ETF and zero otherwise. PTPi, which refer to the percentage trading positions held by\r\ntype i traders, where i = AS, DE, LE, OT, and NO, which respectively refer to (1) asset managers, (2) dealers, (3) leveraged funds, (4) other-reportable traders, and (5)\r\nnon-reportable traders. PTPi\r\nt\r\nis the market\u2019s total open interest, and Spreadingi\r\nvariables are estimated but not tabulated. ***, **, and * indicate significant at the 1 %, 5 %, and 10 % levels, respectively.\r\n\r\nt measures the extent to which type i traders holds equal long and short futures positions. Coefficients on control\r\n\r\nt refer to the long and short positions held by type i traders on t, MTOIt\r\n\r\n)\r\n/MTOIt, where Longi\r\n\r\n+ 2 \u2022 Spreadingi\r\nt\r\n\r\n(\r\nLongi\r\nt\r\n\r\nt and Shorti\r\n\r\n+ \u03b24RVIX\r\n\r\n+ Shorti\r\nt\r\n\r\n+ \u03b25RSP\r\nt\r\n\r\n+ \u03b26Vj\r\n\r\nt = \u03b20\r\n\r\n+ ej\r\n\r\nt(cid:0) 1\r\n\r\n=\r\n\r\n+\r\n\r\nt\r\n\r\nVariable\r\n\r\nIntercept\r\n\r\nDBITO\r\n\r\nPTPDE\r\n\r\nPTPDE \u2022 DBITO\r\n\r\nAdj.R2\r\n\r\nVariable\r\nIntercept\r\n\r\nDBITO\r\n\r\nPTPOT\r\n\r\nPTPOT \u2022 DBITO\r\n\r\nAdj.R2\r\n\r\n(2) Dealers\r\n\r\nV1min\r\n\r\n(cid:0) 15.32***\r\n(0.91)\r\n0.45\r\n(0.31)\r\n0.05\r\n(0.05)\r\n(cid:0) 0.12**\r\n(0.05)\r\n\r\n0.44\r\n\r\n(4) Other-reportable traders\r\nV1min\r\n(cid:0) 15.20***\r\n(0.77)\r\n(cid:0) 1.28**\r\n(0.60)\r\n(cid:0) 0.02\r\n(0.01)\r\n0.08**\r\n(0.04)\r\n0.45\r\n\r\nV5min\r\n\r\n(cid:0) 13.57***\r\n(0.94)\r\n0.51\r\n(0.31)\r\n0.06\r\n(0.05)\r\n(cid:0) 0.14**\r\n(0.05)\r\n\r\n0.38\r\n\r\nV5min\r\n(cid:0) 13.41***\r\n(0.80)\r\n1.32**\r\n(0.64)\r\n(cid:0) 0.02\r\n(0.01)\r\n0.08**\r\n(0.04)\r\n0.38\r\n\r\nVariable\r\n\r\nIntercept\r\n\r\nDBITO\r\n\r\nPTPAS\r\n\r\nPTPAS \u2022 DBITO\r\n\r\nAdj.R2\r\n\r\nVariable\r\nIntercept\r\n\r\nDBITO\r\n\r\nPTPLE\r\n\r\nPTPLE \u2022 DBITO\r\n\r\nAdj.R2\r\n\r\nVariable\r\nIntercept\r\n\r\nDBITO\r\n\r\nPTPNO\r\n\r\nPTPNO \u2022 DBITO\r\n\r\nAdj.R2\r\n\r\n(1) Asset managers\r\n\r\nV1min\r\n\r\n(cid:0) 13.55***\r\n(0.80)\r\n0.01\r\n(0.72)\r\n(cid:0) 0.03\r\n(0.04)\r\n0.02\r\n(0.05)\r\n\r\n0.44\r\n\r\n(3) Leveraged funds\r\nV1min\r\n(cid:0) 16.15***\r\n(1.28)\r\n1.21\r\n(0.94)\r\n0.01\r\n(0.01)\r\n(cid:0) 0.02\r\n(0.01)\r\n0.44\r\n\r\n(5) Non-reportable traders\r\nV1min\r\n(cid:0) 15.40***\r\n(0.86)\r\n(cid:0) 0.53\r\n(0.66)\r\n0.01\r\n(0.02)\r\n0.03\r\n(0.05)\r\n0.43\r\n\r\nV5min\r\n\r\n(cid:0) 13.55***\r\n(0.80)\r\n0.01\r\n(0.72)\r\n(cid:0) 0.03\r\n(0.04)\r\n0.02\r\n(0.05)\r\n\r\n0.37\r\n\r\nV5min\r\n(cid:0) 14.25***\r\n(1.12)\r\n1.07\r\n(1.71)\r\n0.01\r\n(0.01)\r\n(cid:0) 0.02\r\n(0.03)\r\n0.38\r\n\r\nV5min\r\n(cid:0) 13.80***\r\n(0.91)\r\n(cid:0) 0.40\r\n(0.69)\r\n0.01\r\n(0.02)\r\n0.02\r\n(0.05)\r\n0.38\r\n\r\npercentage trading positions are mostly insignificant.", "mimetype": "text/plain", "start_char_idx": 77089, "end_char_idx": 79493, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "356ed351-a55d-4634-9808-d78e3d9d6722": {"__data__": {"id_": "356ed351-a55d-4634-9808-d78e3d9d6722", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "329712ee-34d4-40e5-9b3e-8d3ff7d3c4a5", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "038002f14a77ba7f220e000bb3015312ecb5e19e46bbaff304ad9afddcfe4b55", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c61c661f-ac4d-4b01-ac47-3b80110b890b", "node_type": "1", "metadata": {}, "hash": "74af58e19739f345eacc5abfc6303fe521207fb90ce3218184fb9006372d9dbf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Only the esti-\r\nmated coefficient of the interaction term of BITO introduction and\r\ndealers\u2019 percentage trading position is significantly negative, suggesting\r\nthat dealers may reduce the pricing errors of bitcoin futures after the\r\nBITO introduction. To the extent that low pricing errors may reduce\r\ntransitory volatility, this result is in line with the earlier finding that\r\ndealers may help reduce the volatility of bitcoin futures. In sum, we do\r\nnot find any evidence that the BITO introduction affects the efficiency\r\nand volatility in bitcoin futures, but dealers\u2019 trading after the BITO\r\nintroduction may reduce market volatility and enhance market\r\nefficiency.17\r\n\r\n17 We thank an anonymous reviewer for highlighting the excess kurtosis of the\r\ndata and suggesting the consideration of quantile regression analyses. Due to\r\nspace constraints, the estimation results of the quantile regression analyses are\r\nnot shown here but are available upon request. The results from these analyses\r\nconsistently support that the introduction of BITO strengthens the trading role\r\nof asset managers and their increased trading positions improve market\r\nliquidity. Additionally, the introduction of BITO does not affect the efficiency\r\nand volatility of bitcoin futures.\r\n\r\n14\r\n\r\n7. Market quality in CME bitcoin futures around the BITO\r\nintroduction\r\n\r\nTo better understand the impact of BITO introduction, we further\r\nanalyze the liquidity, volatility, and price efficiency in bitcoin futures at\r\na daily frequency around the BITO introduction day. This analysis can\r\nprovide additional insights because about $1.2 billion flowed into BITO\r\nduring its first three days on the market. Since the TFF report does not\r\nprovide daily or higher frequency data on traders\u2019 positions, our ana-\r\nlyses in Section 5 may be more relevant to the impact of medium- to\r\nlong-term trading on market quality in bitcoin futures. Now, we focus on\r\nshort-term liquidity, volatility, informed trading, and price efficiency in\r\nbitcoin futures immediately before and after the BITO introduction\r\nwithout considering trader positions.\r\n\r\nAnalyzing liquidity, volatility, and price efficiency in bitcoin futures\r\naround the BITO introduction day can provide a rather clean result that\r\ncan be attributed mainly to the BITO introduction and less to other\r\nmarket disturbances. In addition, we use order imbalance and absolute\r\nvalue in order imbalance to measure informed trading and asymmetric\r\ninformation (Chordia et al., 2002 Bernile et al., 2016). We plot the\r\nliquidity, volatility, and price efficiency measures in bitcoin futures on a\r\ndaily basis surrounding the BITO introduction day in Fig. 7. We find that\r\n\r\n\fY.-L. Chen et al.\r\n\r\nInternational Review of Financial Analysis 97 (2025) 103810\r\n\r\nTable 7\r\nMarket efficiency and trading positions in the CME bitcoin futures.\r\nThis table shows results from individual regressions of bitcoin futures market efficiency on its factors and reports the estimations of the following model: MEj\r\n\u03b21DBITO\r\nt\r\nbased on Hasbrouck (1993) (j = PE and RPE) and variance ratios (j = |1 (cid:0) VR[n, m] |, times 102). PE measurement is Hasbrouck\u2019s pricing error variance (\u03c32\r\n\r\n+\r\nt, where MEj are the market efficiency measurements of CME bitcoin futures include pricing error\r\npe) and RPE is\r\n\r\n+ \u03b22PTPi\r\nt\r\n\r\n+ \u03b26MEj\r\n\r\n+ \u03b24RVIX\r\n\r\n+ \u03b25RSP\r\nt\r\n\r\n\u2022 DBITO\r\nt\r\n\r\nt = \u03b20\r\n\r\nPTPi\r\nt\r\n\r\n+ \u03b23\r\n\r\n+ ej\r\n\r\nt(cid:0) 1\r\n\r\n)\r\n\r\n(cid:0)\r\n\r\nt\r\n\r\nthe relative pricing error is calculated as \u03c32\r\npe\r\n\r\n\u03c32\r\npe\r\n\r\n+ \u03c32\r\nm\r\n\r\n, which is the relative mispricing measurement, examined by the pricing error variance as a fraction of total\r\n\r\nprice variance. DBITOrepresent the BITO introduction dummy which equals to one after the introduction of BITO ETF and zero otherwise. PTPi, which refer to the\r\npercentage trading positions held by type i traders, where i = AS, DE, LE, OT, and NO, which respectively refer to (1) asset managers, (2) dealers, (3) leveraged funds,\r\n+ Shorti\r\n(4) other-reportable traders, and (5) non-reportable traders. PTPi\r\nt\r\nt\r\npositions held by type i traders on t, MTOIt is the market\u2019s total open interest, and Spreadingi\r\nt measures the extent to which type i traders holds equal long and short\r\nfutures positions.", "mimetype": "text/plain", "start_char_idx": 79494, "end_char_idx": 83739, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c61c661f-ac4d-4b01-ac47-3b80110b890b": {"__data__": {"id_": "c61c661f-ac4d-4b01-ac47-3b80110b890b", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "356ed351-a55d-4634-9808-d78e3d9d6722", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "2d3f9e4ba46b0db8108f82ea5f7a5b1f3496d18c18ea0de90290a29d702a05e3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a2479684-4814-470c-9420-c20402220582", "node_type": "1", "metadata": {}, "hash": "8e317daa92da19e433e822f94eb423a74db35d359d3987b39b61697b538b8680", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "DBITOrepresent the BITO introduction dummy which equals to one after the introduction of BITO ETF and zero otherwise. PTPi, which refer to the\r\npercentage trading positions held by type i traders, where i = AS, DE, LE, OT, and NO, which respectively refer to (1) asset managers, (2) dealers, (3) leveraged funds,\r\n+ Shorti\r\n(4) other-reportable traders, and (5) non-reportable traders. PTPi\r\nt\r\nt\r\npositions held by type i traders on t, MTOIt is the market\u2019s total open interest, and Spreadingi\r\nt measures the extent to which type i traders holds equal long and short\r\nfutures positions. Coefficients on control variables are estimated but not tabulated. ***, **, and * indicate significant at the 1 %, 5 %, and 10 % levels, respectively.\r\n\r\n)\r\n/MTOIt, where Longi\r\n\r\nt refer to the long and short\r\n\r\n+ 2 \u2022 Spreadingi\r\nt\r\n\r\nt and Shorti\r\n\r\n(\r\nLongi\r\nt\r\n\r\n=\r\n\r\n(\r\n/\r\n\r\n)\r\n\r\nVariable\r\n\r\nPricing errors\r\n\r\nMEPE\r\n\r\n(1) Percentage trading positions of asset managers\r\nIntercept\r\n\r\n(2) Percentage trading positions of dealers\r\nIntercept\r\n\r\n(3) Percentage trading positions of leveraged funds\r\nIntercept\r\n\r\n(4) Percentage trading positions of other reportable traders\r\nIntercept\r\n\r\n(5) Percentage trading positions of non-reportable traders\r\nIntercept\r\n\r\nDBITO\r\n\r\nPTPAS\r\n\r\nPTPAS \u2022 DBITO\r\n\r\nAdj.R2\r\n\r\nDBITO\r\n\r\nPTPDE\r\n\r\nPTPDE \u2022 DBITO\r\n\r\nAdj.R2\r\n\r\nDBITO\r\n\r\nPTPLE\r\n\r\nPTPLE \u2022 DBITO\r\n\r\nAdj.R2\r\n\r\nDBITO\r\n\r\nPTPOT\r\n\r\nPTPOT \u2022 DBITO\r\n\r\nAdj.R2\r\n\r\nDBITO\r\n\r\nPTPNO\r\n\r\nPTPNO \u2022 DBITO\r\n\r\nAdj.R2\r\n\r\n(cid:0) 17.46***\r\n(0.29)\r\n(cid:0) 1.99\r\n(9.01)\r\n0.15\r\n(0.50)\r\n(cid:0) 0.19\r\n(0.58)\r\n0.08\r\n\r\n(cid:0) 17.58***\r\n(0.17)\r\n(cid:0) 0.19\r\n(0.67)\r\n0.11*\r\n(0.06)\r\n(cid:0) 0.18*\r\n(0.11)\r\n0.08\r\n\r\n(cid:0) 18.01***\r\n(1.03)\r\n(cid:0) 1.11\r\n(2.80)\r\n(cid:0) 0.01\r\n(0.01)\r\n(cid:0) 0.03\r\n(0.06)\r\n0.08\r\n\r\n(cid:0) 16.31***\r\n(0.46)\r\n(cid:0) 3.06***\r\n(0.92)\r\n(cid:0) 0.06**\r\n(0.02)\r\n0.19\r\n(0.17)\r\n0.11\r\n\r\n(cid:0) 17.57***\r\n(0.51)\r\n(cid:0) 0.88\r\n(0.88)\r\n(cid:0) 0.01\r\n(0.02)\r\n0.05\r\n(0.07)\r\n0.08\r\n\r\nMERPE\r\n\r\n(cid:0) 3.73***\r\n(0.21)\r\n(cid:0) 0.31\r\n(0.52)\r\n0.02\r\n(0.04)\r\n(cid:0) 0.04\r\n(0.05)\r\n0.06\r\n\r\n(cid:0) 3.63***\r\n(0.14)\r\n(cid:0) 0.42\r\n(0.56)\r\n0.01\r\n(0.05)\r\n(cid:0) 0.01\r\n(0.09)\r\n0.06\r\n\r\n(cid:0) 2.90**\r\n(1.11)\r\n(cid:0) 0.55\r\n(2.36)\r\n(cid:0) 0.01\r\n(0.01)\r\n(cid:0) 0.02\r\n(0.02)\r\n0.07\r\n\r\n(cid:0) 2.06***\r\n(0.78)\r\n(cid:0) 1.53*\r\n(0.81)\r\n(cid:0) 0.03\r\n(0.02)\r\n0.08\r\n(0.06)\r\n0.08\r\n\r\n(cid:0) 2.21**\r\n(0.97)\r\n(cid:0) 0.59\r\n(0.72)\r\n(cid:0) 0.01\r\n(0.02)\r\n0.02\r\n(0.06)\r\n0.", "mimetype": "text/plain", "start_char_idx": 83151, "end_char_idx": 85565, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a2479684-4814-470c-9420-c20402220582": {"__data__": {"id_": "a2479684-4814-470c-9420-c20402220582", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c61c661f-ac4d-4b01-ac47-3b80110b890b", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "03a06029dab9b28a50f800fbc18954623b943a822081779e0577855a618544e0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9d451dcf-3b3d-47ac-9929-82d912828895", "node_type": "1", "metadata": {}, "hash": "18b7d65a77c996869206fcb6936e6a3316352a694ef7f0158c7c86c233bff0e7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "56)\r\n0.01\r\n(0.05)\r\n(cid:0) 0.01\r\n(0.09)\r\n0.06\r\n\r\n(cid:0) 2.90**\r\n(1.11)\r\n(cid:0) 0.55\r\n(2.36)\r\n(cid:0) 0.01\r\n(0.01)\r\n(cid:0) 0.02\r\n(0.02)\r\n0.07\r\n\r\n(cid:0) 2.06***\r\n(0.78)\r\n(cid:0) 1.53*\r\n(0.81)\r\n(cid:0) 0.03\r\n(0.02)\r\n0.08\r\n(0.06)\r\n0.08\r\n\r\n(cid:0) 2.21**\r\n(0.97)\r\n(cid:0) 0.59\r\n(0.72)\r\n(cid:0) 0.01\r\n(0.02)\r\n0.02\r\n(0.06)\r\n0.08\r\n\r\nVariance ratios\r\n\r\n|1(cid:0) VR(1,5|)\r\n\r\nME\r\n\r\n|1(cid:0) VR(1,20) |\r\n\r\nME\r\n\r\n|1(cid:0) VR(1,60) |\r\n\r\nME\r\n\r\n12.31***\r\n(2.61)\r\n(cid:0) 0.07\r\n(9.79)\r\n0.80\r\n(0.55)\r\n(cid:0) 0.77\r\n(0.64)\r\n0.04\r\n\r\n16.21***\r\n(1.52)\r\n(cid:0) 0.33\r\n(5.99)\r\n(cid:0) 0.25\r\n(0.60)\r\n(cid:0) 0.19\r\n(0.99)\r\n0.04\r\n\r\n22.54**\r\n(8.98)\r\n(cid:0) 28.63\r\n(25.50)\r\n(cid:0) 0.11\r\n(0.15)\r\n0.53\r\n(0.55)\r\n0.04\r\n\r\n19.59***\r\n(4.30)\r\n(cid:0) 1.63\r\n(8.63)\r\n(cid:0) 0.23\r\n(0.25)\r\n0.23\r\n(0.70)\r\n0.04\r\n\r\n9.11**\r\n(4.35)\r\n3.41\r\n(7.73)\r\n0.34\r\n(0.22)\r\n(cid:0) 0.31\r\n(0.70)\r\n0.05\r\n\r\n20.62***\r\n(2.93)\r\n(cid:0) 1.85\r\n(11.09)\r\n0.16\r\n(0.62)\r\n(cid:0) 0.05\r\n(0.72)\r\n0.03\r\n\r\n20.39***\r\n(1.72)\r\n(cid:0) 4.14\r\n(6.77)\r\n(cid:0) 0.25\r\n(0.68)\r\n0.29\r\n(1.13)\r\n0.03\r\n\r\n10.95\r\n(10.21)\r\n(cid:0) 11.41\r\n(29.19)\r\n(cid:0) 0.15\r\n(0.17)\r\n0.22\r\n(0.63)\r\n0.04\r\n\r\n26.69***\r\n(4.86)\r\n(cid:0) 7.57\r\n(9.84)\r\n(cid:0) 0.41\r\n(0.28)\r\n0.17\r\n(0.80)\r\n0.04\r\n\r\n18.82***\r\n(5.02)\r\n6.94\r\n(8.91)\r\n0.05\r\n(0.25)\r\n0.45\r\n(0.81)\r\n0.03\r\n\r\n7.47***\r\n(1.92)\r\n(cid:0) 0.99\r\n(7.31)\r\n0.58\r\n(0.48)\r\n(cid:0) 0.57\r\n(0.49)\r\n0.04\r\n\r\n11.22***\r\n(1.09)\r\n(cid:0) 4.63\r\n(4.35)\r\n(cid:0) 0.65\r\n(0.43)\r\n0.71\r\n(0.72)\r\n0.04\r\n\r\n13.44**\r\n(6.65)\r\n(cid:0) 5.71\r\n(19.36)\r\n(cid:0) 0.05\r\n(0.11)\r\n0.04\r\n(0.42)\r\n0.03\r\n\r\n13.03***\r\n(3.18)\r\n(cid:0) 5.67\r\n(6.51)\r\n(cid:0) 0.18\r\n(0.18)\r\n0.14\r\n(0.53)\r\n0.03\r\n\r\n4.70\r\n(3.19)\r\n2.88\r\n(5.72)\r\n0.27*\r\n(0.", "mimetype": "text/plain", "start_char_idx": 85242, "end_char_idx": 86875, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9d451dcf-3b3d-47ac-9929-82d912828895": {"__data__": {"id_": "9d451dcf-3b3d-47ac-9929-82d912828895", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a2479684-4814-470c-9420-c20402220582", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "57eb05c04fdc1c35b961ae41737bc8c7f3e4e2012d2135161cbc3c848ae203f9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "200a6b73-4e93-4166-8e90-a9fe08eed9d5", "node_type": "1", "metadata": {}, "hash": "518e8ba1d0f2195ad57bbcc765f9533e6f07fa11430eaa2a3d85a573f9a982b8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "48)\r\n(cid:0) 0.57\r\n(0.49)\r\n0.04\r\n\r\n11.22***\r\n(1.09)\r\n(cid:0) 4.63\r\n(4.35)\r\n(cid:0) 0.65\r\n(0.43)\r\n0.71\r\n(0.72)\r\n0.04\r\n\r\n13.44**\r\n(6.65)\r\n(cid:0) 5.71\r\n(19.36)\r\n(cid:0) 0.05\r\n(0.11)\r\n0.04\r\n(0.42)\r\n0.03\r\n\r\n13.03***\r\n(3.18)\r\n(cid:0) 5.67\r\n(6.51)\r\n(cid:0) 0.18\r\n(0.18)\r\n0.14\r\n(0.53)\r\n0.03\r\n\r\n4.70\r\n(3.19)\r\n2.88\r\n(5.72)\r\n0.27*\r\n(0.16)\r\n(cid:0) 0.34\r\n(0.52)\r\n0.04\r\n\r\n15\r\n\r\n\fY.-L. Chen et al.\r\n\r\nInternational Review of Financial Analysis 97 (2025) 103810\r\n\r\nFig. 7. Short-term liquidity, volatility, informed trading, and price efficiency in bitcoin futures around BITO introduction.\r\nNote: Means refer to the average values of the variables in five days before and after BITO introduction. The dashed vertical line indicates the introduction day of\r\nBITO (10/19/2021).\r\n\r\nAmihud\u2019s illiquidity falls from 0.44 to 0.37, while trading volume rises\r\nfrom 7782.6 to 10,711.4 from the pre-introduction to the post-\r\nintroduction days. These results suggest that the BITO introduction\r\nimproves short-term liquidity in the bitcoin futures market.\r\n\r\nIn addition, we find that the two daily price efficiency measures, PE\r\nand RPE, jump on the BITO introduction day and then revert back to the\r\nprevious level on the fourth day of the BITO introduction. However,\r\ninformed trading and the level of asymmetric information do not seem to\r\nchange after the BITO introduction.\r\n\r\n8. Conclusions\r\n\r\nIn this study, we investigate the introduction effect of bitcoin futures-\r\nbased ETF (BITO) on investor structure and market quality in bitcoin\r\nfutures. We adopt the TFF report to categorize major traders into\r\ndealers, asset managers, leveraged fund managers, and other reportable\r\ntraders in bitcoin futures. Our results indicate that the BITO introduction\r\nsignificantly changes the investor structure in bitcoin futures and ETF\r\nasset managers become the major long-side participants against the\r\n\r\nshort-side hedge funds. Further, market participants in bitcoin futures\r\nbecome more concentrated. However, these changes in investor struc-\r\nture does not impair futures market quality as the market liquidity of\r\nbitcoin futures improves after the BITO introduction while efficiency\r\nand volatility do not seem to be affected significantly. In contrast, for\r\nshort-term shock from the BITO introduction, we find that fund inflow of\r\nBITO improves the liquidity in bitcoin futures during the first five days\r\nof BITO introduction but hurts futures\u2019 price efficiency on the first three\r\ndays of BITO introduction before reverting back to the previous level.\r\n\r\nOur findings provide several policy implications that could be\r\nconsidered by policymakers. First, we recommend supporting the crea-\r\ntion of bitcoin futures-based ETFs because our research shows that they\r\ndo not destabilize or negatively impact the corresponding bitcoin futures\r\nprices. Instead, they enhance market liquidity over the medium to long\r\nterm. This finding may be further validated by the introduction of the\r\nsecond and third bitcoin futures ETFs, the Valkyrie Bitcoin Strategy ETF\r\n(BTF) and the VanEck Bitcoin Strategy ETF (XBTF). Second, our study\r\nhighlights the unique market concentration in bitcoin futures, which\r\nsignificantly differs from the investor structure in other futures markets.\r\n\r\n16\r\n\r\n\fY.-L. Chen et al.\r\n\r\nInternational Review of Financial Analysis 97 (2025) 103810\r\n\r\nLarge banks, or dealers, have relatively low participation in bitcoin fu-\r\ntures, yet their involvement is crucial as they play a positive role in\r\nreducing volatility and enhancing market efficiency. Therefore, policy-\r\nmakers may consider strategies to encourage greater dealer participa-\r\ntion in bitcoin futures to further improve futures market quality.\r\n\r\nWe anticipate that the introduction of bitcoin spot ETFs on January\r\n11, 2024 will influence trading in bitcoin spot, bitcoin futures, and\r\nBITO.", "mimetype": "text/plain", "start_char_idx": 86550, "end_char_idx": 90409, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "200a6b73-4e93-4166-8e90-a9fe08eed9d5": {"__data__": {"id_": "200a6b73-4e93-4166-8e90-a9fe08eed9d5", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9d451dcf-3b3d-47ac-9929-82d912828895", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "aa24fce2324982e286604b8fdd69f1a348b1fdb184611819c244eb689961ca4b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "32a8ce53-0e3e-4f8a-85eb-90a089c13a76", "node_type": "1", "metadata": {}, "hash": "cee94fcc09e29f4b8179c3cd358e9686c143ccedfbd40234f934679f2e35d61f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This finding may be further validated by the introduction of the\r\nsecond and third bitcoin futures ETFs, the Valkyrie Bitcoin Strategy ETF\r\n(BTF) and the VanEck Bitcoin Strategy ETF (XBTF). Second, our study\r\nhighlights the unique market concentration in bitcoin futures, which\r\nsignificantly differs from the investor structure in other futures markets.\r\n\r\n16\r\n\r\n\fY.-L. Chen et al.\r\n\r\nInternational Review of Financial Analysis 97 (2025) 103810\r\n\r\nLarge banks, or dealers, have relatively low participation in bitcoin fu-\r\ntures, yet their involvement is crucial as they play a positive role in\r\nreducing volatility and enhancing market efficiency. Therefore, policy-\r\nmakers may consider strategies to encourage greater dealer participa-\r\ntion in bitcoin futures to further improve futures market quality.\r\n\r\nWe anticipate that the introduction of bitcoin spot ETFs on January\r\n11, 2024 will influence trading in bitcoin spot, bitcoin futures, and\r\nBITO. Due to the short sample period and thus limited data for con-\r\nducting empirical analyses in this stage, we do not consider the impact of\r\nbitcoin spot ETFs. We recommend that future studies expand our\r\nempirical analyses to investigate the impact of bitcoin spot ETFs on\r\n\r\nmarket quality in bitcoin futures.\r\n\r\nData availability\r\n\r\nThe authors do not have permission to share data.\r\n\r\nAcknowledgments\r\n\r\nYu-Lun Chen acknowledges financial support from the Ministry of\r\nScience and Technology, Taiwan (R.O.C.) (MOST 111\u20132410-H-033-038-\r\nMY3).\r\n\r\nAppendix A\r\n\r\nCME bitcoin futures- contract specifications.\r\n\r\n1. CONTRACT UNIT\r\n\r\n2. PRICE QUOTATION\r\n3. SETTLEMENT METHOD\r\n4. TERMINATION OF\r\nTRADING\r\n5. TRADING HOURS\r\n6. LISTED CONTRACTS\r\n\r\n5 bitcoin, as defined by the CME CF Bitcoin Reference Rate (BRR) BRR is a once a day benchmark index price for bitcoin that aggregates trade data\r\nfrom multiple bitcoin-USD markets operated by major cryptocurrency exchanges.\r\nU.S. dollars and cents per bitcoin\r\nCash Settled\r\nTrading terminates at 4:00 p.m. London time on the last Friday of the contract month that is either a London or U.S. business day. If the last Friday of\r\nthe contract month is not a business day in both London and the U.S., trading terminates on the prior London or U.S. business day.\r\nCME Globex: Sunday - Friday 5:00 p.m. - 4:00 p.m./CT with a 60-min break each day beginning at 4:00 p.m. CT\r\nMonthly contracts listed for 6 consecutive months, quarterly contracts (Mar, Jun, Sep, Dec) listed for 4 additional quarters and a second Dec contract if\r\nonly one is listed\r\n\r\nSource: https://www.cmegroup.com/\r\n\r\nAppendix B\r\n\r\nWe illustrate Hasbrouck (1993) pricing error method here. According to studies of Hasbrouck (1993) and Chen and Xu (2021), asset transaction\r\nprice can be decomposed into a random-walk component and a stationary component. The random-walk component is identified with the efficient\r\nprice and the stationary component represents the difference between efficient price and the transaction price (i.e. pricing error). Hasbrouck proposes\r\nthat pricing error (i.e., the deviation of observed transaction prices from unobserved efficient prices) offers an alternative measure of the implicit\r\ntransaction costs incurred by traders and the variance of the pricing error determines how closely actual transaction prices track the efficient price.\r\nTo measure the variance of the pricing error in Hasbrouck (1993), we estimate the following vector autoregression (VAR) of bitcoin futures price\r\n\r\nchanges and trades first as follows:\r\nrt = a0 + a1rt(cid:0) 1 + a2rt(cid:0) 2 + \u22ef + b1xt(cid:0) 1 + b2xt(cid:0) 2 + \u22ef + v1,t\r\nxt = c0 + c1rt(cid:0) 1 + c2rt(cid:0) 2 + \u22ef + d1xt(cid:0) 1 + d2xt(cid:0) 2 + \u22ef + v2,t\r\n\r\n,\r\n\r\n(B1)\r\n\r\nwhere rt and xt are the log-price changes and trades (according to the tick rule, we classify a buy order as 1 and a sell order as 1). v1,t and v2,t are the\r\nzero mean and serially uncorrelated disturbances. The VAR in Eq.", "mimetype": "text/plain", "start_char_idx": 89453, "end_char_idx": 93390, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "32a8ce53-0e3e-4f8a-85eb-90a089c13a76": {"__data__": {"id_": "32a8ce53-0e3e-4f8a-85eb-90a089c13a76", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "200a6b73-4e93-4166-8e90-a9fe08eed9d5", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "2f30baf7123fe38f7ff8e083d415474864bf2b7903765557c5fae0dd75689ed6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "53879d22-d433-4dce-9474-137cc79d7e18", "node_type": "1", "metadata": {}, "hash": "e3d0a8562a51efcf807e821e7e4d1140f19de01baadf0baa755475f7eed56c4f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "v1,t and v2,t are the\r\nzero mean and serially uncorrelated disturbances. The VAR in Eq. (B1) can be transformed to the vector moving average (VMA) in Eq. (B2) as follows:\r\n\r\nrt = a*\r\nxt = c*\r\n\r\n0v1,t + a*\r\n0v1,t + c*\r\n\r\n1v1,t(cid:0) 1 + a*\r\n1v1,t(cid:0) 1 + c*\r\n\r\n2v1,t(cid:0) 2 + \u22ef + b*\r\n2v1,t(cid:0) 2 + \u22ef + d*\r\n\r\n0v2,t + b*\r\n0v2,t + d*\r\n\r\n1v2,t(cid:0) 1 + b*\r\n1v2,t(cid:0) 1 + d*\r\n\r\n2v2,t(cid:0) 2\u22ef\r\n2v2,t(cid:0) 2\u22ef\r\n\r\n,\r\n\r\n(B2)\r\n\r\nwhere the VMA coefficients can be calculated by forecasting the VAR system in Eq. (B1) by using impulse responses analysis. To calculate pricing error\r\n(st), only the (rt = a*\r\n2v2,t(cid:0) 2\u22ef) is needed, because Hasbrouck (1993) argues that an expanded\r\nrepresentation for pricing errors is\r\n\r\n2v1,t(cid:0) 2 + \u22ef + b*\r\n\r\n1v1,t(cid:0) 1 + a*\r\n\r\n1v2,t(cid:0) 1 + b*\r\n\r\n0v1,t + a*\r\n\r\n0v2,t + b*\r\n\r\n(cid:0)\r\n\r\n)\r\n\u03b10v1,t + \u03b11v1,t(cid:0) 1 + \u22ef\r\n\r\n+\r\n\r\n(cid:0)\r\n\r\n)\r\n\u03b20v2,t + \u03b21v2,t(cid:0) 1 + \u22ef\r\n\r\nst =\r\n\r\n+ (\u03c6t\r\n\r\n+ \u03b31\u03c6t(cid:0) 1\u22ef),\r\n\r\n(cid:0)\r\n\r\n)\r\n\r\n(cid:0)\r\n\r\n\u03b10v1,t + \u03b11v1,t(cid:0) 1 + \u22ef\r\n\r\ncaptures pricing errors\r\nwhere\r\ndue to the current and lagged trades adjustment. In addition, \u03c6t is a zero-mean, covariance-stationary process, orthogonal to all components of v1,t and\r\nv2,t.\r\n\r\ncaptures pricing errors due to the current and lagged price adjustment and\r\n\r\n\u03b20v2,t + \u03b21v2,t(cid:0) 1 + \u22ef\r\n\r\nBy a generalization of Beveridge and Nelson\u2019s (BN, 1981) demonstration, \u03b1j and \u03b2j in Eq. (B3) may be computed with the BN identification re-\r\n\r\nstriction (\u03c6t\r\n\u2211\u221e\r\n\r\n\u03b1j = (cid:0)\r\n\r\nk=j+1\r\n\r\n= \u03b31\r\n\r\n= \u22ef = 0) and the VMA coefficients (a*\r\n\r\n0\u2026), (b*\r\n\r\n0\u2026) in Eq. (B2):\r\n\r\na*\r\nk\r\n\r\nand \u03b2j\r\n\r\n= (cid:0)\r\n\r\n\u2211\u221e\r\n\r\nk=j+1\r\n\r\n.\r\n\r\nb*\r\nk\r\n\r\n(B4)\r\n\r\nWhen the coefficients appear in Eq. (B4) and we drop the \u03c6t terms, the result is an identification-invariant, best-linear estimate of st, conditional on\r\n\r\ncurrent and lagged vt. The pricing error variance (\u03c32\r\n\r\npe) may then be computed as\r\n\r\n17\r\n\r\n(B3)\r\n\r\n)\r\n\r\n\fY.-L. Chen et al.\r\n\r\n\u03c32\r\npe\r\n\r\n=\r\n\r\n\u2211\u221e\r\n\r\nj=0\r\n\r\n[\r\n\u03b1j \u03b2j\r\n\r\n]\r\nCov(v)\r\n\r\n]\r\n\r\n[\r\n\r\n\u03b1j\r\n\u03b2j\r\n\r\nInternational Review of Financial Analysis 97 (2025) 103810\r\n\r\n(B5)\r\n\r\nInitially, by using tick-by-tick price and trade of bitcoin futures, we examine the pricing error variance (\u03c32\r\n\r\ndegree of bitcoin futures market efficiency (i.e., PE measure). To assure meaningful comparisons, we also standardize \u03c32\r\ncomponent variance and pricing error variance, [\u03c32\r\nm\r\nprice efficiency for bitcoin futures market.\r\n\r\npe) which serves as the proxies for the\r\npe by the sum of random walk\r\npe]. A lower (standardized) relative pricing error variance (i.e., RPE measure) implies better\r\n\r\n+\u03c32\r\n\r\nReferences\r\n\r\nAckert, L. F., & Tian, Y. S. (1998). The introduction of Toronto index participation units\r\nand arbitrage opportunities in the Toronto 35 index option market.", "mimetype": "text/plain", "start_char_idx": 93303, "end_char_idx": 96090, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "53879d22-d433-4dce-9474-137cc79d7e18": {"__data__": {"id_": "53879d22-d433-4dce-9474-137cc79d7e18", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "32a8ce53-0e3e-4f8a-85eb-90a089c13a76", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1a8dae73951173e6a4a1691dbbd38cff7b525211a2752f81b14e06aa634f2116", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "29a3d521-dc7f-488a-a8da-20de05f13d35", "node_type": "1", "metadata": {}, "hash": "0fab0ec082c9ce2f01f0ae2d7001e477927a129ca01c53902e72894e807f5aac", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "To assure meaningful comparisons, we also standardize \u03c32\r\ncomponent variance and pricing error variance, [\u03c32\r\nm\r\nprice efficiency for bitcoin futures market.\r\n\r\npe) which serves as the proxies for the\r\npe by the sum of random walk\r\npe]. A lower (standardized) relative pricing error variance (i.e., RPE measure) implies better\r\n\r\n+\u03c32\r\n\r\nReferences\r\n\r\nAckert, L. F., & Tian, Y. S. (1998). The introduction of Toronto index participation units\r\nand arbitrage opportunities in the Toronto 35 index option market. Journal of\r\nDerivatives, 5(4), 44\u201353.\r\n\r\nAckert, L. F., & Tian, Y. S. (2001). Efficiency in index options markets and trading in\r\n\r\nstock baskets. Journal of Banking and Finance, 25(9), 1607\u20131634.\r\n\r\nAmihud, Y. (2002). Illiquidity and stock returns: Cross-section and time-series effects.\r\n\r\nJournal of Financial Markets, 5(1), 31\u201356.\r\n\r\nAndersen, T. G., Bollerslev, T., Diebold, F. X., & Ebens, H. (2001). The distribution of\r\nrealized stock return volatility. Journal of Financial Economics, 61(1), 43\u201376.\r\nAndersen, T. G., Bollerslev, T., Diebold, F. X., & Labys, P. (2003). Modeling and\r\n\r\nforecasting realized volatility. Econometrica, 71(2), 579\u2013625.\r\n\r\nAntonakakis, N., Chatziantoniou, I., & Gabauer, D. (2020). Refined measures of dynamic\r\nconnectedness based on time-varying parameter vector autoregressions. Journal of\r\nRisk and Financial Management, 13(4), 1\u201323.\r\n\r\nAugustin, P., Rubtsov, A., & Shin, D. (2023). The impact of derivatives on spot markets:\r\nEvidence from the introduction of bitcoin futures contracts. Management Science, 69\r\n(11), 6752\u20136776.\r\n\r\nBaur, D. G., & Smales, L. A. (2022). Trading behavior in bitcoin futures: Following the\r\n\r\n\u201csmart money\u201d. Journal of Futures Markets, 42(7), 1304\u20131323.\r\n\r\nBen-David, I., Franzoni, F., & Moussawi, R. (2018). Do ETFs increase volatility? Journal\r\n\r\nof Finance, 73(6), 2471\u20132535.\r\n\r\nBernile, G., Hu, J., & Tang, Y. (2016). Can information be locked up? Informed trading\r\nahead of macro-news announcements. Journal of Financial Economics, 121(3),\r\n496\u2013520.\r\n\r\nBessembinder, H. (1992). Systematic risk, hedging pressure, and risk premiums in futures\r\n\r\nmarkets. Review of Financial Studies, 5(4), 637\u2013667.\r\n\r\nBoehmer, E., & Kelley, E. K. (2009). Institutional investors and the informational\r\n\r\nefficiency of prices. Review of Financial Studies, 22(9), 3563\u20133594.\r\n\r\nBox, T., Davis, R., Evans, R., & Lynch, A. (2021). Intraday arbitrage between ETFs and\r\ntheir underlying portfolios. Journal of Financial Economics, 141(3), 1078\u20131095.\r\nBrennan, M. J., & Subrahmanyam, A. (1995). Investment analysis and price formation in\r\n\r\nsecurities markets. Journal of Financial Economics, 38(3), 361\u2013381.\r\n\r\nChan, W. H., Le, M., & Wu, Y. W. (2019). Holding bitcoin longer: The dynamic hedging\r\nabilities of bitcoin. The Quarterly Review of Economics and Finance, 71, 107\u2013113.\r\nChau, F., Kuo, J. M., & Shi, Y. (2015). Arbitrage opportunities and feedback trading in\r\nemissions and energy markets. Journal of International Financial Markets, Institutions\r\nand Money, 36, 130\u2013147.\r\n\r\nChen, Y. L., & Xu, K. (2021). The impact of RMB\u2019s SDR inclusion on price discovery in\r\nonshore-offshore markets.", "mimetype": "text/plain", "start_char_idx": 95581, "end_char_idx": 98739, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "29a3d521-dc7f-488a-a8da-20de05f13d35": {"__data__": {"id_": "29a3d521-dc7f-488a-a8da-20de05f13d35", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "53879d22-d433-4dce-9474-137cc79d7e18", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "8ecc67efec1da7ce44d7cc41d5b2f60799c4d29d12b0f3d252374acf157322e8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2a0038d3-bf63-4179-8128-4bf07fcfffdf", "node_type": "1", "metadata": {}, "hash": "9c3aecec5b43ae8cab34eb218fe816d57ca58b7e77266f2f9914ed7424e8d9a0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "(1995). Investment analysis and price formation in\r\n\r\nsecurities markets. Journal of Financial Economics, 38(3), 361\u2013381.\r\n\r\nChan, W. H., Le, M., & Wu, Y. W. (2019). Holding bitcoin longer: The dynamic hedging\r\nabilities of bitcoin. The Quarterly Review of Economics and Finance, 71, 107\u2013113.\r\nChau, F., Kuo, J. M., & Shi, Y. (2015). Arbitrage opportunities and feedback trading in\r\nemissions and energy markets. Journal of International Financial Markets, Institutions\r\nand Money, 36, 130\u2013147.\r\n\r\nChen, Y. L., & Xu, K. (2021). The impact of RMB\u2019s SDR inclusion on price discovery in\r\nonshore-offshore markets. Journal of Banking and Finance, 127, Article 106124.\r\nChen, Y. L., & Yang, J. J. (2021). Trader positions in VIX futures. Journal of Empirical\r\n\r\nFinance, 61, 1\u201317.\r\n\r\nChen, Y. L., & Yang, J. J. (2024). Time-varying price discovery in regular and\r\n\r\nmicrobitcoin futures. Journal of Futures Markets, 44(1), 103\u2013121.\r\n\r\nChordia, T., Roll, R., & Subrahmanyam, A. (2002). Order imbalance, liquidity, and\r\n\r\nmarket returns. Journal of Financial Economics, 65(1), 111\u2013130.\r\n\r\nChu, Q. C., & Hsieh, W. L. G. (2002). Pricing efficiency of the S&P 500 index market:\r\n\r\nEvidence from the Standard & Poor\u2019s depositary receipts. Journal of Futures Markets,\r\n22(9), 877\u2013900.\r\n\r\nCong, L. W., Li, X., Tang, K., & Yang, Y. (2023). Crypto wash trading. Management\r\n\r\nScience, 69(11), 6427\u20136454.\r\n\r\nDa, Z., Tang, K., Tao, Y., & Yang, L. (2023). Financialization and commodity markets\r\n\r\nserial dependence. Management Science, 1\u201322.\r\n\r\nDe Roon, F. A., Nijman, T. E., & Veld, C. (2000). Hedging pressure effects in futures\r\n\r\nmarkets. Journal of Finance, 55(3), 1437\u20131456.\r\n\r\nDiebold, F. X., & Yilmaz, K. (2012). Better to give than to receive: Predictive directional\r\nmeasurement of volatility spillovers. International Journal of Forecasting, 28(1),\r\n57\u201366.\r\n\r\nDiebold, F. X., & Yilmaz, K. (2014). On the network topology of variance decompositions:\r\nMeasuring the connectedness of financial firms. Journal of Econometrics, 182(1),\r\n119\u2013134.\r\n\r\nGlosten, L., Nallareddy, S., & Zou, Y. (2021). ETF activity and informational efficiency of\r\n\r\nunderlying securities. Management Science, 67(1), 22\u201347.\r\n\r\nHajric, V. (2021). Bloomberg news. https://www.bloomberg.com/news/articles/2021-1\r\n\r\n0-19/proshares-bitcoin-futures-etf-starts-trading-in-watershed-moment.\r\n\r\nHasbrouck, J. (1993). Assessing the quality of a security market: A new approach to\r\n\r\ntransaction-cost measurement. Review of Financial Studies, 6(1), 191\u2013212.\r\nHasbrouck, J. (2004). Liquidity in the futures pits: Inferring market dynamics from\r\nincomplete data. Journal of Financial and Quantitative Analysis, 39(2), 305\u2013326.\r\n\r\nHegde, S. P., & McDermott, J. B. (2004). The market liquidity of DIAMONDS, Q\u2019s, and\r\n\r\ntheir underlying stocks. Journal of Banking and Finance, 28(5), 1043\u20131067.\r\n\r\nHuang, S. S. (2024). Liquidity dynamics between virtual and equity markets. Journal of\r\n\r\nInternational Financial Markets Institutions and Money, 91, Article 101917.\r\n\r\nHung, J. C., Liu, H. C., & Yang, J. J. (2021).", "mimetype": "text/plain", "start_char_idx": 98129, "end_char_idx": 101192, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2a0038d3-bf63-4179-8128-4bf07fcfffdf": {"__data__": {"id_": "2a0038d3-bf63-4179-8128-4bf07fcfffdf", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "29a3d521-dc7f-488a-a8da-20de05f13d35", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "7eb21aa5ec03c74f8919a57fa3f4c2e21a38ca31aa70d2474cc61e10780d2c1f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cb5bdcd9-9026-436c-b5ed-231f334b54dc", "node_type": "1", "metadata": {}, "hash": "0ea178b1ed41dc50ce338854b271e1912a9c9854129a0b47be8f7151b47f4f46", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Review of Financial Studies, 6(1), 191\u2013212.\r\nHasbrouck, J. (2004). Liquidity in the futures pits: Inferring market dynamics from\r\nincomplete data. Journal of Financial and Quantitative Analysis, 39(2), 305\u2013326.\r\n\r\nHegde, S. P., & McDermott, J. B. (2004). The market liquidity of DIAMONDS, Q\u2019s, and\r\n\r\ntheir underlying stocks. Journal of Banking and Finance, 28(5), 1043\u20131067.\r\n\r\nHuang, S. S. (2024). Liquidity dynamics between virtual and equity markets. Journal of\r\n\r\nInternational Financial Markets Institutions and Money, 91, Article 101917.\r\n\r\nHung, J. C., Liu, H. C., & Yang, J. J. (2021). Trading activity and price discovery in\r\n\r\nbitcoin futures markets. Journal of Empirical Finance, 62, 107\u2013120.\r\n\r\nIsraeli, D., Lee, C., & Sridharan, S. A. (2017). Is there a dark side to exchange traded\r\n\r\nfunds? An information perspective. Review of Accounting Studies, 22(3), 1048\u20131083.\r\n\r\nJi, Q., Li, J., & Sun, X. (2019). Measuring the interdependence between investor\r\n\r\nsentiment and crude oil returns: New evidence from the CFTC\u2019s disaggregated\r\nreports. Finance Research Letters, 30, 420\u2013425.\r\n\r\nKapar, B., & Olmo, J. (2019). An analysis of price discovery between bitcoin futures and\r\n\r\nspot markets. Economics Letters, 174, 62\u201364.\r\n\r\nKurov, A. A., & Lasser, D. J. (2002). The effect of the introduction of cubes on the\r\n\r\nNasdaq-100 index spot-futures pricing relationship. Journal of Futures Markets, 22(3),\r\n197\u2013218.\r\n\r\nMakarov, I., & Schoar, A. (2020). Trading and arbitrage in cryptocurrency markets.\r\n\r\nJournal of Financial Economics, 135(2), 293\u2013319.\r\n\r\nMariana, C. D., Ekaputra, I. A., & Husodo, Z. A. (2021). Are bitcoin and Ethereum safe-\r\nhavens for stocks during the COVID-19 pandemic? Finance Research Letters, 38,\r\nArticle 101798.\r\n\r\nNgene, G. M., Benefield, P., & Lynch, A. K. (2018). Asymmetric and nonlinear dynamics\r\n\r\nin sovereign credit risk markets. Journal of Futures Markets, 38(5), 563\u2013585.\r\nNgene, G. M., & Wang, J. (2024). Arbitrage opportunities and feedback trading in\r\nregulated bitcoin futures market: An intraday analysis. International Review of\r\nEconomics and Finance, 89, 743\u2013761.\r\n\r\nNguyen, K. Q. (2022). The correlation between the stock market and bitcoin during\r\nCOVID-19 and other uncertainty periods. Finance Research Letters, 46, Article\r\n102284.\r\n\r\nO\u2019Hara, M. (2003). Presidential address: Liquidity and price discovery. Journal of\r\n\r\nFinance, 58, 1335\u20131354.\r\n\r\nO\u2019Hara, M. (2020). ETFs and systemic risks. CFA Institute Research Foundation briefs. ISBN\r\n\r\n978\u20131\u2013944960-91-9. Available at SSRN.\r\n\r\nO\u2019Hara, M., & Ye, M. (2011). Is market fragmentation harming market quality? Journal of\r\n\r\nFinancial Economics, 100(3), 459\u2013474.\r\n\r\nPagano, M. (1989). Trading volume and asset liquidity. The Quarterly Journal of\r\n\r\nEconomics, 104(2), 255\u2013274.\r\n\r\nPark, T. H., & Switzer, L. N. (1995). Index participation units and the performance of\r\nindex futures markets: Evidence from the Toronto 35 index participation units\r\nmarket. Journal of Futures Markets, 15(2), 187\u2013200.\r\n\r\nRoll, R. (1984). A simple implicit measure of the effective bid-ask spread in an efficient\r\n\r\nmarket. Journal of Finance, 39(4), 1127\u20131139.", "mimetype": "text/plain", "start_char_idx": 100598, "end_char_idx": 103748, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cb5bdcd9-9026-436c-b5ed-231f334b54dc": {"__data__": {"id_": "cb5bdcd9-9026-436c-b5ed-231f334b54dc", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2229d434-593e-479c-be51-13e40767a5bf", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "16064dc1c04c3b4b88f578224f0a60e121baf1374ceed1199961887a6839dc76", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2a0038d3-bf63-4179-8128-4bf07fcfffdf", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "71e090f22b7ba770d6b296c89283f69cb0a30db4e8eb985c77c0b21cbc0b49a8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Available at SSRN.\r\n\r\nO\u2019Hara, M., & Ye, M. (2011). Is market fragmentation harming market quality? Journal of\r\n\r\nFinancial Economics, 100(3), 459\u2013474.\r\n\r\nPagano, M. (1989). Trading volume and asset liquidity. The Quarterly Journal of\r\n\r\nEconomics, 104(2), 255\u2013274.\r\n\r\nPark, T. H., & Switzer, L. N. (1995). Index participation units and the performance of\r\nindex futures markets: Evidence from the Toronto 35 index participation units\r\nmarket. Journal of Futures Markets, 15(2), 187\u2013200.\r\n\r\nRoll, R. (1984). A simple implicit measure of the effective bid-ask spread in an efficient\r\n\r\nmarket. Journal of Finance, 39(4), 1127\u20131139.\r\n\r\nSwitzer, L. N., Varson, P. L., & Zghidi, S. (2000). Standard and Poor\u2019s depository receipts\r\nand the performance of the S&P 500 index futures market. Journal of Futures Markets,\r\n20(8), 705\u2013716.\r\n\r\nTini\u00e7, M., S\u00b8 ensoy, A., Akyildirim, E., & Corbet, S. (2022). Adverse selection in\r\n\r\ncryptocurrency markets (SSRN working paper).\r\n\r\nTodorov, K. (2021a). The anatomy of bond ETF arbitrage. BIS Quarterly Review (pp.\r\n\r\n41\u201353).\r\n\r\nTodorov, K. (2021b). Launch of the first US bitcoin ETF: Mechanics, impact, and risks. BIS\r\n\r\nQuarterly Review December.\r\n\r\nUrom, C., Abid, I., Guesmi, K., & Chevallier, J. (2020). Quantile spillovers and\r\ndependence between bitcoin, equities and strategic commodities. Economic\r\nModelling, 93, 230\u2013258.\r\n\r\nWang, C. (2003). The behavior and performance of major types of futures traders.\r\n\r\nJournal of Futures Markets, 23(1), 1\u201331.\r\n\r\nWu, J., Xu, K., Zheng, X., & Chen, J. (2021). Fractional cointegration in bitcoin spot and\r\n\r\nfutures markets. Journal of Futures Markets, 41(9), 1478\u20131494.\r\n\r\nZhang, S., Zhang, D., Zheng, J., Aerts, W., & Xu, D. (2023). Plus token and investor\r\n\r\nsearching behavior: A cryptocurrency Ponzi scheme. Accounting and Finance, 63(4),\r\n4713\u20134728.\r\n\r\nZhang, Y. (2015). The securitization of gold and its potential impact on gold stocks.\r\n\r\nJournal of Banking and Finance, 58, 309\u2013326.\r\n\r\nZhong, M., Darrat, A. F., & Otero, R. (2004). Price discovery and volatility spillovers in\r\nindex futures markets: Some evidence from Mexico. Journal of Banking and Finance,\r\n28(12), 3037\u20133054.\r\n\r\nZhu, P., Zhang, X., Wu, Y., Zheng, H., & Zhang, Y. (2021). Investor attention and\r\ncryptocurrency: Evidence from the bitcoin market. PLoS ONE, 16(2), 1\u201328.\r\n\r\n18", "mimetype": "text/plain", "start_char_idx": 103119, "end_char_idx": 105455, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4d57d10d-dec3-4319-b09e-079568c71b15": {"__data__": {"id_": "4d57d10d-dec3-4319-b09e-079568c71b15", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "3ccbb700050d207c687b2f5c787fc41740ff215ab40d53230572ee2b0218052c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9ac97102-5be5-4db4-bf81-15c660cf7a0e", "node_type": "1", "metadata": {}, "hash": "d32c9b3a3702aad8542de144f999fb2c825e7fe1e864274a415f67e675c963c1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Article\r\n\r\nhttps://doi.org/10.1038/s41467-024-44824-z\r\n\r\nSegment anything in medical images\r\n\r\nReceived: 24 October 2023\r\n\r\nAccepted: 5 January 2024\r\n\r\nCheck for updates\r\n\r\n;\r\n,\r\n:\r\n)\r\n(\r\n\r\n0\r\n9\r\n8\r\n7\r\n6\r\n5\r\n4\r\n3\r\n2\r\n1\r\n\r\n;\r\n,\r\n:\r\n)\r\n(\r\n\r\n0\r\n9\r\n8\r\n7\r\n6\r\n5\r\n4\r\n3\r\n2\r\n1\r\n\r\nJun Ma1,2,3, Yuting He4, Feifei Li\r\nBo Wang 1,2,3,7,8\r\n\r\n1, Lin Han5, Chenyu You 6 &\r\n\r\nMedical image segmentation is a critical component in clinical practice, facil-\r\nitating accurate diagnosis, treatment planning, and disease monitoring.\r\nHowever, existing methods, often tailored to speci\ufb01c modalities or disease\r\ntypes, lack generalizability across the diverse spectrum of medical image\r\nsegmentation tasks. Here we present MedSAM, a foundation model designed\r\nfor bridging this gap by enabling universal medical image segmentation. The\r\nmodel is developed on a large-scale medical image dataset with 1,570,263\r\nimage-mask pairs, covering 10 imaging modalities and over 30 cancer types.\r\nWe conduct a comprehensive evaluation on 86 internal validation tasks and 60\r\nexternal validation tasks, demonstrating better accuracy and robustness than\r\nmodality-wise specialist models. By delivering accurate and ef\ufb01cient seg-\r\nmentation across a wide spectrum of tasks, MedSAM holds signi\ufb01cant\r\npotential to expedite the evolution of diagnostic tools and the personalization\r\nof treatment plans.\r\n\r\ntreatment planning,\r\n\r\nSegmentation is a fundamental task in medical imaging analysis, which\r\ninvolves identifying and delineating regions of interest (ROI) in various\r\nmedical images, such as organs, lesions, and tissues1. Accurate seg-\r\nmentation is essential for many clinical applications, including disease\r\ndiagnosis,\r\nand monitoring of disease\r\nprogression2,3. Manual segmentation has long been the gold standard\r\nfor delineating anatomical structures and pathological regions, but\r\nthis process is time-consuming, labor-intensive, and often requires a\r\nhigh degree of expertise. Semi- or fully automatic segmentation\r\nmethods can signi\ufb01cantly reduce the time and labor required, increase\r\nconsistency, and enable the analysis of large-scale datasets4.\r\n\r\nDeep learning-based models have shown great promise in medical\r\nimage segmentation due to their ability to learn intricate image fea-\r\ntures and deliver accurate segmentation results across a diverse range\r\nof tasks, from segmenting speci\ufb01c anatomical structures to identifying\r\npathological regions5. However, a signi\ufb01cant limitation of many cur-\r\nrent medical image segmentation models is their task-speci\ufb01c nature.\r\nThese models are typically designed and trained for a speci\ufb01c seg-\r\nmentation task, and their performance can degrade signi\ufb01cantly when\r\napplied to new tasks or different types of imaging data6. This lack of\r\ngenerality poses a substantial obstacle to the wider application of\r\nthese models in clinical practice. In contrast, recent advances in the\r\n\r\n\ufb01eld of natural image segmentation have witnessed the emergence of\r\nsegmentation foundation models, such as segment anything model\r\n(SAM)7 and Segment Everything Everywhere with Multi-modal\r\nprompts all at once8, showcasing remarkable versatility and perfor-\r\nmance across various segmentation tasks.\r\n\r\nThere is a growing demand for universal models in medical image\r\nsegmentation: models that can be trained once and then applied to a\r\nwide range of segmentation tasks. Such models would not only exhibit\r\nheightened versatility in terms of model capacity but also potentially\r\nlead to more consistent results across different tasks. However, the\r\napplicability of the segmentation foundation models (e.g., SAM7) to\r\nmedical image segmentation remains limited due to the signi\ufb01cant\r\ndifferences between natural images and medical images. Essentially,\r\nSAM is a promptable segmentation method that requires points or\r\nbounding boxes to specify the segmentation targets. This resembles\r\nconventional interactive segmentation methods4,9\u201311 but SAM has bet-\r\nter generalization ability, while existing deep learning-based inter-\r\nactive segmentation methods focus mainly on limited tasks and image\r\nmodalities.\r\n\r\nMany studies have applied the out-of-the-box SAM models to\r\ntypical medical image segmentation tasks12\u201317 and other challenging\r\nscenarios18\u201321. For example, the concurrent studies22,23 conducted a\r\n\r\n1Peter Munk Cardiac Centre, University Health Network, Toronto, ON, Canada. 2Department of Laboratory Medicine and Pathobiology, University of Toronto,\r\nToronto, ON, Canada.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4487, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9ac97102-5be5-4db4-bf81-15c660cf7a0e": {"__data__": {"id_": "9ac97102-5be5-4db4-bf81-15c660cf7a0e", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "3ccbb700050d207c687b2f5c787fc41740ff215ab40d53230572ee2b0218052c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4d57d10d-dec3-4319-b09e-079568c71b15", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "a13722b1a709deb1533974490b4c67d1acf5200b13367c6cef4bffb6645be8ac", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6ad8952e-6aa3-4e4d-823b-57e157185095", "node_type": "1", "metadata": {}, "hash": "a4b23f82f1b773d05eb0befe9a79e157880668fe17576f3f0f232369c30e73e4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "However, the\r\napplicability of the segmentation foundation models (e.g., SAM7) to\r\nmedical image segmentation remains limited due to the signi\ufb01cant\r\ndifferences between natural images and medical images. Essentially,\r\nSAM is a promptable segmentation method that requires points or\r\nbounding boxes to specify the segmentation targets. This resembles\r\nconventional interactive segmentation methods4,9\u201311 but SAM has bet-\r\nter generalization ability, while existing deep learning-based inter-\r\nactive segmentation methods focus mainly on limited tasks and image\r\nmodalities.\r\n\r\nMany studies have applied the out-of-the-box SAM models to\r\ntypical medical image segmentation tasks12\u201317 and other challenging\r\nscenarios18\u201321. For example, the concurrent studies22,23 conducted a\r\n\r\n1Peter Munk Cardiac Centre, University Health Network, Toronto, ON, Canada. 2Department of Laboratory Medicine and Pathobiology, University of Toronto,\r\nToronto, ON, Canada. 3Vector Institute, Toronto, ON, Canada. 4Department of Computer Science, Western University, London, ON, Canada. 5Tandon School\r\nof Engineering, New York University, New York, NY, USA. 6Department of Electrical Engineering, Yale University, New Haven, CT, USA. 7Department of\r\nComputer Science, University of Toronto, Toronto, ON, Canada. 8UHN AI Hub, Toronto, ON, Canada.\r\n\r\ne-mail: bowang@vectorinstitute.ai\r\n\r\nNature Communications |\r\n\r\n (2024) 15:654\r\n\r\n1\r\n\r\n\fArticle\r\n\r\nhttps://doi.org/10.1038/s41467-024-44824-z\r\n\r\ncomprehensive assessment of SAM across a diverse array of medical\r\nimages, underscoring that SAM achieved satisfactory segmentation\r\noutcomes primarily on targets characterized by distinct boundaries.\r\nHowever, the model exhibited substantial limitations in segmenting\r\ntypical medical targets with weak boundaries or low contrast. In con-\r\ngruence with these observations, we further introduce MedSAM, a\r\nre\ufb01ned foundation model that signi\ufb01cantly enhances the segmenta-\r\ntion performance of SAM on medical images. MedSAM accomplishes\r\nthis by \ufb01ne-tuning SAM on an unprecedented dataset with more than\r\none million medical image-mask pairs.\r\n\r\nimaging modalities. Experimental\r\n\r\nWe thoroughly evaluate MedSAM through comprehensive\r\nexperiments on 86 internal validation tasks and 60 external validation\r\ntasks, spanning a variety of anatomical structures, pathological con-\r\nditions, and medical\r\nresults\r\ndemonstrate that MedSAM consistently outperforms the state-of-the-\r\nart (SOTA) segmentation foundation model7, while achieving perfor-\r\nmance on par with, or even surpassing specialist models1,24 that were\r\ntrained on the images from the same modality. These results highlight\r\nthe potential of MedSAM as a new paradigm for versatile medical\r\nimage segmentation.\r\n\r\nResults\r\nMedSAM: a foundation model for promptable medical image\r\nsegmentation\r\nMedSAM aims to ful\ufb01ll the role of a foundation model for universal\r\nmedical image segmentation. A crucial aspect of constructing such a\r\nmodel is the capacity to accommodate a wide range of variations in\r\nimaging conditions, anatomical structures, and pathological condi-\r\ntions. To address this challenge, we curated a diverse and large-scale\r\n\r\nmedical image segmentation dataset with 1,570,263 medical image-\r\nmask pairs, covering 10 imaging modalities, over 30 cancer types, and\r\na multitude of\r\nimaging protocols (Fig. 1 and Supplementary\r\nTables 1\u20134). This large-scale dataset allows MedSAM to learn a rich\r\nrepresentation of medical images, capturing a broad spectrum of\r\nanatomies and lesions across different modalities. Figure 2a provides\r\nan overview of the distribution of images across different medical\r\nimaging modalities in the dataset, ranked by their total numbers. It is\r\nevident that computed tomography (CT), magnetic resonance ima-\r\nging (MRI), and endoscopy are the dominant modalities, re\ufb02ecting\r\ntheir ubiquity in clinical practice. CT and MRI images provide detailed\r\ncross-sectional views of 3D body structures, making them indis-\r\npensable for non-invasive diagnostic imaging. Endoscopy, albeit more\r\ninvasive, enables direct visual inspection of organ interiors, proving\r\ninvaluable for diagnosing gastrointestinal and urological conditions.\r\nDespite the prevalence of these modalities, others such as ultrasound,\r\npathology, fundus, dermoscopy, mammography, and optical coher-\r\nence tomography (OCT) also hold signi\ufb01cant roles in clinical practice.", "mimetype": "text/plain", "start_char_idx": 3537, "end_char_idx": 7940, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6ad8952e-6aa3-4e4d-823b-57e157185095": {"__data__": {"id_": "6ad8952e-6aa3-4e4d-823b-57e157185095", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "3ccbb700050d207c687b2f5c787fc41740ff215ab40d53230572ee2b0218052c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9ac97102-5be5-4db4-bf81-15c660cf7a0e", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "ce9bb5137bf2d1750b2569e1b8acf3da3028a9ff1f128a286f8a9e575ab499e8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0a4a161c-c208-43e5-97a8-8f75231f94de", "node_type": "1", "metadata": {}, "hash": "de7aae2bdd7fad58ae61bd1509a3ce9d01e2fb025bdb468f0c236e9e0ba5ca68", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Figure 2a provides\r\nan overview of the distribution of images across different medical\r\nimaging modalities in the dataset, ranked by their total numbers. It is\r\nevident that computed tomography (CT), magnetic resonance ima-\r\nging (MRI), and endoscopy are the dominant modalities, re\ufb02ecting\r\ntheir ubiquity in clinical practice. CT and MRI images provide detailed\r\ncross-sectional views of 3D body structures, making them indis-\r\npensable for non-invasive diagnostic imaging. Endoscopy, albeit more\r\ninvasive, enables direct visual inspection of organ interiors, proving\r\ninvaluable for diagnosing gastrointestinal and urological conditions.\r\nDespite the prevalence of these modalities, others such as ultrasound,\r\npathology, fundus, dermoscopy, mammography, and optical coher-\r\nence tomography (OCT) also hold signi\ufb01cant roles in clinical practice.\r\nThe diversity of these modalities and their corresponding segmenta-\r\ntion targets underscores the necessity for universal and effective\r\nsegmentation models capable of handling the unique characteristics\r\nassociated with each modality.\r\n\r\nAnother critical consideration is the selection of the appropriate\r\nsegmentation prompt and network architecture. While the concept of\r\nfully automatic segmentation foundation models is enticing, it is\r\nfraught with challenges that make it impractical. One of the primary\r\nchallenges is the variability inherent in segmentation tasks. For\r\nexample, given a liver cancer CT image, the segmentation task can vary\r\ndepending on the speci\ufb01c clinical scenario. One clinician might be\r\n\r\nFig. 1 | MedSAM is trained on a large-scale dataset that can handle diverse segmentation tasks. The dataset covers a variety of anatomical structures, pathological\r\nconditions, and medical imaging modalities. The magenta contours and mask overlays denote the expert annotations and MedSAM segmentation results, respectively.\r\n\r\nNature Communications |\r\n\r\n (2024) 15:654\r\n\r\n2\r\n\r\n\fArticle\r\n\r\na\r\n\r\nb\r\n\r\nhttps://doi.org/10.1038/s41467-024-44824-z\r\n\r\nImage\r\nencoder\r\n\r\nMask decoder\r\n\r\nPrompt encoder\r\n\r\nInput Image\r\n\r\nImage\r\nembedding\r\n\r\nSegmentation\r\n\r\nBounding box prompts\r\n\r\nFig. 2 | Overview of the modality distribution in the dataset and the network architecture. a The number of medical image-mask pairs in each modality. b MedSAM is a\r\npromptable segmentation method where users can use bounding boxes to specify the segmentation targets. Source data are provided as a Source Data \ufb01le.\r\n\r\ninterested in segmenting the liver tumor, while another might need to\r\nsegment the entire liver and surrounding organs. Additionally, the\r\nvariability in imaging modalities presents another challenge. Mod-\r\nalities such as CT and MR generate 3D images, whereas others like\r\nX-ray and ultrasound yield 2D images. These variabilities in task de\ufb01-\r\nnition and imaging modalities complicate the design of a fully auto-\r\nmatic model capable of accurately anticipating and addressing the\r\ndiverse requirements of different users.\r\n\r\nConsidering these challenges, we argue that a more practical\r\napproach is to develop a promptable 2D segmentation model. The\r\nmodel can be easily adapted to speci\ufb01c tasks based on user-provided\r\nprompts, offering enhanced \ufb02exibility and adaptability. It is also able\r\nto handle both 2D and 3D images by processing 3D images as a series\r\nof 2D slices. Typical user prompts include points and bounding boxes\r\nand we show some segmentation examples with the different prompts\r\nin Supplementary Fig. 1. It can be found that bounding boxes provide a\r\nmore unambiguous spatial context for the region of interest, enabling\r\nthe algorithm to more precisely discern the target area. This stands in\r\ncontrast to point-based prompts, which can introduce ambiguity,\r\nparticularly when proximate structures resemble each other. More-\r\nover, drawing a bounding box is ef\ufb01cient, especially in scenarios\r\ninvolving multi-object segmentation. We follow the network archi-\r\ntecture in SAM7, including an image encoder, a prompt encoder, and a\r\nmask decoder (Fig. 2b). The image encoder25 maps the input image\r\ninto a high-dimensional image embedding space. The prompt encoder\r\ntransforms the user-drawn bounding boxes into feature representa-\r\ntions via positional encoding26. Finally, the mask decoder fuses the\r\nfeatures using cross-attention27\r\nimage embedding and prompt\r\n(Methods).\r\n\r\nQuantitative and qualitative analysis\r\nWe evaluated MedSAM through both internal validation and external\r\nvalidation.", "mimetype": "text/plain", "start_char_idx": 7092, "end_char_idx": 11571, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0a4a161c-c208-43e5-97a8-8f75231f94de": {"__data__": {"id_": "0a4a161c-c208-43e5-97a8-8f75231f94de", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "3ccbb700050d207c687b2f5c787fc41740ff215ab40d53230572ee2b0218052c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6ad8952e-6aa3-4e4d-823b-57e157185095", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "19fbf8fe47b6daaf385766bc0426afceda7fa946c97dc9ac8e3cf24f789d7a96", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "654e52b6-0538-4305-b719-8f25f1b96a93", "node_type": "1", "metadata": {}, "hash": "30defdfff29896d61ac514c9559e50e3518120bdb4ec793eb8fb3ec32d3fdab9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This stands in\r\ncontrast to point-based prompts, which can introduce ambiguity,\r\nparticularly when proximate structures resemble each other. More-\r\nover, drawing a bounding box is ef\ufb01cient, especially in scenarios\r\ninvolving multi-object segmentation. We follow the network archi-\r\ntecture in SAM7, including an image encoder, a prompt encoder, and a\r\nmask decoder (Fig. 2b). The image encoder25 maps the input image\r\ninto a high-dimensional image embedding space. The prompt encoder\r\ntransforms the user-drawn bounding boxes into feature representa-\r\ntions via positional encoding26. Finally, the mask decoder fuses the\r\nfeatures using cross-attention27\r\nimage embedding and prompt\r\n(Methods).\r\n\r\nQuantitative and qualitative analysis\r\nWe evaluated MedSAM through both internal validation and external\r\nvalidation. Speci\ufb01cally, we compared it to the SOTA segmentation\r\nfoundation model SAM7 as well as modality-wise specialist U-Net1 and\r\nDeepLabV3+24 models. Each specialized model was trained on images\r\nfrom the corresponding modality, resulting in 10 dedicated specialist\r\nmodels for each method. During inference, these specialist models\r\nwere used to segment the images from corresponding modalities,\r\nwhile SAM and MedSAM were employed for segmenting images across\r\nall modalities (Methods). The internal validation contained 86 seg-\r\nmentation tasks (Supplementary Tables 5\u20138 and Fig. 2), and Fig. 3a\r\nshows the median dice similarity coef\ufb01cient (DSC) score of these tasks\r\nfor the four methods. Overall, SAM obtained the lowest performance\r\non most segmentation tasks although it performed promisingly on\r\nsome RGB image segmentation tasks, such as polyp (DSC: 91.3%,\r\ninterquartile range (IQR): 81.2\u201395.1%) segmentation in endoscopy\r\nimages. This could be attributed to SAM\u2019s training on a variety of RGB\r\nimages, and the fact that many targets in these images are relatively\r\nstraightforward to segment due to their distinct appearances. The\r\nother three models outperformed SAM by a large margin and MedSAM\r\n\r\nhas a narrower distribution of DSC scores of the 86 interval validation\r\ntasks than the two groups of specialist models, re\ufb02ecting the robust-\r\nness of MedSAM across different tasks. We further connected the DSC\r\nscores corresponding to the same task of the four models with the\r\npodium plot Fig. 3b, which is complementary to the box plot. In the\r\nupper part, each colored dot denotes the median DSC achieved with\r\nthe respective method on one task. Dots corresponding to identical\r\ntest cases are connected by a line. In the lower part, the frequency of\r\nachieved ranks for each method is presented with bar charts. It can be\r\nfound that MedSAM ranked in \ufb01rst place on most tasks, surpassing the\r\nperformance of the U-Net and DeepLabV3+ specialist models that have\r\na high frequency of ranks with second and third places, respectively, In\r\ncontrast, SAM ranked last place in almost all tasks. Figure 3c (and\r\nSupplementary Fig. 9) visualizes some randomly selected segmenta-\r\ntion examples where MedSAM obtained a median DSC score, including\r\nliver tumor in CT images, brain tumor in MR images, breast tumor in\r\nultrasound images, and polyp in endoscopy images. SAM struggles\r\nwith targets of weak boundaries, which is prone to under or over-\r\nsegmentation errors. In contrast, MedSAM can accurately segment a\r\nwide range of targets across various imaging conditions, which\r\nachieves comparable of even better than the specialist U-Net and\r\nDeepLabV3+ models.\r\n\r\nThe external validation included 60 segmentation tasks, all of\r\nwhich either were from new datasets or involved unseen segmen-\r\ntation targets (Supplementary Tables 9\u201311 and Figs. 10\u201312). Fig-\r\nure 4a, b show the task-wise median DSC score distribution and their\r\ncorrespondence of the 60 tasks, respectively. Although SAM con-\r\ntinued exhibiting lower performance on most CT and MR segmen-\r\ntation tasks,\r\nthe specialist models no longer consistently\r\noutperformed SAM (e.g., right kidney segmentation in MR T1-\r\nweighted images: 90.1%, 85.3%, 86.4% for SAM, U-Net, and Dee-\r\npLabV3+, respectively). This indicates the limited generalization\r\nability of such specialist models on unseen targets. In contrast,\r\nMedSAM consistently delivers superior performance.", "mimetype": "text/plain", "start_char_idx": 10756, "end_char_idx": 15005, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "654e52b6-0538-4305-b719-8f25f1b96a93": {"__data__": {"id_": "654e52b6-0538-4305-b719-8f25f1b96a93", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "3ccbb700050d207c687b2f5c787fc41740ff215ab40d53230572ee2b0218052c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0a4a161c-c208-43e5-97a8-8f75231f94de", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "de5eb7f677ab88f3c441befb20655789bd7a294e91e7b11325e9b062636a26bb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "017cf284-efa9-43f8-8efb-3438ca8ab526", "node_type": "1", "metadata": {}, "hash": "3d5da386f3c8595ad5aabebd14cdf8fcd3ec7a21eb4f872537e040aa2f3a4d06", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The external validation included 60 segmentation tasks, all of\r\nwhich either were from new datasets or involved unseen segmen-\r\ntation targets (Supplementary Tables 9\u201311 and Figs. 10\u201312). Fig-\r\nure 4a, b show the task-wise median DSC score distribution and their\r\ncorrespondence of the 60 tasks, respectively. Although SAM con-\r\ntinued exhibiting lower performance on most CT and MR segmen-\r\ntation tasks,\r\nthe specialist models no longer consistently\r\noutperformed SAM (e.g., right kidney segmentation in MR T1-\r\nweighted images: 90.1%, 85.3%, 86.4% for SAM, U-Net, and Dee-\r\npLabV3+, respectively). This indicates the limited generalization\r\nability of such specialist models on unseen targets. In contrast,\r\nMedSAM consistently delivers superior performance. For example,\r\nMedSAM obtained median DSC scores of 87.8% (IQR: 85.0-91.4%) on\r\nthe nasopharynx cancer segmentation task, demonstrating 52.3%,\r\n15.5%, and 22.7 improvements over SAM, the specialist U-Net, and\r\nDeepLabV3+, respectively. Signi\ufb01cantly, MedSAM also achieved\r\nbetter performance in some unseen modalities (e.g., abdomen T1\r\nInphase and Outphase), surpassing SAM and the specialist models\r\nwith improvements by up to 10%. Figure 4c presents four randomly\r\nselected segmentation examples for qualitative evaluation, reveal-\r\ning that while all the methods have the ability to handle simple\r\nsegmentation targets, MedSAM performs better at segmenting\r\nchallenging targets with indistinguishable boundaries, such as cer-\r\nvical cancer in MR images (more examples are presented in Sup-\r\nplementary Fig. 13). Furthermore, we evaluated MedSAM on the\r\nmultiple myeloma plasma cell dataset, which represents a distinct\r\nmodality and task in contrast to all previously leveraged validation\r\ntasks. Although this task had never been seen during training,\r\n\r\nNature Communications |\r\n\r\n (2024) 15:654\r\n\r\n3\r\n\r\n\fArticle\r\n\r\nhttps://doi.org/10.1038/s41467-024-44824-z\r\n\r\nb\r\n\r\na\r\n\r\nc\r\n\r\nSAM\r\n\r\nU-Net\r\n\r\nDeepLabV3+\r\n\r\nMedSAM\r\n\r\nSAM\r\n\r\nU-Net\r\n\r\nDeepLabV3+\r\n\r\nMedSAM\r\n\r\nFig. 3 | Quantitative and qualitative evaluation results on the internal\r\nvalidation set. a Performance distribution of 86 internal validation tasks in terms\r\nof median dice similarity coef\ufb01cient (DSC) score. The center line within the box\r\nrepresents the median value, with the bottom and top bounds of the box deli-\r\nneating the 25th and 75th percentiles, respectively. Whiskers are chosen to show\r\nthe 1.5 of the interquartile range. Up-triangles denote the minima and down-\r\ntriangles denote the maxima. b Podium plots for visualizing the performance\r\ncorrespondence of 86 internal validation tasks. Upper part: each colored dot\r\ndenotes the median DSC achieved with the respective method on one task. Dots\r\n\r\ncorresponding to identical tasks are connected by a line. Lower part: bar charts\r\nrepresent the frequency of achieved ranks for each method. MedSAM ranks in the\r\n\ufb01rst place on most tasks. c Visualized segmentation examples on the internal\r\nvalidation set. The four examples are liver cancer, brain cancer, breast cancer, and\r\npolyp in computed tomography (CT), (Magnetic Resonance Imaging) MRI, ultra-\r\nsound, and endoscopy images, respectively. Blue: bounding box prompts; Yellow:\r\nsegmentation results. Magenta: expert annotations. Source data are provided as a\r\nSource Data \ufb01le.\r\n\r\nb\r\n\r\na\r\n\r\nc\r\n\r\nSAM\r\n\r\nU-Net\r\n\r\nDeepLabV3+\r\n\r\nMedSAM\r\n\r\nSAM\r\n\r\nU-Net\r\n\r\nDeepLabV3+\r\n\r\nMedSAM\r\n\r\nFig. 4 | Quantitative and qualitative evaluation results on the external\r\nvalidation set. a Performance distribution of 60 external validation tasks in terms\r\nof median dice similarity coef\ufb01cient (DSC) score. The center line within the box\r\nrepresents the median value, with the bottom and top bounds of the box deli-\r\nneating the 25th and 75th percentiles, respectively. Whiskers are chosen to show\r\nthe 1.5 of the interquartile range. Up-triangles denote the minima and down-\r\ntriangles denote the maxima.", "mimetype": "text/plain", "start_char_idx": 14244, "end_char_idx": 18168, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "017cf284-efa9-43f8-8efb-3438ca8ab526": {"__data__": {"id_": "017cf284-efa9-43f8-8efb-3438ca8ab526", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "3ccbb700050d207c687b2f5c787fc41740ff215ab40d53230572ee2b0218052c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "654e52b6-0538-4305-b719-8f25f1b96a93", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "9b600b03c8aadc6a082826abb46c99d21b298fd936a87e96883ab4569813e904", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7b7434ef-61f7-4853-83c9-5a42376ad2df", "node_type": "1", "metadata": {}, "hash": "e2344bc3416f2d5e39cbfbbe380df88623d5acbda2ec9a2bec2552851c1ac569", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Blue: bounding box prompts; Yellow:\r\nsegmentation results. Magenta: expert annotations. Source data are provided as a\r\nSource Data \ufb01le.\r\n\r\nb\r\n\r\na\r\n\r\nc\r\n\r\nSAM\r\n\r\nU-Net\r\n\r\nDeepLabV3+\r\n\r\nMedSAM\r\n\r\nSAM\r\n\r\nU-Net\r\n\r\nDeepLabV3+\r\n\r\nMedSAM\r\n\r\nFig. 4 | Quantitative and qualitative evaluation results on the external\r\nvalidation set. a Performance distribution of 60 external validation tasks in terms\r\nof median dice similarity coef\ufb01cient (DSC) score. The center line within the box\r\nrepresents the median value, with the bottom and top bounds of the box deli-\r\nneating the 25th and 75th percentiles, respectively. Whiskers are chosen to show\r\nthe 1.5 of the interquartile range. Up-triangles denote the minima and down-\r\ntriangles denote the maxima. b Podium plots for visualizing the performance\r\ncorrespondence of 60 external validation tasks. Upper part: each colored dot\r\n\r\ndenotes the median DSC achieved with the respective method on one task. Dots\r\ncorresponding to identical tasks are connected by a line. Lower part: bar charts\r\nrepresent the frequency of achieved ranks for each method. MedSAM ranks in the\r\n\ufb01rst place on most tasks. c Visualized segmentation examples on the external\r\nvalidation set. The four examples are the lymph node, cervical cancer, fetal head,\r\nand polyp in CT, MR, ultrasound, and endoscopy images, respectively. Source data\r\nare provided as a Source Data \ufb01le.\r\n\r\nNature Communications |\r\n\r\n (2024) 15:654\r\n\r\n4\r\n\r\n\fArticle\r\n\r\nhttps://doi.org/10.1038/s41467-024-44824-z\r\n\r\nMedSAM still exhibited superior performance compared to the SAM\r\n(Supplementary Fig. 14), highlighting its remarkable generalization\r\nability.\r\n\r\nThe effect of training dataset size\r\nWe also investigated the effect of varying dataset sizes on MedSAM\u2019s\r\nperformance because the training dataset size has been proven to be\r\npivotal in model performance28. We additionally trained MedSAM on\r\ntwo different dataset sizes: 10,000 (10K) and 100,000 (100K) images\r\nand their performances were compared with the default MedSAM\r\nmodel. The 10K and 100K training images were uniformly sampled\r\nfrom the whole training set, to maintain data diversity. As shown in\r\n(Fig. 5a) (Supplementary Tables 12\u201314), the performance adhered to\r\nthe scaling rule, where increasing the number of training images sig-\r\nni\ufb01cantly improved the performance in both internal and external\r\nvalidation sets.\r\n\r\nMedSAM can improve the annotation ef\ufb01ciency\r\nFurthermore, we conducted a human annotation study to assess the\r\ntime cost of two pipelines (Methods). For the \ufb01rst pipeline, two human\r\nexperts manually annotate 3D adrenal tumors in a slice-by-slice way. For\r\nthe second pipeline, the experts \ufb01rst drew the long and short tumor axes\r\nwith the linear marker (initial marker) every 3-10 slices, which is a com-\r\nmon practice in tumor response evaluation. Then, MedSAM was used to\r\nsegment the tumors based on these sparse linear annotations. Finally,\r\nthe expert manually revised the segmentation results until they were\r\nsatis\ufb01ed. We quantitatively compared the annotation time cost between\r\nthe two pipelines (Fig. 5b). The results demonstrate that with the assis-\r\ntance of MedSAM, the annotation time is substantially reduced by\r\n82.37% and 82.95% for the two experts, respectively.\r\n\r\nDiscussion\r\nWe introduce MedSAM, a deep learning-powered foundation model\r\ndesigned for the segmentation of a wide array of anatomical structures\r\nand lesions across diverse medical imaging modalities. MedSAM is\r\ntrained on a meticulously assembled large-scale dataset comprised of\r\nover one million medical image-mask pairs. Its promptable con\ufb01g-\r\nuration strikes an optimal balance between automation and customi-\r\nzation, rendering MedSAM a versatile tool for universal medical image\r\nsegmentation.\r\n\r\nThrough comprehensive evaluations encompassing both internal\r\nand external validation, MedSAM has demonstrated substantial cap-\r\nabilities in segmenting a diverse array of targets and robust general-\r\nization abilities to manage new data and tasks. Its performance not\r\nonly signi\ufb01cantly exceeds that of existing the state-of-the-art seg-\r\nmentation foundation model, but also rivals or even surpasses spe-\r\ncialist models.", "mimetype": "text/plain", "start_char_idx": 17427, "end_char_idx": 21619, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7b7434ef-61f7-4853-83c9-5a42376ad2df": {"__data__": {"id_": "7b7434ef-61f7-4853-83c9-5a42376ad2df", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "3ccbb700050d207c687b2f5c787fc41740ff215ab40d53230572ee2b0218052c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "017cf284-efa9-43f8-8efb-3438ca8ab526", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "afc688d4cf8e583639e7fc074a13ccc0c1fa4803ff22fdb0d6e0af1a5b25f1a0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7f28a954-ea6c-4e44-b783-9c8346113e18", "node_type": "1", "metadata": {}, "hash": "dfc32c23b96608b3fd229234e038a557f7010ed3a442464eb313b80eae9ab827", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Discussion\r\nWe introduce MedSAM, a deep learning-powered foundation model\r\ndesigned for the segmentation of a wide array of anatomical structures\r\nand lesions across diverse medical imaging modalities. MedSAM is\r\ntrained on a meticulously assembled large-scale dataset comprised of\r\nover one million medical image-mask pairs. Its promptable con\ufb01g-\r\nuration strikes an optimal balance between automation and customi-\r\nzation, rendering MedSAM a versatile tool for universal medical image\r\nsegmentation.\r\n\r\nThrough comprehensive evaluations encompassing both internal\r\nand external validation, MedSAM has demonstrated substantial cap-\r\nabilities in segmenting a diverse array of targets and robust general-\r\nization abilities to manage new data and tasks. Its performance not\r\nonly signi\ufb01cantly exceeds that of existing the state-of-the-art seg-\r\nmentation foundation model, but also rivals or even surpasses spe-\r\ncialist models. By providing precise delineation of anatomical\r\nstructures and pathological regions, MedSAM facilitates the compu-\r\ntation of various quantitative measures that serve as biomarkers. For\r\n\r\ninstance, in the \ufb01eld of oncology, MedSAM could play a crucial role in\r\naccelerating the 3D tumor annotation process, enabling subsequent\r\ncalculations of tumor volume, which is a critical biomarker29 for\r\nassessing disease progression and response to treatment. Additionally,\r\nMedSAM provides a successful paradigm for adapting natural image\r\nfoundation models to new domains, which can be further extended to\r\nbiological image segmentation30, such as cell segmentation in light\r\nmicroscopy images31 and organelle segmentation in electron micro-\r\nscopy images32.\r\n\r\nWhile MedSAM boasts strong capabilities, it does present certain\r\nlimitations. One such limitation is the modality imbalance in the\r\ntraining set, with CT, MRI, and endoscopy images dominating the\r\ndataset. This could potentially impact the model\u2019s performance on\r\nless-represented modalities, such as mammography. Another limita-\r\ntion is its dif\ufb01culty in the segmentation of vessel-like branching\r\nstructures because the bounding box prompt can be ambiguous in this\r\nsetting. For example, arteries and veins share the same bounding box\r\nin eye fundus images. However, these limitations do not diminish\r\nMedSAM\u2019s utility. Since MedSAM has learned rich and representative\r\nmedical image features from the large-scale training set, it can be \ufb01ne-\r\ntuned to effectively segment new tasks from less-represented mod-\r\nalities or intricate structures like vessels.\r\n\r\nIn conclusion, this study highlights the feasibility of constructing a\r\nsingle foundation model capable of managing a multitude of seg-\r\nmentation tasks, thereby eliminating the need for task-speci\ufb01c models.\r\nMedSAM, as the inaugural foundation model in medical image seg-\r\nmentation, holds great potential to accelerate the advancement of new\r\ndiagnostic and therapeutic tools, and ultimately contribute to\r\nimproved patient care33.\r\n\r\nMethods\r\nDataset curation and pre-processing\r\nWe curated a comprehensive dataset by collating images from publicly\r\navailable medical image segmentation datasets, which were obtained\r\nfrom various sources across the internet, including the Cancer Imaging\r\nArchive (TCIA)34, Kaggle, Grand-Challenge, Scienti\ufb01c Data, CodaLab,\r\nand segmentation challenges in the Medical Image Computing and\r\nComputer Assisted Intervention Society (MICCAI). All the datasets\r\nprovided segmentation annotations by human experts, which have\r\nbeen widely used in existing literature (Supplementary Table 1\u20134). We\r\nincorporated these annotations directly for both model development\r\nand validation.\r\n\r\nThe original 3D datasets consisted of computed tomography (CT)\r\nand magnetic resonance (MR) images in DICOM, nrrd, or mhd formats.\r\nTo ensure uniformity and compatibility with developing medical\r\nimage deep learning models, we converted the images to the widely\r\nused NifTI format. Additionally, grayscale images (such as X-Ray and\r\nUltrasound) as well as RGB images (including endoscopy, dermoscopy,\r\nfundus, and pathology images), were converted to the png format.\r\n\r\nFig. 5 | The effect of training dataset size and a user study of tumor annotation\r\nef\ufb01ciency. a Scaling up the training image size to one million can signi\ufb01cantly\r\nimprove the model performance on both internal and external validation sets.\r\n\r\nb MedSAM can be used to substantially reduce the annotation time cost. Source\r\ndata are provided as a Source Data \ufb01le.", "mimetype": "text/plain", "start_char_idx": 20691, "end_char_idx": 25186, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7f28a954-ea6c-4e44-b783-9c8346113e18": {"__data__": {"id_": "7f28a954-ea6c-4e44-b783-9c8346113e18", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "3ccbb700050d207c687b2f5c787fc41740ff215ab40d53230572ee2b0218052c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7b7434ef-61f7-4853-83c9-5a42376ad2df", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "fb26798bbe45c36d2063d9d5cf64ecb4bb146744879de715425ff72f72fcf1f8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fccfd992-163e-445e-9391-a027dbd18a04", "node_type": "1", "metadata": {}, "hash": "233df14f45470e6e46242c97ec2a2557076ac037ec9c136a3ad0f73d8ab88894", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The original 3D datasets consisted of computed tomography (CT)\r\nand magnetic resonance (MR) images in DICOM, nrrd, or mhd formats.\r\nTo ensure uniformity and compatibility with developing medical\r\nimage deep learning models, we converted the images to the widely\r\nused NifTI format. Additionally, grayscale images (such as X-Ray and\r\nUltrasound) as well as RGB images (including endoscopy, dermoscopy,\r\nfundus, and pathology images), were converted to the png format.\r\n\r\nFig. 5 | The effect of training dataset size and a user study of tumor annotation\r\nef\ufb01ciency. a Scaling up the training image size to one million can signi\ufb01cantly\r\nimprove the model performance on both internal and external validation sets.\r\n\r\nb MedSAM can be used to substantially reduce the annotation time cost. Source\r\ndata are provided as a Source Data \ufb01le.\r\n\r\nNature Communications |\r\n\r\n (2024) 15:654\r\n\r\n5\r\n\r\n\fArticle\r\n\r\nhttps://doi.org/10.1038/s41467-024-44824-z\r\n\r\nSeveral exclusive criteria are applied to improve the dataset quality\r\nand consistency, including incomplete images and segmentation tar-\r\ngets with branching structures,\r\ninaccurate annotations, and tiny\r\nvolumes. Notably, image intensities varied signi\ufb01cantly across differ-\r\nent modalities. For instance, CT images had intensity values ranging\r\nfrom -2000 to 2000, while MR images exhibited a range of 0 to 3000.\r\nIn endoscopy and ultrasound images, intensity values typically span-\r\nned from 0 to 255. To facilitate stable training, we performed intensity\r\nnormalization across all\r\nimages, ensuring they shared the same\r\nintensity range.\r\n\r\nFor CT images, we initially normalized the Houns\ufb01eld units using\r\ntypical window width and level values. The employed window width\r\nand level values for soft tissues, lung, and brain are (W:400, L:40),\r\n(W:1500, L:-160), and (W:80, L:40), respectively. Subsequently, the\r\nintensity values were rescaled to the range of [0, 255]. For MR, X-ray,\r\nultrasound, mammography, and optical coherence tomography (OCT)\r\nimages, we clipped the intensity values to the range between the 0.5th\r\nand 99.5th percentiles before rescaling them to the range of [0, 255].\r\nRegarding RGB images (e.g., endoscopy, dermoscopy, fundus, and\r\npathology images), if they were already within the expected intensity\r\nrange of [0, 255], their intensities remained unchanged. However, if\r\nthey fell outside this range, we utilized max-min normalization to\r\nrescale the intensity values to [0, 255]. Finally, to meet the model\u2019s\r\ninput requirements, all images were resized to a uniform size of\r\n1024 \u00d7 1024 \u00d7 3. In the case of whole-slide pathology images, patches\r\nwere extracted using a sliding window approach without overlaps. The\r\npatches located on boundaries were padded to this size with 0. As for\r\n3D CT and MR images, each 2D slice was resized to 1024 \u00d7 1024, and\r\nthe channel was repeated three times to maintain consistency. The\r\nremaining 2D images were directly resized to 1024 \u00d7 1024 \u00d7 3. Bi-cubic\r\ninterpolation was used for resizing images, while nearest-neighbor\r\ninterpolation was applied for resizing masks to preserve their precise\r\nboundaries and avoid introducing unwanted artifacts. These standar-\r\ndization procedures ensured uniformity and compatibility across all\r\nimages and facilitated seamless integration into the subsequent stages\r\nof the model training and evaluation pipeline.\r\n\r\nNetwork architecture\r\nThe network utilized in this study was built on transformer\r\narchitecture27, which has demonstrated remarkable effectiveness in\r\nvarious domains such as natural language processing and image\r\nrecognition tasks25. Speci\ufb01cally, the network incorporated a vision\r\ntransformer (ViT)-based image encoder responsible for extracting\r\nimage features, a prompt encoder for integrating user interactions\r\n(bounding boxes), and a mask decoder that generated segmentation\r\nresults and con\ufb01dence scores using the image embedding, prompt\r\nembedding, and output token.", "mimetype": "text/plain", "start_char_idx": 24354, "end_char_idx": 28303, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fccfd992-163e-445e-9391-a027dbd18a04": {"__data__": {"id_": "fccfd992-163e-445e-9391-a027dbd18a04", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "3ccbb700050d207c687b2f5c787fc41740ff215ab40d53230572ee2b0218052c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7f28a954-ea6c-4e44-b783-9c8346113e18", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "9ed54d778289ffa0debd2b417db9ead65e06d44f15ce03ed845c458664d80db2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4bce771b-8c79-4401-a0e4-5a6a8e334227", "node_type": "1", "metadata": {}, "hash": "777b3241fa39b5062dd206d49d21553e2b5ae96ee410f1cc58da8d7e339c9100", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Bi-cubic\r\ninterpolation was used for resizing images, while nearest-neighbor\r\ninterpolation was applied for resizing masks to preserve their precise\r\nboundaries and avoid introducing unwanted artifacts. These standar-\r\ndization procedures ensured uniformity and compatibility across all\r\nimages and facilitated seamless integration into the subsequent stages\r\nof the model training and evaluation pipeline.\r\n\r\nNetwork architecture\r\nThe network utilized in this study was built on transformer\r\narchitecture27, which has demonstrated remarkable effectiveness in\r\nvarious domains such as natural language processing and image\r\nrecognition tasks25. Speci\ufb01cally, the network incorporated a vision\r\ntransformer (ViT)-based image encoder responsible for extracting\r\nimage features, a prompt encoder for integrating user interactions\r\n(bounding boxes), and a mask decoder that generated segmentation\r\nresults and con\ufb01dence scores using the image embedding, prompt\r\nembedding, and output token.\r\n\r\nTo strike a balance between segmentation performance and com-\r\nputational ef\ufb01ciency, we employed the base ViT model as the image\r\nencoder since extensive evaluation indicated that larger ViT models,\r\nsuch as ViT Large and ViT Huge, offered only marginal improvements in\r\naccuracy7 while signi\ufb01cantly increasing computational demands. Speci-\r\n\ufb01cally, the base ViT model consists of 12 transformer layers27, with each\r\nblock comprising a multi-head self-attention block and a Multilayer\r\nPerceptron (MLP) block incorporating layer normalization35. Pre-training\r\nwas performed using masked auto-encoder modeling36, followed by\r\nfully supervised training on the SAM dataset7. The input image\r\n(1024 \u00d7 1024 \u00d7 3) was reshaped into a sequence of \ufb02attened 2D patches\r\nwith the size 16 \u00d7 16 \u00d7 3, yielding a feature size in image embedding of\r\n64 \u00d7 64 after passing through the image encoder, which is 16 \u00d7 down-\r\nscaled. The prompt encoders mapped the corner point of the bounding\r\nbox prompt to 256-dimensional vectorial embeddings26. In particular,\r\neach bounding box was represented by an embedding pair of the top-\r\nleft corner point and the bottom-right corner point. To facilitate real-\r\ntime user interactions once the image embedding had been computed, a\r\n\r\nlightweight mask decoder architecture was employed. It consists of two\r\ntransformer layers27 for fusing the image embedding and prompt\r\nencoding, and two transposed convolutional layers to enhance the\r\nembedding resolution to 256 \u00d7 256. Subsequently, the embedding\r\nunderwent sigmoid activation, followed by bi-linear interpolations to\r\nmatch the input size.\r\n\r\nTraining protocol and experimental setting\r\nDuring data pre-processing, we obtained 1,570,263 medical image-\r\nmask pairs for model development and validation. For internal vali-\r\ndation, we randomly split the dataset into 80%, 10%, and 10% as\r\ntraining, tuning, and validation, respectively. Speci\ufb01cally, for mod-\r\nalities where within-scan continuity exists, such as CT and MRI, and\r\nmodalities where continuity exists between consecutive frames, we\r\nperformed the data splitting at the 3D scan and the video level\r\nrespectively, by which any potential data leak was prevented. For\r\npathology images, recognizing the signi\ufb01cance of slide-level cohe-\r\nsiveness, we \ufb01rst separated the whole-slide images into distinct slide-\r\nbased sets. Then, each slide was divided into small patches with a \ufb01xed\r\nsize of 1024 \u00d7 1024. This setup allowed us to monitor the model\u2019s\r\nperformance on the tuning set and adjust its parameters during\r\ntraining to prevent over\ufb01tting. For the external validation, all datasets\r\nwere held out and did not appear during model training. These data-\r\nsets provide a stringent test of the model\u2019s generalization ability, as\r\nthey represent new patients, imaging conditions, and potentially new\r\nsegmentation tasks that the model has not encountered before. By\r\nevaluating the performance of MedSAM on these unseen datasets, we\r\ncan gain a realistic understanding of how MedSAM is likely to perform\r\nin real-world clinical settings, where it will need to handle a wide range\r\nof variability and unpredictability in the data. The training and vali-\r\ndation are independent.\r\n\r\nThe model was initialized with the pre-trained SAM model with\r\nthe ViT-Base model. We \ufb01xed the prompt encoder since it can already\r\nencode the bounding box prompt. All the trainable parameters in the\r\nimage encoder and mask decoder were updated during training.", "mimetype": "text/plain", "start_char_idx": 27318, "end_char_idx": 31783, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4bce771b-8c79-4401-a0e4-5a6a8e334227": {"__data__": {"id_": "4bce771b-8c79-4401-a0e4-5a6a8e334227", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "3ccbb700050d207c687b2f5c787fc41740ff215ab40d53230572ee2b0218052c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fccfd992-163e-445e-9391-a027dbd18a04", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "182506fa55a8f380c1a89287d2d31cb0d23f3361c11e1efaf80235a838c1a575", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8bff7753-8211-4486-9469-29cc002ff212", "node_type": "1", "metadata": {}, "hash": "5e4a75e41ef7045a8c38f14051ddeaaf2e66d892e9a53705d10f4b4e26b16486", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For the external validation, all datasets\r\nwere held out and did not appear during model training. These data-\r\nsets provide a stringent test of the model\u2019s generalization ability, as\r\nthey represent new patients, imaging conditions, and potentially new\r\nsegmentation tasks that the model has not encountered before. By\r\nevaluating the performance of MedSAM on these unseen datasets, we\r\ncan gain a realistic understanding of how MedSAM is likely to perform\r\nin real-world clinical settings, where it will need to handle a wide range\r\nof variability and unpredictability in the data. The training and vali-\r\ndation are independent.\r\n\r\nThe model was initialized with the pre-trained SAM model with\r\nthe ViT-Base model. We \ufb01xed the prompt encoder since it can already\r\nencode the bounding box prompt. All the trainable parameters in the\r\nimage encoder and mask decoder were updated during training.\r\nSpeci\ufb01cally, the number of trainable parameters for the image encoder\r\nand mask decoder are 89,670,912 and 4,058,340, respectively. The\r\nbounding box prompt was simulated from the expert annotations with\r\na random perturbation of 0-20 pixels. The loss function is the\r\nunweighted sum between dice loss and cross-entropy loss, which has\r\nbeen proven to be robust in various segmentation tasks1. The network\r\nwas optimized by AdamW37 optimizer (\u03b21 = 0.9, \u03b22 = 0.999) with an\r\ninitial learning rate of 1e-4 and a weight decay of 0.01. The global batch\r\nsize was 160 and data augmentation was not used. The model was\r\ntrained on 20 A100 (80G) GPUs with 150 epochs and the last check-\r\npoint was selected as the \ufb01nal model.\r\n\r\nFurthermore, to thoroughly evaluate the performance of Med-\r\nSAM, we conducted comparative analyses against both the state-of-\r\nthe-art segmentation foundation model SAM7 and specialist models\r\n(i.e., U-Net1 and DeepLabV3+24). The training images contained 10\r\nmodalities: CT, MR, chest X-ray (CXR), dermoscopy, endoscopy,\r\nultrasound, mammography, OCT, and pathology, and we trained the\r\nU-Net and DeepLabV3+ specialist models for each modality. There\r\nwere 20 specialist models in total and the number of corresponding\r\ntraining images was presented in Supplementary Table 5. We\r\nemployed the nnU-Net to conduct all U-Net experiments, which can\r\nautomatically con\ufb01gure the network architecture based on the dataset\r\nproperties. In order to incorporate the bounding box prompt into the\r\nmodel, we transformed the bounding box into a binary mask and\r\nconcatenated it with the image as the model input. This function was\r\noriginally supported by nnU-Net in the cascaded pipeline, which has\r\ndemonstrated increased performance in many segmentation tasks by\r\nusing the binary mask as an additional channel to specify the target\r\nlocation. The training settings followed the default con\ufb01gurations of\r\n2D nnU-Net. Each model was trained on one A100 GPU with 1000\r\n\r\nNature Communications |\r\n\r\n (2024) 15:654\r\n\r\n6\r\n\r\n\fArticle\r\n\r\nhttps://doi.org/10.1038/s41467-024-44824-z\r\n\r\nepochs and the last checkpoint was used as the \ufb01nal model. The\r\nDeepLabV3+ specialist models used ResNet5038 as the encoder. Similar\r\nto ref. 3, the input images were resized to 224 \u00d7 224 \u00d7 3. The bounding\r\nbox was transformed into a binary mask as an additional input channel\r\nto provide the object location prompt. Segmentation Models Pytorch\r\n(0.3.3)39 was used to perform training and inference for all the\r\nmodality-wise specialist DeepLabV3 + models. Each modality-wise\r\nmodel was trained on one A100 GPU with 500 epochs and the last\r\ncheckpoint was used as the \ufb01nal model. During the inference phase,\r\nSAM and MedSAM were used to perform segmentation across all\r\nmodalities with a single model. In contrast, the U-Net and DeepLabV3+\r\nspecialist models were used to individually segment the respective\r\ncorresponding modalities.\r\n\r\nA task-speci\ufb01c segmentation model might outperform a modality-\r\nbased one for certain applications.", "mimetype": "text/plain", "start_char_idx": 30887, "end_char_idx": 34813, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8bff7753-8211-4486-9469-29cc002ff212": {"__data__": {"id_": "8bff7753-8211-4486-9469-29cc002ff212", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "3ccbb700050d207c687b2f5c787fc41740ff215ab40d53230572ee2b0218052c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4bce771b-8c79-4401-a0e4-5a6a8e334227", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "b5d2d8699bf4a685161b3281130b1765f8fa9828a46461aa04d13fc7ef4ce106", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "da6eb826-48f7-4546-826b-d5a9e2c85d65", "node_type": "1", "metadata": {}, "hash": "254e2e1ec7f0b2c6dee7e89c415c59fc3cc6db6d4320bea609c218e3a35e144d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Similar\r\nto ref. 3, the input images were resized to 224 \u00d7 224 \u00d7 3. The bounding\r\nbox was transformed into a binary mask as an additional input channel\r\nto provide the object location prompt. Segmentation Models Pytorch\r\n(0.3.3)39 was used to perform training and inference for all the\r\nmodality-wise specialist DeepLabV3 + models. Each modality-wise\r\nmodel was trained on one A100 GPU with 500 epochs and the last\r\ncheckpoint was used as the \ufb01nal model. During the inference phase,\r\nSAM and MedSAM were used to perform segmentation across all\r\nmodalities with a single model. In contrast, the U-Net and DeepLabV3+\r\nspecialist models were used to individually segment the respective\r\ncorresponding modalities.\r\n\r\nA task-speci\ufb01c segmentation model might outperform a modality-\r\nbased one for certain applications. Since U-Net obtained better per-\r\nformance than DeepLabV3+ on most tasks, we further conducted a\r\ncomparison study by training task-speci\ufb01c U-Net models on four\r\nrepresentative tasks, including liver cancer segmentation in CT scans,\r\nabdominal organ segmentation in MR scans, nerve cancer segmenta-\r\ntion in ultrasound, and polyp segmentation in endoscopy images. The\r\nexperiments included both internal validation and external validation.\r\nFor internal validation, we adhered to the default data splits, using\r\nthem to train the task-speci\ufb01c U-Net models and then evaluate their\r\nperformance on the corresponding validation set. For external vali-\r\ndation, the trained U-Net models were evaluated on new datasets from\r\nthe same modality or segmentation targets. In all these experiments,\r\nMedSAM was directly applied to the validation sets without additional\r\n\ufb01ne-tuning. As shown in Supplementary Fig. 15, while task-speci\ufb01c U-\r\nNet models often achieved great results on internal validation sets,\r\ntheir performance diminished signi\ufb01cantly for external sets. In con-\r\ntrast, MedSAM maintained consistent performance across both inter-\r\nnal and external validation sets. This underscores MedSAM\u2019s superior\r\ngeneralization ability, making it a versatile tool in a variety of medical\r\nimage segmentation tasks.\r\n\r\nLoss function\r\nWe used the unweighted sum between cross-entropy loss and dice\r\nloss40 as the \ufb01nal loss function since it has been proven to be robust\r\nacross different medical image segmentation tasks41. Speci\ufb01cally, let\r\nS, G denote the segmentation result and ground truth, respectively.\r\nsi, gi denotes the predicted segmentation and ground truth of voxel i,\r\nrespectively. N is the number of voxels in the image I. Binary cross-\r\nentropy loss is de\ufb01ned by\r\n\r\nLBCE = (cid:1)\r\n\r\n1\r\nN\r\n\r\nXN\r\n\r\n(cid:2)\r\n\r\ni = 1\r\n\r\n(cid:3)\r\ngi log si + \u00f01 (cid:1) gi\u00de log\u00f01 (cid:1) si\u00de\r\n\r\n,\r\n\r\nand dice loss is de\ufb01ned by\r\n\r\nLDice = 1 (cid:1)\r\n\r\nThe \ufb01nal loss L is de\ufb01ned by\r\n\r\nP\r\n\r\nP\r\nN\r\n\r\n2\r\ni = 1 \u00f0gi\u00de2 +\r\n\r\nN\r\ni = 1 gisi\r\nP\r\nN\r\n\r\ni = 1 \u00f0si\u00de2\r\n\r\n:\r\n\r\nL = LBCE + LDice\r\n\r\n:\r\n\r\n\u00f01\u00de\r\n\r\n\u00f02\u00de\r\n\r\n\u00f03\u00de\r\n\r\nHuman annotation study\r\nThe objective of the human annotation study was to quantitatively\r\nevaluate how MedSAM can reduce the annotation time cost. Speci\ufb01-\r\ncally, we used the recent adrenocortical carcinoma CT dataset34,42,43,\r\nwhere the segmentation target, adrenal tumor, was neither part of the\r\ntraining nor of the existing validation sets. We randomly sampled 10\r\ncases, comprising a total of 733 tumor slices requiring annotations.\r\nTwo human experts participated in this study, both of whom are\r\n\r\nexperienced radiologists with 8 and 6 years of clinical practice in\r\nabdominal diseases, respectively. Each expert generated two groups of\r\nannotations, one with the assistance of MedSAM and one without.\r\n\r\nIn the \ufb01rst group, the experts manually annotated the 3D adrenal\r\ntumor in a slice-by-slice manner. Annotations by the two experts were\r\nconducted independently, with no collaborative discussions, and the\r\ntime taken for each case was recorded. In the second group, annota-\r\ntions were generated after one week of cooling period.", "mimetype": "text/plain", "start_char_idx": 34001, "end_char_idx": 37952, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "da6eb826-48f7-4546-826b-d5a9e2c85d65": {"__data__": {"id_": "da6eb826-48f7-4546-826b-d5a9e2c85d65", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "3ccbb700050d207c687b2f5c787fc41740ff215ab40d53230572ee2b0218052c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8bff7753-8211-4486-9469-29cc002ff212", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "3b12092745146b9a77ed9058a750668ffdca894d4463040076aadd1dd3c05aa1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "225ab9dd-740d-4894-84d1-6b9dc362d3ac", "node_type": "1", "metadata": {}, "hash": "5e23fd8db3f0945e7839b266bdd1f4e7a68d404551e394a8b63b9085513c43b0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We randomly sampled 10\r\ncases, comprising a total of 733 tumor slices requiring annotations.\r\nTwo human experts participated in this study, both of whom are\r\n\r\nexperienced radiologists with 8 and 6 years of clinical practice in\r\nabdominal diseases, respectively. Each expert generated two groups of\r\nannotations, one with the assistance of MedSAM and one without.\r\n\r\nIn the \ufb01rst group, the experts manually annotated the 3D adrenal\r\ntumor in a slice-by-slice manner. Annotations by the two experts were\r\nconducted independently, with no collaborative discussions, and the\r\ntime taken for each case was recorded. In the second group, annota-\r\ntions were generated after one week of cooling period. The experts\r\nindependently drew the long and short tumor axes as initial markers,\r\nwhich is a common practice in tumor response evaluation. This pro-\r\ncess was executed every 3-10 slices from the top slice to the bottom\r\nslice of the tumor. Then, we applied MedSAM to segment the tumors\r\nbased on these sparse linear annotations, including three steps.\r\n\r\n(cid:129)\r\n\r\n(cid:129)\r\n\r\n(cid:129)\r\n\r\nStep 1. For each annotated slice, a rectangle binary mask was\r\ngenerated based on the linear label that can completely cover\r\nthe linear label.\r\nStep 2. For the unlabeled slices, the rectangle binary masks were\r\ncreated through interpolation of the surrounding labeled slices.\r\nStep 3. We transformed the binary masks into bounding boxes\r\nand then fed them along with the images into MedSAM to gen-\r\nerate segmentation results.\r\n\r\nAll these steps were conducted in an automatic way and the model\r\nrunning time was recorded for each case. Finally, human experts\r\nmanually re\ufb01ned the segmentation results until they met their satis-\r\nfaction. To summarize, the time cost of the second group of annota-\r\ntions contained three parts: initial markers, MedSAM inference, and\r\nre\ufb01nement. All the manual annotation processes were based on ITK-\r\nSNAP44, an open-source software designed for medical image visuali-\r\nzation and annotation.\r\n\r\nEvaluation metrics\r\nWe followed the recommendations in Metrics Reloaded45 and used the\r\ndice similarity coef\ufb01cient and normalized surface distance (NSD) to\r\nquantitatively evaluate the segmentation results. DSC is a region-based\r\nsegmentation metric, aiming to evaluate the region overlap between\r\nexpert annotation masks and segmentation results, which is de\ufb01ned by\r\n\r\nDSC\u00f0G, S\u00de =\r\n\r\n2jG \\ Sj\r\njGj + jSj\r\n\r\n,\r\n\r\nNSD46 is a boundary-based metric, aiming to evaluate the boundary\r\nconsensus between expert annotation masks and segmentation results\r\nat a given tolerance, which is de\ufb01ned by\r\n\r\nNSD\u00f0G, S\u00de =\r\n\r\nj\u2202G \\ B\u00f0\u03c4\u00de\r\n\r\n\u2202S j + j\u2202S \\ B\u00f0\u03c4\u00de\r\n\u2202Gj\r\nj\u2202Gj + j\u2202Sj\r\n\r\n,\r\n\r\n\u2202G = fx 2 R3 j 9~x 2 \u2202G, jjx (cid:1) ~xjj \u2264 \u03c4g, B\u00f0\u03c4\u00de\r\n\r\nwhere B\u00f0\u03c4\u00de\r\n\u2202S = fx 2 R3 j 9~x 2 \u2202S, jjx (cid:1)\r\n~xjj \u2264 \u03c4g denote the border region of the expert annotation mask and\r\nthe segmentation surface at tolerance \u03c4, respectively. In this paper, we\r\nset the tolerance \u03c4 as 2.\r\n\r\nStatistical analysis\r\nTo statistically analyze and compare the performance of the afore-\r\nmentioned four methods (MedSAM, SAM, U-Net, and DeepLabV3+\r\nspecialist models), we employed the Wilcoxon signed-rank test. This\r\nnon-parametric test is well-suited for comparing paired samples and is\r\nparticularly useful when the data does not meet the assumptions of\r\nnormal distribution. This analysis allowed us to determine if any\r\nmethod demonstrated statistically superior segmentation perfor-\r\nmance compared to the others, providing valuable insights into the\r\ncomparative effectiveness of the evaluated methods. The Wilcoxon\r\nsigned-rank test results are marked on the DSC and NSD score tables\r\n(Supplementary Table 6\u201311).\r\n\r\nNature Communications |\r\n\r\n (2024) 15:654\r\n\r\n7\r\n\r\n\fArticle\r\n\r\nhttps://doi.org/10.1038/s41467-024-44824-z\r\n\r\nSoftware utilized\r\nAll code was implemented in Python (3.10) using Pytorch (2.0) as the\r\nbase deep learning framework.", "mimetype": "text/plain", "start_char_idx": 37256, "end_char_idx": 41175, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "225ab9dd-740d-4894-84d1-6b9dc362d3ac": {"__data__": {"id_": "225ab9dd-740d-4894-84d1-6b9dc362d3ac", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "3ccbb700050d207c687b2f5c787fc41740ff215ab40d53230572ee2b0218052c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "da6eb826-48f7-4546-826b-d5a9e2c85d65", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "74a77cbd0db77a07d19069a189e10d3e1c929def77cdbb879b0909d4b72bdc87", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7d19aff2-ace2-467e-800a-686d47ab519b", "node_type": "1", "metadata": {}, "hash": "13041f35c5b4797802b24b193ae4a1890f29c363d655621d3748873c13e3172a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This\r\nnon-parametric test is well-suited for comparing paired samples and is\r\nparticularly useful when the data does not meet the assumptions of\r\nnormal distribution. This analysis allowed us to determine if any\r\nmethod demonstrated statistically superior segmentation perfor-\r\nmance compared to the others, providing valuable insights into the\r\ncomparative effectiveness of the evaluated methods. The Wilcoxon\r\nsigned-rank test results are marked on the DSC and NSD score tables\r\n(Supplementary Table 6\u201311).\r\n\r\nNature Communications |\r\n\r\n (2024) 15:654\r\n\r\n7\r\n\r\n\fArticle\r\n\r\nhttps://doi.org/10.1038/s41467-024-44824-z\r\n\r\nSoftware utilized\r\nAll code was implemented in Python (3.10) using Pytorch (2.0) as the\r\nbase deep learning framework. We also used several Python packages\r\nincluding connected-\r\nfor data analysis and results visualization,\r\ncomponents-3d (3.10.3), SimpleITK (2.2.1), nibabel (5.1.0), torchvision\r\n(0.15.2), numpy (1.24.3), scikit-image (0.20.0), scipy (1.10.1), and pan-\r\ndas (2.0.2), matplotlib (3.7.1), opencv-python (4.8.0), ChallengeR\r\n(1.0.5), and plotly (5.15.0). Biorender was used to create Fig. 1.\r\n\r\nReporting summary\r\nFurther information on research design is available in the Nature\r\nPortfolio Reporting Summary linked to this article.\r\n\r\nData availability\r\nThe training and validating datasets used in this study are available in\r\nthe public domain and can be downloaded via the links provided in\r\nSupplementary Tables 16 and 17. Source data are provided with this\r\npaper in the Source Data \ufb01le. We con\ufb01rmed that All the image datasets\r\nin this study are publicly accessible and permitted for research pur-\r\nposes. Source data are provided in this paper.\r\n\r\nCode availability\r\nThe training script, inference script, and trained model have been\r\npublicly available at https://github.com/bowang-lab/MedSAM. A per-\r\nmanent version is released on Zenodo47.\r\n\r\nReferences\r\n1.\r\n\r\nIsensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J. & Maier-Hein, K. H.\r\nnnU-Net: a self-con\ufb01guring method for deep learning-based bio-\r\nmedical image segmentation. Nat. Method. 18, 203\u2013211 (2021).\r\n2. De Fauw, J. Clinically applicable deep learning for diagnosis and\r\nreferral in retinal disease. Nat. Med. 24, 1342\u20131350 (2018).\r\n\r\n3. Ouyang, D. Video-based AI for beat-to-beat assessment of cardiac\r\n\r\nfunction. Nature 580, 252\u2013256 (2020).\r\n\r\n4. Wang, G. Deepigeos: a deep interactive geodesic framework for\r\n\r\nmedical image segmentation. In IEEE Transactions on Pattern Ana-\r\nlysis and Machine Intelligence 41, 1559\u20131572 (IEEE, 2018).\r\n\r\n5. Antonelli, M. The medical segmentation decathlon. Nat. Commun.\r\n\r\n13, 4128 (2022).\r\n\r\n7.\r\n\r\n6. Minaee, S. Image segmentation using deep learning: A survey. In\r\nIEEE Transactions on Pattern Analysis and Machine Intelligence 44,\r\n3523\u20133542 (IEEE, 2021).\r\nKirillov, A. et al. Segment anything. In IEEE International Conference\r\non Computer Vision. 4015\u20134026 (IEEE, 2023).\r\nZou, X. et al. Segment everything everywhere all at once. In\r\nAdvances in Neural Information Processing Systems (MIT\r\nPress, 2023).\r\n\r\n8.\r\n\r\n15. Roy, S. et al. SAM.MD: zero-shot medical image segmentation\r\n\r\ncapabilities of the segment anything model. Preprint at https://\r\narxiv.org/abs/2304.05396 (2023).\r\n\r\n16. Zhou, T., Zhang, Y., Zhou, Y., Wu, Y. & Gong, C. Can SAM segment\r\npolyps? Preprint at https://arxiv.org/abs/2304.07583 (2023).\r\n17.", "mimetype": "text/plain", "start_char_idx": 40437, "end_char_idx": 43806, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7d19aff2-ace2-467e-800a-686d47ab519b": {"__data__": {"id_": "7d19aff2-ace2-467e-800a-686d47ab519b", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "3ccbb700050d207c687b2f5c787fc41740ff215ab40d53230572ee2b0218052c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "225ab9dd-740d-4894-84d1-6b9dc362d3ac", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "80591bc3d396ac178bc7e20f1655e6b07e292912bef0ddf198dd436e3503b78d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d03f4b53-cdfb-420b-b0c3-67a326a87a8b", "node_type": "1", "metadata": {}, "hash": "a30efb92c0707f1bbd0cd73350f855a4551cbf001fa52b7b6ec5c8f238470462", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Kirillov, A. et al. Segment anything. In IEEE International Conference\r\non Computer Vision. 4015\u20134026 (IEEE, 2023).\r\nZou, X. et al. Segment everything everywhere all at once. In\r\nAdvances in Neural Information Processing Systems (MIT\r\nPress, 2023).\r\n\r\n8.\r\n\r\n15. Roy, S. et al. SAM.MD: zero-shot medical image segmentation\r\n\r\ncapabilities of the segment anything model. Preprint at https://\r\narxiv.org/abs/2304.05396 (2023).\r\n\r\n16. Zhou, T., Zhang, Y., Zhou, Y., Wu, Y. & Gong, C. Can SAM segment\r\npolyps? Preprint at https://arxiv.org/abs/2304.07583 (2023).\r\n17. Mohapatra, S., Gosai, A., Schlaug, G. Sam vs bet: a comparative\r\n\r\nstudy for brain extraction and segmentation of magnetic resonance\r\nimages using deep learning. Preprint at https://arxiv.org/abs/2304.\r\n04738 (2023).\r\n\r\n18. Chen, J., Bai, X. Learning to\" segment anything\" in thermal infrared\r\n\r\nimages through knowledge distillation with a large scale dataset\r\nSATIR. Preprint at https://arxiv.org/abs/2304.07969 (2023).\r\n19. Tang, L., Xiao, H., Li, B. Can SAM segment anything? when SAM\r\n\r\nmeets camou\ufb02aged object detection. Preprint at https://arxiv.org/\r\nabs/2304.04709 (2023).\r\n\r\n20. Ji, G.-P. et al. SAM struggles in concealed scenes\u2013empirical study\r\non\u201d segment anything\u201d. Science China Information Sciences. 66,\r\n226101 (2023).\r\nJi, W., Li, J., Bi, Q., Li, W., Cheng, L. Segment anything is not always\r\nperfect: an investigation of SAM on different real-world applica-\r\ntions. Preprint at https://arxiv.org/abs/2304.05750 (2023).\r\n22. Mazurowski, M. A. Segment anything model for medical image\r\n\r\n21.\r\n\r\nanalysis: an experimental study. Med. Image Anal. 89,\r\n102918 (2023).\r\n\r\n23. Huang, Y. et al. Segment anything model for medical images? Med.\r\n\r\nImage Anal. 92, 103061 (2024).\r\n\r\n24. Chen, L.-C., Zhu, Y., Papandreou, G., Schroff, F., Adam, H. Encoder-\r\ndecoder with atrous separable convolution for semantic image\r\nsegmentation. In Proc. European Conference on Computer Vision.\r\n801\u2013818 (IEEE, 2018).\r\n\r\n25. Dosovitskiy, A. et al. An image is worth 16x16 words: transformers\r\nfor image recognition at scale. In: International Conference on\r\nLearning Representations (OpenReview.net, 2020).\r\n\r\n26. Tancik, M. Fourier features let networks learn high frequency\r\nfunctions in low-dimensional domains. In Advances in Neural\r\nInformation Processing Systems 33, 7537\u20137547 (Curran Associates,\r\nInc., 2020).\r\n\r\n27. Vaswani, A. et al. Attention is all you need. In Advances in Neural\r\nInformation Processing Systems, Vol. 30 (Curran Associates,\r\nInc., 2017).\r\n\r\n28. He, B. Blinded, randomized trial of sonographer versus AI cardiac\r\n\r\nfunction assessment. Nature 616, 520\u2013524 (2023).\r\n\r\n29. Eisenhauer, E. A. New response evaluation criteria in solid tumours:\r\n\r\nrevised recist guideline (version 1.1). Eur. J. Cancer 45,\r\n228\u2013247 (2009).\r\n\r\n30. Ma, J. & Wang, B. Towards foundation models of biological image\r\n\r\nsegmentation. Nat. Method. 20, 953\u2013955 (2023).\r\n\r\n9. Wang, G. Interactive medical image segmentation using deep\r\n\r\n31. Ma, J. et al. The multi-modality cell segmentation challenge:\r\n\r\nlearning with image-speci\ufb01c \ufb01ne tuning. In IEEE Transactions on\r\nMedical Imaging 37, 1562\u20131573 (IEEE, 2018).\r\n\r\ntowards universal solutions. Preprint at https://arxiv.org/abs/2308.", "mimetype": "text/plain", "start_char_idx": 43244, "end_char_idx": 46487, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d03f4b53-cdfb-420b-b0c3-67a326a87a8b": {"__data__": {"id_": "d03f4b53-cdfb-420b-b0c3-67a326a87a8b", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "3ccbb700050d207c687b2f5c787fc41740ff215ab40d53230572ee2b0218052c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7d19aff2-ace2-467e-800a-686d47ab519b", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "f4332abe435f78931e517781d22a3e6b7f60f2336c164a4864505d891181400d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ec18cb2e-8f9e-4c3a-9fe1-98a404dca07f", "node_type": "1", "metadata": {}, "hash": "676218462fc1fea418066c745d942251568b3280d87abc04491f064b69687cc9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Nature 616, 520\u2013524 (2023).\r\n\r\n29. Eisenhauer, E. A. New response evaluation criteria in solid tumours:\r\n\r\nrevised recist guideline (version 1.1). Eur. J. Cancer 45,\r\n228\u2013247 (2009).\r\n\r\n30. Ma, J. & Wang, B. Towards foundation models of biological image\r\n\r\nsegmentation. Nat. Method. 20, 953\u2013955 (2023).\r\n\r\n9. Wang, G. Interactive medical image segmentation using deep\r\n\r\n31. Ma, J. et al. The multi-modality cell segmentation challenge:\r\n\r\nlearning with image-speci\ufb01c \ufb01ne tuning. In IEEE Transactions on\r\nMedical Imaging 37, 1562\u20131573 (IEEE, 2018).\r\n\r\ntowards universal solutions. Preprint at https://arxiv.org/abs/2308.\r\n05864 (2023).\r\n\r\n10. Zhou, T. Volumetric memory network for interactive medical image\r\n\r\n32. Xie, R., Pang, K., Bader, G.D., Wang, B. Maester: masked auto-\r\n\r\n11.\r\n\r\nsegmentation. Med. Image Anal. 83, 102599 (2023).\r\nLuo, X. Mideepseg: Minimally interactive segmentation of unseen\r\nobjects from medical images using deep learning. Med. Image Anal.\r\n72, 102102 (2021).\r\n\r\n12. Deng, R. et al. Segment anything model (SAM) for digital pathology:\r\nassess zero-shot segmentation on whole slide imaging. Preprint at\r\nhttps://arxiv.org/abs/2304.04155 (2023).\r\n\r\n13. Hu, C., Li, X. When SAM meets medical images: an investigation of\r\nsegment anything model (SAM) on multi-phase liver tumor seg-\r\nmentation. Preprint at https://arxiv.org/abs/2304.08506\r\n(2023).\r\n\r\n14. He, S., Bao, R., Li, J., Grant, P.E., Ou, Y. Accuracy of segment-\r\n\r\nanything model (SAM) in medical image segmentation tasks. Pre-\r\nprint at https://doi.org/10.48550/arXiv.2304.09324 (2023).\r\n\r\nencoder guided segmentation at pixel resolution for accurate, self-\r\nsupervised subcellular structure recognition. In IEEE Conference on\r\nComputer Vision and Pattern Recognition. 3292\u20133301 (IEEE, 2023).\r\n33. Bera, K., Braman, N., Gupta, A., Velcheti, V. & Madabhushi, A. Pre-\r\ndicting cancer outcomes with radiomics and arti\ufb01cial intelligence in\r\nradiology. Nat. Rev. Clin. Oncol. 19, 132\u2013146 (2022).\r\n\r\n34. Clark, K. The cancer imaging archive (TCIA): maintaining and\r\n\r\noperating a public information repository. J. Digit. Imaging 26,\r\n1045\u20131057 (2013).\r\n\r\n35. Ba, J.L., Kiros, J.R., Hinton, G.E. Layer normalization. Preprint at\r\n\r\nhttps://arxiv.org/abs/1607.06450 (2016).\r\n\r\n36. He, K. et al. Masked autoencoders are scalable vision learners. In\r\nProc. IEEE/CVF Conference on Computer Vision and Pattern\r\nRecognition. 16000\u201316009 (IEEE, 2022).\r\n\r\nNature Communications |\r\n\r\n (2024) 15:654\r\n\r\n8\r\n\r\n\fArticle\r\n\r\nhttps://doi.org/10.1038/s41467-024-44824-z\r\n\r\n37. Loshchilov, I., Hutter, F. Decoupled weight decay regularization. In\r\nInternational Conference on Learning Representations (Open-\r\nReview.net, 2019).\r\n\r\n39.\r\n\r\n38. He, K., Zhang, X., Ren, S., Sun, J. Deep residual learning for image\r\nrecognition. In Proc. IEEE Conference on Computer Vision and Pat-\r\ntern Recognition. 770\u2013778 (IEEE, 2016).\r\nIakubovskii, P. Segmentation models pytorch. GitHub https://\r\ngithub.com/qubvel/segmentation_models.pytorch (2019).\r\n40. Milletari, F., Navab, N., Ahmadi, S.-A. V-net: Fully convolutional\r\nneural networks for volumetric medical image segmentation.", "mimetype": "text/plain", "start_char_idx": 45866, "end_char_idx": 48996, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ec18cb2e-8f9e-4c3a-9fe1-98a404dca07f": {"__data__": {"id_": "ec18cb2e-8f9e-4c3a-9fe1-98a404dca07f", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "3ccbb700050d207c687b2f5c787fc41740ff215ab40d53230572ee2b0218052c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d03f4b53-cdfb-420b-b0c3-67a326a87a8b", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "071b7c4a591beee60bc9fbb306ac75c9ac0a09c9521689f0f4e632f3276714ad", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2b7ca07d-a1ac-4b2f-889a-cce7b1d390b3", "node_type": "1", "metadata": {}, "hash": "fb393f4c3d5c932a7c2c78f90143af4965110b8381ce6cb63926919734c2364c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Loshchilov, I., Hutter, F. Decoupled weight decay regularization. In\r\nInternational Conference on Learning Representations (Open-\r\nReview.net, 2019).\r\n\r\n39.\r\n\r\n38. He, K., Zhang, X., Ren, S., Sun, J. Deep residual learning for image\r\nrecognition. In Proc. IEEE Conference on Computer Vision and Pat-\r\ntern Recognition. 770\u2013778 (IEEE, 2016).\r\nIakubovskii, P. Segmentation models pytorch. GitHub https://\r\ngithub.com/qubvel/segmentation_models.pytorch (2019).\r\n40. Milletari, F., Navab, N., Ahmadi, S.-A. V-net: Fully convolutional\r\nneural networks for volumetric medical image segmentation. In\r\nInternational Conference on 3D Vision (3DV). 565\u2013571\r\n(IEEE, 2016).\r\n\r\n41. Ma, J. Loss odyssey in medical image segmentation. Med. Image\r\n\r\nAnal. 71, 102035 (2021).\r\n\r\n42. Ahmed, A. Radiomic mapping model for prediction of Ki-67\r\nexpression in adrenocortical carcinoma. Clin. Radiol. 75,\r\n479\u201317 (2020).\r\n\r\n43. Moawad, A.W. et al. Voxel-level segmentation of pathologically-\r\n\r\nAuthor contributions\r\nConceived and designed the experiments: J.M. Y.H., C.Y., B.W. Per-\r\nformed the experiments: J.M. Y.H., F.L., L.H., C.Y. Analyzed the data: J.M.\r\nY.H., F.L., L.H., C.Y., B.W. Wrote the paper: J.M. Y.H., F.L., L.H., C.Y., B.W.\r\nAll authors have read and agreed to the published version of the\r\nmanuscript.\r\n\r\nCompeting interests\r\nThe authors declare no competing interests\r\n\r\nAdditional information\r\nSupplementary information The online version contains\r\nsupplementary material available at\r\nhttps://doi.org/10.1038/s41467-024-44824-z.\r\n\r\nCorrespondence and requests for materials should be addressed to Bo\r\nWang.\r\n\r\nproven Adrenocortical carcinoma with Ki-67 expression (Adrenal-\r\nACC-Ki67-Seg) [data set]. https://doi.org/10.7937/1FPG-\r\nVM46 (2023).\r\n\r\nPeer review information Nature Communications thanks David Ouyang,\r\nand the other, anonymous, reviewer(s) for their contribution to the peer\r\nreview of this work. A peer review \ufb01le is available.\r\n\r\n44. Yushkevich, P.A., Gao, Y., Gerig, G. Itk-snap: an interactive tool for\r\n\r\nsemi-automatic segmentation of multi-modality biomedical ima-\r\nges. In International Conference of the IEEE Engineering in Medicine\r\nand Biology Society (EMBC). 3342\u20133345 (IEEE, 2016).\r\n\r\n45. Maier-Hein, L. et al. Metrics reloaded: Pitfalls and recommendations\r\nfor image analysis validation. Preprint at https://arxiv.org/abs/\r\n2206.01653 (2022).\r\n\r\n46. DeepMind surface-distance. https://github.com/google-\r\n\r\ndeepmind/surface-distance (2018).\r\n\r\n47. Ma, J. bowang-lab/MedSAM: v1.0.0. https://doi.org/10.5281/\r\n\r\nzenodo.10452777 (2023).\r\n\r\nAcknowledgements\r\nThis work was supported by the Natural Sciences and Engineering\r\nResearch Council of Canada (NSERC, RGPIN-2020-06189 and DGECR-\r\n2020-00294) and CIFAR AI Chair programs. The authors of this paper\r\nhighly appreciate all the data owners for providing public medical\r\nimages to the community. We also thank Meta AI for making the source\r\ncode of segment anything publicly available to the community. This\r\nresearch was enabled in part by computing resources provided by the\r\nDigital Research Alliance of Canada.\r\n\r\nReprints and permissions information is available at\r\nhttp://www.nature.com/reprints\r\n\r\nPublisher\u2019s note Springer Nature remains neutral with regard to jur-\r\nisdictional claims in published maps and institutional af\ufb01liations.", "mimetype": "text/plain", "start_char_idx": 48407, "end_char_idx": 51727, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2b7ca07d-a1ac-4b2f-889a-cce7b1d390b3": {"__data__": {"id_": "2b7ca07d-a1ac-4b2f-889a-cce7b1d390b3", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e2ab657e-8ac1-43f7-945b-9980a8e9ee95", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "3ccbb700050d207c687b2f5c787fc41740ff215ab40d53230572ee2b0218052c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ec18cb2e-8f9e-4c3a-9fe1-98a404dca07f", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "93911979e299c4d40ced2fb862a071f2812a5215cab7613677fd32d47efef5e3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Ma, J. bowang-lab/MedSAM: v1.0.0. https://doi.org/10.5281/\r\n\r\nzenodo.10452777 (2023).\r\n\r\nAcknowledgements\r\nThis work was supported by the Natural Sciences and Engineering\r\nResearch Council of Canada (NSERC, RGPIN-2020-06189 and DGECR-\r\n2020-00294) and CIFAR AI Chair programs. The authors of this paper\r\nhighly appreciate all the data owners for providing public medical\r\nimages to the community. We also thank Meta AI for making the source\r\ncode of segment anything publicly available to the community. This\r\nresearch was enabled in part by computing resources provided by the\r\nDigital Research Alliance of Canada.\r\n\r\nReprints and permissions information is available at\r\nhttp://www.nature.com/reprints\r\n\r\nPublisher\u2019s note Springer Nature remains neutral with regard to jur-\r\nisdictional claims in published maps and institutional af\ufb01liations.\r\n\r\nOpen Access This article is licensed under a Creative Commons\r\nAttribution 4.0 International License, which permits use, sharing,\r\nadaptation, distribution and reproduction in any medium or format, as\r\nlong as you give appropriate credit to the original author(s) and the\r\nsource, provide a link to the Creative Commons licence, and indicate if\r\nchanges were made. The images or other third party material in this\r\narticle are included in the article\u2019s Creative Commons licence, unless\r\nindicated otherwise in a credit line to the material. If material is not\r\nincluded in the article\u2019s Creative Commons licence and your intended\r\nuse is not permitted by statutory regulation or exceeds the permitted\r\nuse, you will need to obtain permission directly from the copyright\r\nholder. To view a copy of this licence, visit http://creativecommons.org/\r\nlicenses/by/4.0/.\r\n\r\n\u00a9 The Author(s) 2024\r\n\r\nNature Communications |\r\n\r\n (2024) 15:654\r\n\r\n9", "mimetype": "text/plain", "start_char_idx": 50883, "end_char_idx": 52668, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1695f3cd-7f0c-45cf-b40e-fffeb198943d": {"__data__": {"id_": "1695f3cd-7f0c-45cf-b40e-fffeb198943d", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9bfb63cb-3192-435e-96d4-ed9c95aba53f", "node_type": "1", "metadata": {}, "hash": "65c7daa1eff63bf9d292949c5e7684609af2d534607d6a4304bcba4d6f03eb80", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Education and Information Technologies\r\nhttps://doi.org/10.1007/s10639-024-13169-x\r\n\r\nYoung children\u2019s understanding of\u00a0AI\r\n\r\nDagmar\u00a0Mercedes\u00a0Heeg1\r\n\r\n\u00a0\u00b7 Lucy\u00a0Avraamidou1\r\n\r\nReceived: 7 June 2024 / Accepted: 7 November 2024\r\n\u00a9 The Author(s) 2024\r\n\r\nAbstract\r\nAI has become integral to daily life. Teaching, learning, and research are no excep-\r\ntion. However, most studies on education have approached AI as a technology and\r\nfocused mostly on learning outcomes rather than understanding student engagement\r\nand sense-making of AI as a socio-cultural tool with impact on their daily lives. To\r\naddress  this  gap  in  the  knowledge  base,  we  performed  a  qualitative  case  study  to\r\nexplore young children\u2019s conceptualization of AI not only as a technology but also\r\nas a tool utilised in their everyday lives. We collected data through semi-structured\r\ngroup  interviews  with  eighteen  children  aged  11  to  12  and  thematically  analyzed\r\nthe data through a combination of deductive and inductive coding techniques. The\r\nfindings  suggest  that:  a)  children\u2019s  conceptualizations  of  AI  as  a  technology  are\r\ngrounded in their personal experiences; b) children have a socio-cultural approach\r\nto AI in which they experience and understand AI as first and foremost a supportive\r\ntool; and, c) children exhibit a high level of engagement with ethics of AI, showing\r\na keen interest in the socio-cultural implications, particularly about AI applications\r\nwith which they are familiar. Based on these findings and grounded within existing\r\nliterature, we offer a set of recommendations for the design of engaging and person-\r\nally relevant AI education curriculum materials for young children with critical AI\r\nliteracy at the forefront.\r\n\r\nKeywords  AI education\u00a0\u00b7 AI ethics\u00a0\u00b7 AI literacy\u00a0\u00b7 Young children\r\n\r\n1  Introduction\r\n\r\nWith  the  rapid  expansion  of  Artificial  intelligence  (AI)  in  industry,  education,\r\nand  everyday  life,  children  are  living  in  and  facing  an  increasingly  AI-powered\r\nsociety.  In  the  last  decade,  researchers  have  explored  AI\u2019s  potential  to  address\r\n\r\n *  Dagmar Mercedes Heeg\r\nd.m.heeg@rug.nl\r\n\r\n1  University of\u00a0Groningen, Nijenborgh 7, Groningen\u00a09747AG, Kingdom\u00a0of\u00a0the\u00a0Netherlands\r\n\r\nVol.:(0123456789)\r\n\fEducation and Information Technologies\r\n\r\neducational challenges (e.g. achievement gaps, unequity, high workload) through\r\ntools such as intelligent tutoring systems, chatbots, or automated feedback mod-\r\nels  (Heeg  &  Avraamidou,  2023).  More  recently,  research  efforts  have  shifted\r\nfrom  teaching  \u2018with\u2019  AI,  to  teaching  \u2018about\u2019  AI,  as  contemporary  reform  docu-\r\nments have widely called for \u2018AI literacy\u2019 as a new set of skills and competencies\r\nthat  future  student  generations  need  to  responsibly  and  ethically  function  in  an\r\nAI-powered society (OECD, 2021; UNESCO, 2022).\r\n\r\nAs a response, all around the world, attention is placed on developing AI educa-\r\ntion for schools (e.g. Casal-Otero et\u00a0al., 2023; Su et\u00a0al., 2023a, b; Yue et\u00a0al., 2022).\r\nIn China, AI education is part of the mandatory high school curriculum and a series\r\nof seven AI textbooks is already available for elementary, middle, and high schools\r\n(Chen & Tang, 2018; Xiong et\u00a0al., 2018). In the rest of the world, no national AI\r\ncurricula have yet been implemented. However, increasing efforts are put into creat-\r\ning AI literacy frameworks and educational materials that can help teachers intro-\r\nduce AI into their classrooms. For instance, in the United States, the AI4K12 project\r\nidentified  \u2018Five  big  ideas  in  AI\u2019  and  organized  K-12  frameworks  around  them,  to\r\nserve as guidelines for AI curricula development (Touretzky et\u00a0al., 2019).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3736, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9bfb63cb-3192-435e-96d4-ed9c95aba53f": {"__data__": {"id_": "9bfb63cb-3192-435e-96d4-ed9c95aba53f", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1695f3cd-7f0c-45cf-b40e-fffeb198943d", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "01273f60cb19935a9bd665e15b7e101d1f412d62777c48b91fe317a19f861c48", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "86b17884-16bb-46d7-92d3-094ec8dcfcc7", "node_type": "1", "metadata": {}, "hash": "cfbf83e0bed29ee7d00732fefead0da511b8720365f7b14dfbf50bbb52a03afe", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In China, AI education is part of the mandatory high school curriculum and a series\r\nof seven AI textbooks is already available for elementary, middle, and high schools\r\n(Chen & Tang, 2018; Xiong et\u00a0al., 2018). In the rest of the world, no national AI\r\ncurricula have yet been implemented. However, increasing efforts are put into creat-\r\ning AI literacy frameworks and educational materials that can help teachers intro-\r\nduce AI into their classrooms. For instance, in the United States, the AI4K12 project\r\nidentified  \u2018Five  big  ideas  in  AI\u2019  and  organized  K-12  frameworks  around  them,  to\r\nserve as guidelines for AI curricula development (Touretzky et\u00a0al., 2019). Research-\r\ners at the Massachusetts Institute of Technology (MIT) developed a collection of AI\r\nlessons and tools to engage middle schoolers with the social and ethical implications\r\nof AI (Williams et\u00a0al., 2022). Similarly in Europe, the Erasmus + project GENERA-\r\nTION AI developed an AI introductory course for primary school children available\r\nin various European languages. Germany launched a national initiative that included\r\na 6-module AI course (Micheuz, 2020), and in the Netherlands, which defines the\r\ncontext of this study, a series of \u2018National courses are available for school teachers,\r\nwith different themes, such as AI in healthcare and AI in education.\r\n\r\nAs  these  projects  are  a  few  examples  of  pioneering  the  development  of  educa-\r\ntional materials and implementing them is novel, consequently, there exists a gap in\r\nthe knowledge base regarding students\u2019 understanding of AI, particularly as a socio-\r\ncultural tool with ethical implications. This gap also exists in the context of primary\r\nschools,  where  it  is  especially  relevant  because  of  the  wide  variety  of  young  chil-\r\ndren\u2019s  interests,  capabilities,  and  prior  experiences,  presenting  a  unique  challenge\r\nto  curriculum  development.  To  design  effective  and  meaningful  AI  curricula  that\r\nresonate with all learners, an in-depth understanding of children\u2019s engagement and\r\nsense-making of AI is needed to inform future curriculum design initiatives. This is\r\nprecisely what the purpose of the single case study reported in this paper is about; to\r\nexplore young children\u2019s understanding of AI.\r\n\r\n2   Theoretical and\u00a0empirical underpinnings\r\n\r\n2.1   AI literacy\r\n\r\nAI literacy is part of the 21st-century skills that can enhance living standards, learn-\r\ning and working effectiveness, employability, and support citizens in becoming criti-\r\ncal consumers of this technology (Ng et\u00a0al., 2022a, b; OECD, 2021). The term \u201cAI\r\nliteracy\u201d was first coined by Burgsteiner et\u00a0al. (2016) and Kandlhofer et\u00a0al. (2016),\r\n\r\n\fEducation and Information Technologies\r\n\r\nwho defined it as the ability to understand the techniques and concepts behind AI-\r\ndriven applications and services, instead of just learning how to use them. A related\r\nconceptual framework, inspired by drawing an analogy with classic literacy develop-\r\nment, contains four different stages of AI literacy development, where each stage is\r\nassigned to an educational level starting with building awareness in primary school\r\nto becoming fluent in AI at the university level. As the first conceptual framework\r\nof AI literacy, the work started a conversation on what AI literacy is and what stu-\r\ndents need to learn. Since then, other conceptual frameworks have been conceptual-\r\nized. What follows is a brief overview of three AI literacy frameworks, with each its\r\nfocus, advantages, and challenges.\r\n\r\nA more holistic approach to AI is taken by Kong and Zhang (2021), by shedding\r\nlight  on  both  the  technical  and  socio-cultural  dimensions  of  AI.  The  authors  pro-\r\npose a conceptual framework for AI literacy to empower citizens by promoting AI\r\nliteracy and the ethical use of AI. The framework involves three dimensions. First,\r\nthe cognitive dimension, which focuses on skills and competencies needed to under-\r\nstand  and  evaluate  AI.  Second,  the  affective  dimension  promotes  AI  self-efficacy\r\nand AI perceptions to empower citizens by making them feel AI is personally mean-\r\ningful to them. The final dimension is the socio-cultural dimension, promoting the\r\nethical use of AI.", "mimetype": "text/plain", "start_char_idx": 3059, "end_char_idx": 7323, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "86b17884-16bb-46d7-92d3-094ec8dcfcc7": {"__data__": {"id_": "86b17884-16bb-46d7-92d3-094ec8dcfcc7", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9bfb63cb-3192-435e-96d4-ed9c95aba53f", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "a4f454d1e2b5269ee951e996440b66ba2be4d048a24be2477ebca6226ae3fb21", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "480cb991-6583-422d-8cd9-ba9cb55fe9a8", "node_type": "1", "metadata": {}, "hash": "2e06076f9ef1cfb0fcf5640243183cf5cbd28f568a436c45f7c10f9220293c4d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Since then, other conceptual frameworks have been conceptual-\r\nized. What follows is a brief overview of three AI literacy frameworks, with each its\r\nfocus, advantages, and challenges.\r\n\r\nA more holistic approach to AI is taken by Kong and Zhang (2021), by shedding\r\nlight  on  both  the  technical  and  socio-cultural  dimensions  of  AI.  The  authors  pro-\r\npose a conceptual framework for AI literacy to empower citizens by promoting AI\r\nliteracy and the ethical use of AI. The framework involves three dimensions. First,\r\nthe cognitive dimension, which focuses on skills and competencies needed to under-\r\nstand  and  evaluate  AI.  Second,  the  affective  dimension  promotes  AI  self-efficacy\r\nand AI perceptions to empower citizens by making them feel AI is personally mean-\r\ningful to them. The final dimension is the socio-cultural dimension, promoting the\r\nethical use of AI. Expanding the framework beyond the technical dimension of AI is\r\nmodern and AI attitudes and AI self-efficacy constructs to empower citizens receive\r\nincreasing attention in the literature (e.g. Schepman & Rodway, 2023; Wang et\u00a0al.,\r\n2023). However, Kong and Zhang do not offer a set of concrete competencies that\r\ncan be used to design AI literacy instructions or explore or assess their three dimen-\r\nsions of AI literacy.\r\n\r\nFocusing  more  on  cognitive  development,  Ng  et\u00a0 al.  (2021)  conceptualized  AI\r\nby  building  on  the  classic  educational  model  of  Bloom\u2019s  taxonomy.  Through  an\r\nexplorative review, they reviewed how 30 studies define AI literacy and synthesized\r\nthese different AI literacy definitions into different levels of cognitive processes in\r\nAI  learning,  each  associated  with  a  different  taxonomy  level.  These  levels  require\r\na  higher  level  of  complexity  and  ordered  thinking  from  students,  and  are  succes-\r\nsive so that one level must be mastered before the next level can be reached. From\r\nthe  bottom  upwards,  Ng  et\u00a0 al.  determined  the  levels  to  be  \u2018Know  and  Understand\r\nAI\u2019, \u2018Use and Apply AI\u2019, and the highest level\u2019Evaluate and Create AI\u2019. Moreover,\r\nthey  conclude  emphasis  on  the  ethical  use  of  AI  is  needed.  With  this  framework,\r\nNg  et\u00a0 al.  are  the  first  to  bring  classic  educational  models  to  AI  literacy.  Bloom\u2019s\r\ntaxonomy  was  initially  created  in  the  1950s,  and  originally  it  endured  popularity\r\nbecause it provides a structured framework for educators to design learning objec-\r\ntives and assessments. However, some critics argue that the hierarchical structure of\r\nthe model is too rigid and that learning is more complex and dynamic, and individu-\r\nals may engage in higher-order thinking without mastering lower-level skills first.\r\n\r\nA more contemporary and widely used framework of AI literature has been devel-\r\noped by Long and Magerko (2020). Following a scoping study of existing research\r\nto synthesize what AI professionals believe all citizens should know and common\r\nperceptions  and  misconceptions  among  learners,  the  researchers  conceptualize  AI\r\nliteracy  through  five  overarching  competencies:  what  is  AI,  what  can  AI  do,  how\r\ndoes AI work, how should it be used, and how is it perceived. Additionally, Long\r\n\r\n\fEducation and Information Technologies\r\n\r\nand Magerko formulated 17 competencies that should be acquired to be AI literate\r\n(Table\u00a01). For educators, the conceptual framework\u00a0comes with 16 design consid-\r\nerations to support the design of AI education.\r\n\r\nAlthough this conceptual framework offers concrete design guidelines and com-\r\npetencies  for  educators,  it  is  predominantly  focused  on  the  technical  dimension  of\r\nAI, as evidenced by the fact that 16 out of 17 competencies focus on technology. Lit-\r\ntle attention is given to the socio-cultural dimension of AI.\r\n\r\nIn  the  pursuit  of  understanding  primary  school  students\u2019  conceptualization  of\r\nAI,  this  exploratory  study  adopts  a  comprehensive  approach  by  drawing  on  these\r\nvarious conceptual frameworks and framing them within socio-cultural theories of\r\nlearning emphasizing social interaction.", "mimetype": "text/plain", "start_char_idx": 6434, "end_char_idx": 10572, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "480cb991-6583-422d-8cd9-ba9cb55fe9a8": {"__data__": {"id_": "480cb991-6583-422d-8cd9-ba9cb55fe9a8", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "86b17884-16bb-46d7-92d3-094ec8dcfcc7", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "4ae8386bcf72a7db67472704c7014bf2ec0de5b2fd514e46a61a77e0274e79c7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9f916a12-0c72-426d-8ddb-487b25506219", "node_type": "1", "metadata": {}, "hash": "2a4cca7a2f8f910573bf2efb6686442bab406a7db85d1c41ccb6a46e15c25b56", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Additionally, Long\r\n\r\n\fEducation and Information Technologies\r\n\r\nand Magerko formulated 17 competencies that should be acquired to be AI literate\r\n(Table\u00a01). For educators, the conceptual framework\u00a0comes with 16 design consid-\r\nerations to support the design of AI education.\r\n\r\nAlthough this conceptual framework offers concrete design guidelines and com-\r\npetencies  for  educators,  it  is  predominantly  focused  on  the  technical  dimension  of\r\nAI, as evidenced by the fact that 16 out of 17 competencies focus on technology. Lit-\r\ntle attention is given to the socio-cultural dimension of AI.\r\n\r\nIn  the  pursuit  of  understanding  primary  school  students\u2019  conceptualization  of\r\nAI,  this  exploratory  study  adopts  a  comprehensive  approach  by  drawing  on  these\r\nvarious conceptual frameworks and framing them within socio-cultural theories of\r\nlearning emphasizing social interaction. This approach is deemed appropriate for an\r\nexploratory study, given that our purpose is not to test a predetermined hypothesis\r\nbut to generate insights that inform the design of personally relevant and meaningful\r\nAI education materials for primary schools.\r\n\r\n2.2   Children\u2019s understanding of\u00a0AI\r\n\r\nAn examination of the literature shows that before any AI education, young children\r\nstart conceptualizing AI through exposure to media representations of AI or experi-\r\nences  with  AI-enabled  devices  at  home  (Druga  et\u00a0 al.,  2017;  Szczuka  et\u00a0 al.,  2022;\r\nWilliams et\u00a0al., 2019). Some children frequently engage with voice assistants such\r\nas  Hey  Google  or  Siri.  Moreover,  their  interactions  extend  to  popular  digital  plat-\r\nforms like TikTok and YouTube, where algorithms dynamically tailor online content\r\nto align with their individual preferences. Additionally, children actively explore the\r\nfunctionalities  of  generative  AI  models,  such  as  ChatGPT  or  DALL-E,  leveraging\r\nthese technologies to compose text and generate images. Collectively, these interac-\r\ntions contribute to the development of their AI understanding and shape their atti-\r\ntudes toward the technology (Ottenbreit-Leftwich\u00a0et al., 2022) and hence AI concep-\r\ntions, before starting AI education, can therefore vary as children can have different\r\nexperiences  (Druga  et\u00a0 al.,  2017)  or  unequal  access  to  such  experiences  (UNICEF,\r\n2021). To ensure effective teaching instructions for all children AI educational mate-\r\nrials must tie into these varying prior experiences of children.\r\n\r\nEmpirical evidence shows that children\u2019s existing understanding of AI is that it is\r\nnot a binary concept that can be determined to be right or wrong, as it encompasses\r\na range of perceptions. For example, in a study with 195 Finnish students aged 12 to\r\n13, Mertala et\u00a0al. (2022) showed that students\u2019 initial conceptions of AI are varied\r\nand often uninformed. Data were collected through an online qualitative survey, ask-\r\ning children to describe what AI is, what it is used for, how it works, and why they\r\nthink  AI  is  used.  The  students  described  AI  as  an  autonomous  system,  being  able\r\nto  perform  tasks  on  its  own,  without  the  need  for  human  interference.  They  also\r\nconceptualized  AI  as  programmed,  acknowledging  the  human  role  in  AI  develop-\r\nment.  The  same  students  also  showed  to  have  less  accurate  conceptualizations  of\r\nAI;  assigning  AI  human-like  cognitive  processes,  such  as  knowing  and  thinking.\r\nThese conceptualizations imply an anthropomorphic conception of what AI is. This\r\nis in agreement with the findings of a study conducted by Ottenbreit-Leftwich et\u00a0al.\r\n\r\n\fEducation and Information Technologies\r\n\r\nTable 1   AI literacy competencies adopted by Long and Magerko (2020)\r\n\r\nCompetency\r\n\r\nDescription\r\n\r\nTheme: What is AI?\r\n\r\n 1. Recognizing AI\r\n\r\nDistinguish between technological artifacts that use and do not\r\n\r\nuse AI\r\n\r\n 2. Understanding Intelligence\r\n\r\nCritically analyze and discuss features that make an entity\r\n\r\n 3. Interdisciplinarity\r\n\r\n 4. General vs. Narrow\r\n\r\nTheme: What can AI do?\r\n\r\n 5.", "mimetype": "text/plain", "start_char_idx": 9666, "end_char_idx": 13763, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9f916a12-0c72-426d-8ddb-487b25506219": {"__data__": {"id_": "9f916a12-0c72-426d-8ddb-487b25506219", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "480cb991-6583-422d-8cd9-ba9cb55fe9a8", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "fa8f78da68615ec12b79a1664181c95196b33c5b1c37da98a768406a615a98cb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "220c3479-912f-465d-a016-8163e001695b", "node_type": "1", "metadata": {}, "hash": "04be9642ba24044e445ffd468cae8cc9f257c6f86f28b98cace1e2e7e70fcad7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The  same  students  also  showed  to  have  less  accurate  conceptualizations  of\r\nAI;  assigning  AI  human-like  cognitive  processes,  such  as  knowing  and  thinking.\r\nThese conceptualizations imply an anthropomorphic conception of what AI is. This\r\nis in agreement with the findings of a study conducted by Ottenbreit-Leftwich et\u00a0al.\r\n\r\n\fEducation and Information Technologies\r\n\r\nTable 1   AI literacy competencies adopted by Long and Magerko (2020)\r\n\r\nCompetency\r\n\r\nDescription\r\n\r\nTheme: What is AI?\r\n\r\n 1. Recognizing AI\r\n\r\nDistinguish between technological artifacts that use and do not\r\n\r\nuse AI\r\n\r\n 2. Understanding Intelligence\r\n\r\nCritically analyze and discuss features that make an entity\r\n\r\n 3. Interdisciplinarity\r\n\r\n 4. General vs. Narrow\r\n\r\nTheme: What can AI do?\r\n\r\n 5. AI\u2019s Strengths & Weaknesses\r\n\r\n\u201cintelligent\u201d, including discussing differences between human,\r\nanimal, and machine intelligence\r\n\r\nRecognize that there are many ways to think about and develop\r\n\u201cintelligent\u201d machines. Identify a variety of technologies that\r\nuse AI, including technology spanning cognitive systems,\r\nrobotics, and ML\r\n\r\nDistinguish between general and narrow AI\r\n\r\nIdentify problem types that AI excels at and problems that are\r\nmore challenging for AI. Use this information to determine\r\nwhen it is appropriate to use AI and when to leverage human\r\nskills\r\n\r\n 6. Imagine the Future of AI\r\n\r\nImagine possible future applications of AI and consider the\r\n\r\neffects of such applications on the world\r\n\r\nTheme: How does AI work?\r\n\r\n 7. Representations\r\n\r\nUnderstand what a knowledge representation is and describe\r\n\r\nsome examples of knowledge representations\r\n\r\n 8. Decision-Making\r\n\r\nRecognize and describe examples of how computers reason and\r\n\r\nmake decisions\r\n\r\n 9. Machine Learning Steps\r\n\r\nUnderstand the steps involved in machine learning and the prac-\r\n\r\ntices and challenges that each step entails\r\n\r\n 10. Human role in AI\r\n\r\nRecognize that humans play an important role in programming,\r\n\r\nchoosing models, and fine-tuning AI systems\r\n\r\n 11. Data literacy\r\n\r\nUnderstand basic data literacy concepts\r\n\r\n 12. Learning from Data\r\n\r\nRecognize that computers often learn from data (including one\u2019s\r\n\r\ndata)\r\n\r\n 13. Critically Interpreting Data\r\n\r\nUnderstand that data cannot be taken at face value and requires\r\n\r\n 14. Action & Reaction\r\n\r\n 15. Sensors\r\n\r\nTheme: How should AI be used?\r\n\r\n 16. Ethics\r\n\r\ninterpretation. Describe how the training examples provided in\r\nan initial dataset can affect the results of an algorithm\r\n\r\nUnderstand that some AI systems have the ability to physically\r\nact on the world. This action can be directed by higher-level\r\nreasoning (e.g. walking along a planned path) or it can be reac-\r\ntive (e.g. jumping backward to avoid a sensed obstacle)\r\n\r\nUnderstand what sensors are, recognize that computers perceive\r\nthe world using sensors, and identify sensors on a variety of\r\ndevices. Recognize that different sensors support different\r\ntypes of representation and reasoning about the world\r\n\r\nIdentify and describe different perspectives on the key ethical\r\n\r\nissues surrounding AI (i.e. privacy, employment, misinforma-\r\ntion, the singularity, ethical decision-making, diversity, bias,\r\ntransparency, accountability)\r\n\r\nTheme: How do people perceive AI?\r\n\r\n 17. Programmability\r\n\r\nUnderstand that agents are programmable\r\n\r\n\fEducation and Information Technologies\r\n\r\n(2022),  who  explored  the  existing  understanding  and  interests  of  young  learners\r\nabout AI in the context of the US. Through one-on-one semi-structured interviews.\r\nTen students, aged 9 to 11, were asked to elaborate on what AI means, and how it\r\nworks, and to share examples of AI. Nine of the ten described AI to involve coding\r\nor programming. Moreover, the researchers noticed that at times, students described\r\nAI to be preprogrammed, making it a human-made artifact, while other times, attrib-\r\nuting anthropomorphic, life-like characteristics to these devices, using personal pro-\r\nnouns to describe an AI, and thinking it could understand and see them. The idea\r\nof AI being preprogrammed illustrates a lack of a deeper understanding of what AI\r\nis and how it works. Ottenbreit-Leftwich et\u00a0al.", "mimetype": "text/plain", "start_char_idx": 12973, "end_char_idx": 17193, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "220c3479-912f-465d-a016-8163e001695b": {"__data__": {"id_": "220c3479-912f-465d-a016-8163e001695b", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9f916a12-0c72-426d-8ddb-487b25506219", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "51d4118a51a4fe5166e9889cd68ef1c648e5902edfb5354f1524660a3f38c726", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4b75fde5-91b7-46f0-82e6-6d369703c068", "node_type": "1", "metadata": {}, "hash": "8f175a34b159b9bb0f4ffbbb960fbcd1e5eee1c495e0d9b818a6197751ed996c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Through one-on-one semi-structured interviews.\r\nTen students, aged 9 to 11, were asked to elaborate on what AI means, and how it\r\nworks, and to share examples of AI. Nine of the ten described AI to involve coding\r\nor programming. Moreover, the researchers noticed that at times, students described\r\nAI to be preprogrammed, making it a human-made artifact, while other times, attrib-\r\nuting anthropomorphic, life-like characteristics to these devices, using personal pro-\r\nnouns to describe an AI, and thinking it could understand and see them. The idea\r\nof AI being preprogrammed illustrates a lack of a deeper understanding of what AI\r\nis and how it works. Ottenbreit-Leftwich et\u00a0al. (2022) observed a few students who\r\nunderstood AI involves training, however, none of the students were able to give a\r\nmore detailed explanation of how an AI model is trained.\r\n\r\nAnother set of studies provides evidence that students\u2019 awareness of AI applica-\r\ntions in their daily lives is nuanced and not easily characterized as entirely correct\r\nor incorrect. While young children demonstrate proficiency in identifying numerous\r\nAI applications (Mertala et\u00a0al., 2022; Ottenbreit-Leftwich et\u00a0al., 2022), such as voice\r\nassistants, search engines, recommendation software, and autonomous devices, Kim\r\net\u00a0al. (2023) observed students tend to over label automated appliances as instances\r\nof  AI.  During  an  AI  summer  camp,  14  middle  schoolers  were  observed  playing  a\r\ngame  called  \u201cAI  or  not  AI?\u201d.  Students  were  shown  an  everyday  object  and  then\r\nasked to position themselves from 0 (Not AI) to 100 (AI). Once situated, teachers\r\nwould  ask  students  to  share  their  reasoning  for  their  assessment.  Throughout  the\r\nactivity, several students argued that many automated instances were examples of AI\r\nsuch  as  electronic  toll  collection  on  the  highway  using  RFID  technology,  washing\r\nmachines controlled by personal mobile phones using IoT, and industrial robots in\r\nthe factory.\r\n\r\nNotably,  there  exist  conflicting  findings  concerning  students\u2019  understanding  of\r\nthe  ethical  dimension  of  AI.  The  literature  reports  students  who  believe  AI  could\r\nmake lives easier, by helping with certain chores. Especially the lives of sick or dis-\r\nabled  people,  who  could  benefit  from  such  AI  applications  (Mertala  et\u00a0 al.,  2022;\r\nOttenbreit-Leftwich et\u00a0al., 2022). Regarding ethical risks, few students in the Otten-\r\nbreit-Leftwich et\u00a0al. (2022) study, shared concerns regarding cybersecurity, privacy,\r\nand misuse of AI applications. On the contrary, Kim et\u00a0al. (2023) found students not\r\nto worry about AI, believing AI is emotionless and therefore impartial and fair, not\r\nrecognizing any ethical considerations of AI.\r\n\r\nCollectively, the findings of existing studies shed light on the complexity of stu-\r\ndents\u2019  existing  understanding  of  AI  that  they  bring  into  the  classroom.  AI  under-\r\nstanding is not a binary concept that can be determined to be correct or incorrect.\r\nInstead, it encompasses a range of perceptions, as illustrated by the above-described\r\nempirical findings. Research also shows cultural upbringing can influence children\u2019s\r\nperceptions and attitudes toward AI (Long & Magerko, 2020), adding to the com-\r\nplexity of AI literacy development. In recognition of this complexity, in this study,\r\nwe  use  a  qualitative  research  approach  to  explore  primary  school  students\u2019  AI  lit-\r\neracy in depth.\r\n\r\n\fEducation and Information Technologies\r\n\r\n2.3   AI\u2011based educational practices\r\n\r\nEducation,  governments,  and  industry  leaders  have  acknowledged  the  value  of\r\npromoting AI literacy among young learners in primary and secondary education\r\n(Pedro et\u00a0al., 2019; Touretzky et\u00a0al., 2019; UNESCO, 2019). There are currently\r\n14  AI  curricula  endorsed  and  implemented  at  primary  and  secondary  school\r\nlevels  by  governments  in  11  countries  (UNESCO,  2022).", "mimetype": "text/plain", "start_char_idx": 16509, "end_char_idx": 20476, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4b75fde5-91b7-46f0-82e6-6d369703c068": {"__data__": {"id_": "4b75fde5-91b7-46f0-82e6-6d369703c068", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "220c3479-912f-465d-a016-8163e001695b", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "855d93e52b8f587f68c628b2961fd2902672f0f7b4d7de383fb6a1e990e7a00e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "420add2b-8a70-4fbb-b98d-d06feeb0f9b8", "node_type": "1", "metadata": {}, "hash": "e45fa3044d7292935e28cabc33e75e98b16c569609a4f5bff67d85a0db67393e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In recognition of this complexity, in this study,\r\nwe  use  a  qualitative  research  approach  to  explore  primary  school  students\u2019  AI  lit-\r\neracy in depth.\r\n\r\n\fEducation and Information Technologies\r\n\r\n2.3   AI\u2011based educational practices\r\n\r\nEducation,  governments,  and  industry  leaders  have  acknowledged  the  value  of\r\npromoting AI literacy among young learners in primary and secondary education\r\n(Pedro et\u00a0al., 2019; Touretzky et\u00a0al., 2019; UNESCO, 2019). There are currently\r\n14  AI  curricula  endorsed  and  implemented  at  primary  and  secondary  school\r\nlevels  by  governments  in  11  countries  (UNESCO,  2022).  Additionally,  scholars\r\nstarted  to  design  and  implement  AI  learning  activities  in  the  form  of  interven-\r\ntions,  workshops,  or  courses,  and  empirical  studies  on  how  such  teaching  and\r\nlearning efforts can support students in fostering AI literacy. For example, Zhang\r\net\u00a0 al.  (2022)  designed  and  implemented  the  \u201cDeveloping  AI  Literacy\u201d  (DAILy)\r\ncourse  that  aimed  to  develop  AI  literacy  among  middle  school  students  by  cov-\r\nering  age-appropriate  technical  knowledge  and  skills  in  AI,  creating  an  under-\r\nstanding  of  the  ethical  and  societal  implications  of  AI,  and  finally,  by  increas-\r\ning knowledge of AI\u2019s impact on jobs. A group of MIT researchers designed and\r\npilot-tested various AI Ethics activities for middle school students (e.g. Ali et\u00a0al.,\r\n2021; DiPaola et\u00a0al., 2020; Lee et\u00a0al., 2021; Payne, 2020; Williams et\u00a0al., 2022).\r\nVan Brummelen et\u00a0al. (2021) used Long and Magerko\u2019s (2020) conceptual frame-\r\nwork to design an online workshop of five days. Williams et\u00a0al. (2022) pilot-tested\r\nthree  activities  on  generative  adversarial  networks  (GANs),  deep  fakes,  coding,\r\nand supervised machine learning. The activities were meant to increase students\u2019\r\ntechnical  AI  knowledge,  ability  to  think  critically  about  the  implications  of  AI,\r\nand  ability  to  apply  AI  knowledge  to  topics  they  personally  care  about.  Eguchi\r\net\u00a0 al.  (2021)  used  related  MIT-designed  AI + ethics  curricula  and  used  a  cultur-\r\nally  responsive  approach  to  teach  it  by  adapting  the  curricula  to  the  Japanese\r\ncontext. To do this, they changed or added certain AI application examples. For\r\nexample,  YouTube  was  replaced  with  the,  in  Japan  wider  known,  Yahoo.  They\r\nalso added various AI-enhanced devices that are well-known and used in Japan,\r\nsuch as AI-enhanced microwaves, washing machines, and personal service robots.\r\nMoreover,  various  pedagogical  approaches  such  as  problem-based  learning  (Su\r\n& Zhong, 2022), role-playing (Henry et\u00a0al., 2021), and digital story writing (Ng\r\net\u00a0al., 2022a, b) were introduced to develop young children\u2019s AI literacy.\r\n\r\nThis body of research provides insights into the design of AI literacy education\r\nmaterials,  and  the  pedagogical  strategies  tools,  and  resources  used  to  implement\r\nthese  curricula.  A  critical  examination  of  the  knowledge  base  showcases  specific\r\ngaps:  a)  lack  of  qualitative  studies,  b)  lack  of  studies  in  the  context  of  Europe,  c)\r\nfew studies explore learning experiences and processes, and d) few studies approach\r\nAI as a socio-cultural tool. Overall, the existing knowledge base offers merely pre-\r\nliminary insights into the impact of specific curricula on children\u2019s AI literacy. The\r\neffects are often examined by focusing on learning outcomes, using mixed or quanti-\r\ntative methods.", "mimetype": "text/plain", "start_char_idx": 19837, "end_char_idx": 23387, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "420add2b-8a70-4fbb-b98d-d06feeb0f9b8": {"__data__": {"id_": "420add2b-8a70-4fbb-b98d-d06feeb0f9b8", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4b75fde5-91b7-46f0-82e6-6d369703c068", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "068b4f6472edbda278d92d5dc6cf82038644876a584ba99f8c0bd184fccd20b9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0e5d4827-a298-4c37-a190-3cd6d53468a6", "node_type": "1", "metadata": {}, "hash": "bc91bbffbdcb9d825332dd3cae011eb279fd2e53f02b87d941396d0551b32d4b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This body of research provides insights into the design of AI literacy education\r\nmaterials,  and  the  pedagogical  strategies  tools,  and  resources  used  to  implement\r\nthese  curricula.  A  critical  examination  of  the  knowledge  base  showcases  specific\r\ngaps:  a)  lack  of  qualitative  studies,  b)  lack  of  studies  in  the  context  of  Europe,  c)\r\nfew studies explore learning experiences and processes, and d) few studies approach\r\nAI as a socio-cultural tool. Overall, the existing knowledge base offers merely pre-\r\nliminary insights into the impact of specific curricula on children\u2019s AI literacy. The\r\neffects are often examined by focusing on learning outcomes, using mixed or quanti-\r\ntative methods. Qualitative research methods can mostly be found in conference pro-\r\nceedings,  but  offer  only  superficial  preliminary  findings  of  pilot  tests  of  curricula.\r\nWe argue that since only recently AI curricula have been implemented, more atten-\r\ntion  should  be  paid  to  qualitatively  understanding  children\u2019s  understanding  of  AI\r\nand learning experiences rather than solely focusing on learning outcomes. This is\r\nprecisely the purpose of this manuscript.\r\n\r\n\fEducation and Information Technologies\r\n\r\n2.4   Research questions\r\n\r\nAs stated earlier, there exists a lack of qualitative studies exploring children\u2019s under-\r\nstanding of AI that go beyond the technical dimension and address the socio-cultural\r\nnature of AI. In attempting to address this gap in the knowledge base, in the study\r\nreported  in  this  manuscript  we  explore  young  children\u2019s  understanding  of  AI  as  a\r\ntechnology, AI as a tool, and AI as an ethical phenomenon. In doing so, we aim to\r\nrespond to the following research questions:\r\n\r\nRQ1: How do young children understand AI?\r\nRQ2: How do young children understand AI applications in their daily lives?\r\nRQ3: What (if any) ethical risks do young children identify in relation to AI?\r\n\r\nIn responding to these questions, through this study, we aim to contribute to the gap\r\nin existing literature on an in-depth understanding of students\u2019 AI conceptualizations.\r\nWe provide detailed insights into students\u2019 engagement with AI that can be used to sup-\r\nport the design of effective and engaging AI curricula for primary school children.\r\n\r\n3   Methods\r\n\r\n3.1   Research design\r\n\r\nTo  explore  what  AI  themes  and  competencies  are  appropriate  for  primary  school\r\nchildren  we  follow  a  qualitative  case  study  paradigm  with  the  case  being  defined\r\nby  a  group  of  young  children  in  a  school  classroom  (Merriam  &  Tisdell,  2015).\r\nAdopting this paradigm allows us to employ a detailed and in-depth exploration of\r\nstudents\u2019  understanding  of  AI.  Even  though  the  students  in  the  classroom  will  be\r\ntreated as one case, in analyzing the data we apply a constant comparative approach\r\nacross the students to also gain an understanding of their personal understanding.\r\n\r\n3.2   Context and\u00a0participants\r\n\r\nThe  context  of  the  study  was  defined  by  a  primary  school  classroom  of  18  chil-\r\ndren (11\u201312\u00a0years old). The classroom was selected through a purposeful sampling\r\nmethod to ensure: a) the classroom population is representative of the country\u2019s stu-\r\ndent  population,  and  b)  the  teacher  has  background  knowledge  and  interest  in  the\r\nuse of AI tools in teaching and learning. In terms of demographics, typical of the\r\ncountry\u2019s  population,  the  classroom  included  Caucasian  (national)  children  and  a\r\nfew of those with a migration background, mostly Arabic. There were nine boys and\r\nnine girls, all with average to high socio-economic status. We purposefully selected\r\na classroom with a teacher who was knowledgeable enough about AI and was com-\r\nfortable  in  implementing  an  introductory  course  specially  designed  for  this  age\r\ngroup.  The  study  meets  the  ethical  and  legal  requirements  of  the  university  in  the\r\n\r\n\fEducation and Information Technologies\r\n\r\ncountry context where this study is carried out.", "mimetype": "text/plain", "start_char_idx": 22660, "end_char_idx": 26732, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0e5d4827-a298-4c37-a190-3cd6d53468a6": {"__data__": {"id_": "0e5d4827-a298-4c37-a190-3cd6d53468a6", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "420add2b-8a70-4fbb-b98d-d06feeb0f9b8", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "37f8cf802b57f73d6bdf76632b71c0f7d91a33773cbc4f4062fedef90d38f0ab", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "353be917-9355-4d06-bed0-5d0955221b6c", "node_type": "1", "metadata": {}, "hash": "6a4e63a0272b30b11525ea94e07cc14faebfba4b212416c7bb300a4dbc73b857", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In terms of demographics, typical of the\r\ncountry\u2019s  population,  the  classroom  included  Caucasian  (national)  children  and  a\r\nfew of those with a migration background, mostly Arabic. There were nine boys and\r\nnine girls, all with average to high socio-economic status. We purposefully selected\r\na classroom with a teacher who was knowledgeable enough about AI and was com-\r\nfortable  in  implementing  an  introductory  course  specially  designed  for  this  age\r\ngroup.  The  study  meets  the  ethical  and  legal  requirements  of  the  university  in  the\r\n\r\n\fEducation and Information Technologies\r\n\r\ncountry context where this study is carried out. Approval for the study was received\r\nfollowing an application process to the Ethics committee, which included informa-\r\ntion about data privacy, consent, confidentiality, and data protection.\r\n\r\nThe teacher has more than five years of experience, he has a strong interest in digital\r\nliteracy including AI and he has been involved in curriculum design for digital literacy.\r\nThe teacher implemented a five-week-long AI introductory course, based on an AI cur-\r\nriculum developed and pilot-tested as part of an EU-funded project developed by the\r\nresearchers. The course includes 5 lessons on AI definition, voice assistants, machine\r\nlearning, and AI ethics and is centered around the digital learners\u2019 competencies formu-\r\nlated by the Digital Competence Framework for Educators (Redecker, 2017).\r\n\r\nIt is important to note that the course was not used as an intervention but instead as\r\na context for initiating conversations with the students about AI that would help shed\r\nlight on their existing understanding of AI. This is precisely why the course was not\r\nintended to support the construction of new knowledge but to engage students in activi-\r\nties that would support them in making their prior knowledge and thinking visible.\r\n\r\n3.3   Data collection and\u00a0analysis\r\n\r\nThe main research data for this study were collected through five online group inter-\r\nviews  with  the  children.  Conducting  online  interviews  with  children,  as  opposed\r\nto in-person interviews, not only fosters a sense of comfort in their familiar digital\r\nenvironment but also serves as a strategic method to mitigate traditional adult\u2013child\r\npower dynamics. In the virtual setting, children can feel safe to express themselves.\r\nAn illustrative example of this dynamic emerged during interviews where children\r\ndesiring  a  private  exchange,  muted  themselves  for  a  few  seconds  to  communicate\r\nwith each other without the direct presence of the interviewer. This instance show-\r\ncased a self-directed control over the interview space, reflecting a nuanced shift in\r\npower  dynamics  that  supports  children  to  communicate  freely  within  the  digital\r\ncontext. To address limitations of the online interaction in forming bonds with the\r\nchildren, we started each interview with informal conversations that included pres-\r\nentations of ourselves in regards to personal interests and hobbies. To increase our\r\nefforts to make children, especially shy ones, feel at ease during the interviews, we\r\nchose group interviews. Each interview lasted between twenty and thirty minutes.\r\n\r\nThe first author conducted the interviews and acted as a facilitator to create a comfort-\r\nable atmosphere in which all participants felt free to share their voices. The second author\r\nhas more than 15\u00a0years of experience with qualitative research, both as a researcher as\r\nwell as an instructor of advanced qualitative methods courses at the doctoral level. The\r\nsecond author provided training to the first author in interviewing techniques to overcome\r\ncommon limitations of group interviews, such as dominant personalities, silent partici-\r\npants, or students getting off-topic. Techniques such as (a) directing questions at less par-\r\nticipating students, (b) follow-up questions on non-verbal communication from students\r\n(e.g. nodding, facial expressions), and (c) naturally redirecting the conversation.\r\n\r\nThe  interviews  were  semi-structured,  allowing  a  more  natural  conversation  to  take\r\nplace  during  which  the  students  played  a  role  in  navigating  the  direction  of  the  inter-\r\nview. The interview protocol that was used, has been used in similar research with young\r\n\r\n\fEducation and Information Technologies\r\n\r\nchildren in a different context (Avraamidou, 2013; Heeg et\u00a0al., 2022). It included a com-\r\nbination of closed and open-ended questions such as the following: Can you explain what\r\nAI is? What are examples of AI? Is AI always good for us?", "mimetype": "text/plain", "start_char_idx": 26070, "end_char_idx": 30695, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "353be917-9355-4d06-bed0-5d0955221b6c": {"__data__": {"id_": "353be917-9355-4d06-bed0-5d0955221b6c", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0e5d4827-a298-4c37-a190-3cd6d53468a6", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "aadfa6a86fdc0937fd09807e8c2c436166cca239c004df06e867db1c186ff136", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e4eaa9e0-751e-455e-9690-ac6e13af67b4", "node_type": "1", "metadata": {}, "hash": "71923f6ce0eec6d897325361e57673df6921e9c10b18e504f39cfdb03258a34e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "nodding, facial expressions), and (c) naturally redirecting the conversation.\r\n\r\nThe  interviews  were  semi-structured,  allowing  a  more  natural  conversation  to  take\r\nplace  during  which  the  students  played  a  role  in  navigating  the  direction  of  the  inter-\r\nview. The interview protocol that was used, has been used in similar research with young\r\n\r\n\fEducation and Information Technologies\r\n\r\nchildren in a different context (Avraamidou, 2013; Heeg et\u00a0al., 2022). It included a com-\r\nbination of closed and open-ended questions such as the following: Can you explain what\r\nAI is? What are examples of AI? Is AI always good for us? A complete list of questions\r\ncan  be  found  in  Appendix.  The  interview  questions  were  developed  through  using  the\r\nresearch question as a basis as well as input from the literature. They were discussed with\r\na research group and pilot tested with a small group of students for validity purposes.\r\n\r\nDuring  the  interview,  the  children  shared  one  laptop  with  a  built-in  camera  to\r\ncommunicate with the interviewer. All students\u2019 upper bodies and heads remained\r\nvisible during the interview, to ensure non-verbal communication could be seen and\r\nacted on by the interviewer. All interviews were audio tape-recorded and fully tran-\r\nscribed for the purposes of the analysis.\r\n\r\nFor  the  data  analysis,  we  adopted  a  thematic  approach  to  identify  the  AI  literacy\r\nconstructs that were more salient. The Atlas software was used to analyze the data. To\r\ncarry out the analysis, we combined deductive and inductive analytic practices to pro-\r\nvide a more comprehensive view (Vanover et\u00a0al., 2022). For the first round of coding,\r\nwe applied a deductive approach to organize our data into deductive categories aligned\r\nwith the conceptual framework of Long and Magerko (2020), in this case, the AI lit-\r\neracy themes (see Table\u00a01). During the second round of coding, we applied an induc-\r\ntive approach, using in\u00a0vivo, line-by-line coding techniques, to allow codes and patterns\r\nto emerge from the data. Based on the patterns, the inductive codes were clustered in\r\ncategories, for example, \u2018imagining the future with AI\u2019, \u2018opinions on AI\u2019, and \u2018privacy\u2019,\r\nwhich were then grouped under three themes aligned with the three research questions.\r\nFor an overview of the coding process, including examples of codes, please see Table\u00a02.\r\n\r\n3.4   Trustworthiness\r\n\r\nIn  pursuit  of  establishing  trustworthiness,  we  increased  the  internal  validity  of  the\r\ninterviews by incorporating different questions addressing the same issue in the inter-\r\nview protocol. To establish external validity, both authors independently engaged with\r\nthe  data,  using  the  established  coding  scheme.  In  comparing  the  two  codings  there\r\nwas  an  80%  agreement.  The  authors  met  multiple  times  to  discuss  the  coding  and\r\ninterpretations.  The  authors  discussed  disagreements  until  a  consensus  was  reached\r\nas a way to enhance the trustworthiness of the findings. However, typical with qualita-\r\ntive research, confirmability and generalizability are not possible. We, however, pro-\r\nvide detailed information about both the context and processes of data collection to\r\nadvance the possibility of transferability of the findings to similar contexts.\r\n\r\n4   Findings\r\n\r\nThe outcomes of the analysis are presented around the final three themes that align\r\nwith the research questions of this paper: children\u2019s understanding of AI, AI in daily\r\nlife, and ethical risks of AI. All children\u2019s quotes were translated into English from\r\ntheir original language.", "mimetype": "text/plain", "start_char_idx": 30046, "end_char_idx": 33686, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e4eaa9e0-751e-455e-9690-ac6e13af67b4": {"__data__": {"id_": "e4eaa9e0-751e-455e-9690-ac6e13af67b4", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "353be917-9355-4d06-bed0-5d0955221b6c", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "8162baf65f53dc9b76d1b5b240bbe1aa6b288533651dc7cd73708281a89fe332", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "168b23cc-f5d4-4b27-b89b-5888022719c4", "node_type": "1", "metadata": {}, "hash": "ae587f21ae730f9a25280ae31f300a291e31f12cf4c166d4ae3ccb9b11a2cff4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In  comparing  the  two  codings  there\r\nwas  an  80%  agreement.  The  authors  met  multiple  times  to  discuss  the  coding  and\r\ninterpretations.  The  authors  discussed  disagreements  until  a  consensus  was  reached\r\nas a way to enhance the trustworthiness of the findings. However, typical with qualita-\r\ntive research, confirmability and generalizability are not possible. We, however, pro-\r\nvide detailed information about both the context and processes of data collection to\r\nadvance the possibility of transferability of the findings to similar contexts.\r\n\r\n4   Findings\r\n\r\nThe outcomes of the analysis are presented around the final three themes that align\r\nwith the research questions of this paper: children\u2019s understanding of AI, AI in daily\r\nlife, and ethical risks of AI. All children\u2019s quotes were translated into English from\r\ntheir original language.\r\n\r\n\fEducation and Information Technologies\r\n\r\ns\r\ne\r\nm\r\ne\r\nh\r\nt\r\n\r\ne\r\ne\r\nr\r\nh\r\nt\r\n\r\nr\r\ne\r\nd\r\nn\r\nu\r\n\r\ns\r\ne\r\ni\r\nr\r\no\r\ng\r\ne\r\nt\r\na\r\nc\r\n\r\ng\r\nn\r\ni\r\np\r\nu\r\no\r\nr\r\nG\r\n\r\ng\r\nn\r\ni\r\ns\r\nu\r\n\r\ns\r\ne\r\ni\r\nr\r\no\r\ng\r\ne\r\nt\r\na\r\nc\r\n\r\no\r\nt\r\nn\r\ni\r\n\r\ns\r\ne\r\nd\r\no\r\nc\r\n\r\ng\r\nn\r\ni\r\nr\r\ne\r\nt\r\ns\r\nu\r\nl\r\nC\r\n\r\n-\r\ny\r\nb\r\n-\r\ne\r\nn\r\ni\r\nl\r\n\r\n,\r\no\r\nv\r\ni\r\nv\r\n-\r\nn\r\ni\r\ng\r\nn\r\ni\r\ns\r\nu\r\ng\r\nn\r\ni\r\nd\r\no\r\nc\r\nf\r\no\r\n2\r\nd\r\nn\r\nu\r\no\r\nR\r\n\r\n5\r\n\r\ne\r\nh\r\nt\r\n\r\ng\r\nn\r\ni\r\ns\r\nu\r\n\r\ng\r\nn\r\ni\r\nd\r\no\r\nc\r\n\r\ne\r\nv\r\ni\r\nt\r\nc\r\nu\r\nd\r\ne\r\nd\r\nf\r\no\r\n\r\n1\r\n\r\nd\r\nn\r\nu\r\no\r\nR\r\n\r\ns\r\nn\r\no\r\ni\r\nt\r\ns\r\ne\r\nu\r\nq\r\n\r\nh\r\nc\r\nr\r\na\r\ne\r\ns\r\ne\r\nr\r\n\r\ne\r\ne\r\nr\r\nh\r\nt\r\n\r\ne\r\nh\r\nt\r\n\r\nh\r\nt\r\ni\r\n\r\nw\r\nd\r\ne\r\nn\r\ng\r\ni\r\nl\r\na\r\n\r\nf\r\no\r\n\r\ns\r\ne\r\ni\r\nc\r\nn\r\ne\r\nt\r\ne\r\np\r\nm\r\no\r\nc\r\n\r\n7\r\n1\r\n\r\ne\r\nh\r\nt\r\n\r\no\r\nt\r\n\r\ng\r\nn\r\ni\r\nd\r\nd\r\na\r\n\r\nd\r\nn\r\na\r\n\r\n:\r\ns\r\ne\r\nd\r\no\r\nc\r\ne\r\nl\r\np\r\nm\r\na\r\nx\r\nE\r\n\r\n.\r\ns\r\ne\r\nu\r\nq\r\ni\r\nn\r\nh\r\nc\r\ne\r\nt\r\ng\r\nn\r\ni\r\nd\r\no\r\nc\r\ne\r\nn\r\ni\r\nl\r\n\r\no\r\nk\r\nr\r\ne\r\ng\r\na\r\nM\r\nd\r\nn\r\na\r\n\r\ng\r\nn\r\no\r\nL\r\ny\r\nb\r\n\r\ns\r\ne\r\nm\r\ne\r\nh\r\nt\r\n\r\ny\r\nc\r\na\r\nr\r\ne\r\nt\r\ni\r\nl\r\n\r\nI\r\n\r\nA\r\n\r\ne\r\nl\r\np\r\nm\r\na\r\nx\r\nE\r\n\r\n.\r\n)", "mimetype": "text/plain", "start_char_idx": 32812, "end_char_idx": 34641, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "168b23cc-f5d4-4b27-b89b-5888022719c4": {"__data__": {"id_": "168b23cc-f5d4-4b27-b89b-5888022719c4", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e4eaa9e0-751e-455e-9690-ac6e13af67b4", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "8d43eec5dc6280bd9c7d14e12f5fa35733a62e883b4a1bd29532574a07f0a26c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1b9baa5e-f17a-4668-9317-d777f61eba07", "node_type": "1", "metadata": {}, "hash": "ba2d72b5497c242327bb4318626df794349579cda0a46a72281e5257a2678b41", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "s\r\ne\r\nu\r\nq\r\ni\r\nn\r\nh\r\nc\r\ne\r\nt\r\ng\r\nn\r\ni\r\nd\r\no\r\nc\r\ne\r\nn\r\ni\r\nl\r\n\r\no\r\nk\r\nr\r\ne\r\ng\r\na\r\nM\r\nd\r\nn\r\na\r\n\r\ng\r\nn\r\no\r\nL\r\ny\r\nb\r\n\r\ns\r\ne\r\nm\r\ne\r\nh\r\nt\r\n\r\ny\r\nc\r\na\r\nr\r\ne\r\nt\r\ni\r\nl\r\n\r\nI\r\n\r\nA\r\n\r\ne\r\nl\r\np\r\nm\r\na\r\nx\r\nE\r\n\r\n.\r\n)\r\n0\r\n2\r\n0\r\n2\r\n(\r\n\r\no\r\nk\r\nr\r\ne\r\ng\r\na\r\nM\r\nd\r\nn\r\na\r\n\r\ng\r\nn\r\no\r\nL\r\n\r\n:\r\ns\r\ne\r\ni\r\nr\r\no\r\ng\r\ne\r\nt\r\na\r\nc\r\n\r\n)\r\n0\r\n2\r\n0\r\n2\r\n(\r\n\r\ns\r\ns\r\ne\r\nc\r\no\r\nr\r\np\r\n\r\ng\r\nn\r\ni\r\nd\r\no\r\nc\r\n\r\nf\r\no\r\nw\r\ne\r\ni\r\nv\r\nr\r\ne\r\nv\r\nO\r\n\r\n2\r\ne\r\nl\r\nb\r\na\r\nT\r\n\r\ns\r\ne\r\nv\r\ni\r\nl\r\n\r\ny\r\nl\r\ni\r\na\r\nd\r\n\r\n\u2019\r\ns\r\nt\r\nn\r\ne\r\nd\r\nu\r\nt\r\ns\r\n\r\nn\r\ni\r\n\r\nI\r\n\r\nA\r\n\r\nI\r\n\r\nA\r\ng\r\nn\r\ni\r\nz\r\ni\r\nn\r\ng\r\no\r\nc\r\ne\r\nR\r\n\r\n-\r\na\r\nd\r\nn\r\ne\r\nm\r\nm\r\no\r\nc\r\ne\r\nr\r\n\r\nI\r\n\r\nA\r\n\r\n,\r\ne\r\nb\r\nu\r\nT\r\nu\r\no\r\nY\r\n\r\n,\r\n\r\nm\r\nh\r\nt\r\ni\r\nr\r\no\r\ng\r\nl\r\nA\r\n\r\n?\r\nI\r\nA\r\ns\r\ni\r\n\r\nt\r\na\r\nh\r\nW\r\n\r\ns\r\nn\r\no\r\ni\r\nt\r\n\r\ns\r\ne\r\nv\r\ni\r\nl\r\n\r\ny\r\nl\r\ni\r\na\r\nd\r\n\r\n\u2019\r\ns\r\nt\r\nn\r\ne\r\nd\r\nu\r\nt\r\ns\r\n\r\nn\r\ni\r\n\r\nI\r\n\r\nA\r\n\r\nI\r\n\r\nA\r\n\r\nf\r\no\r\n\r\ng\r\nn\r\ni\r\nd\r\nn\r\na\r\nt\r\ns\r\nr\r\ne\r\nd\r\nn\r\nU\r\n\r\nI\r\n\r\nA\r\n\r\nf\r\no\r\n\r\ns\r\nk\r\ns\r\ni\r\nr\r\n\r\nl\r\na\r\nc\r\ni\r\nh\r\nt\r\nE\r\n\r\ns\r\ne\r\nv\r\ni\r\nl\r\n\r\ny\r\nl\r\ni\r\na\r\nd\r\n\r\n\u2019\r\ns\r\nt\r\nn\r\ne\r\nd\r\nu\r\nt\r\ns\r\n\r\nn\r\ni\r\n\r\nI\r\n\r\nA\r\n\r\nI\r\n\r\nA\r\nn\r\ni\r\n\r\ne\r\nl\r\no\r\nr\r\n\r\nn\r\na\r\nm\r\nu\r\nH\r\n\r\nI\r\n\r\nA\r\ng\r\nn\r\ni\r\nk\r\na\r\nm\r\n\r\n,\r\n\r\nd\r\ne\r\nm\r\nm\r\na\r\nr\r\ng\r\no\r\nr\r\np\r\n\r\ns\r\ni\r\n\r\nI\r\n\r\nA\r\n\r\nI\r\n\r\nA\r\n\r\nf\r\no\r\n\r\ne\r\ns\r\nU\r\n\r\np\r\nl\r\ne\r\nh\r\n\r\nn\r\na\r\nc\r\n\r\nI\r\n\r\nA\r\n\r\n,\r\nk\r\nl\r\na\r\nt\r\n\r\nn\r\na\r\nc\r\n\r\nI\r\n\r\nA\r\n\r\n,\r\nn\r\na\r\ne\r\nl\r\nc\r\n\r\nn\r\na\r\nc\r\n\r\nI\r\n\r\nA\r\n\r\n?\r\nk\r\nr\r\no\r\nw\r\n\r\nI\r\n\r\nA\r\ns\r\ne\r\no\r\nd\r\nw\r\no\r\nH\r\n\r\n?\r\no\r\nd\r\n\r\nI\r\n\r\nA\r\nn\r\na\r\nc\r\n\r\nt\r\na\r\nh\r\nW\r\n\r\nn\r\no\r\ni\r\nn\r\ni\r\np\r\nO\r\n\r\ns\r\nc\r\ni\r\nh\r\nt\r\nE\r\n\r\ny\r\nc\r\na\r\nv\r\ni\r\nr\r\np\r\n\r\n,\r\nt\r\n\r\nfi\r\no\r\nr\r\np\r\n\r\n,\r\n\r\nm\r\ns\r\ni\r\nx\r\ne\r\ns\r\n\r\n,\r\n\r\nm\r\ns\r\ni\r\nc\r\na\r\nr\r\n\r\n,\r\ns\r\na\r\ni\r\nB\r\n\r\n?\r\nd\r\ne\r\ns\r\nu\r\n\r\ne\r\nb\r\n\r\nI\r\n\r\nA\r\nd\r\nl\r\nu\r\no\r\nh\r\ns\r\nw\r\no\r\nH\r\n\r\nn\r\no\r\ni\r\nn\r\ni\r\np\r\nO\r\n\r\n?", "mimetype": "text/plain", "start_char_idx": 34444, "end_char_idx": 36019, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1b9baa5e-f17a-4668-9317-d777f61eba07": {"__data__": {"id_": "1b9baa5e-f17a-4668-9317-d777f61eba07", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "168b23cc-f5d4-4b27-b89b-5888022719c4", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "a8f306bb0041155432a933a7f8e8fb6005bac69b91a365d50414b82249cf1097", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "879028d7-6a5e-4ff5-8475-277216851565", "node_type": "1", "metadata": {}, "hash": "b3da6154c0a6881590d7d23bd13e67fef43c423b2a8e5b2f15cc93b53d2707fb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "k\r\nr\r\no\r\nw\r\n\r\nI\r\n\r\nA\r\ns\r\ne\r\no\r\nd\r\nw\r\no\r\nH\r\n\r\n?\r\no\r\nd\r\n\r\nI\r\n\r\nA\r\nn\r\na\r\nc\r\n\r\nt\r\na\r\nh\r\nW\r\n\r\nn\r\no\r\ni\r\nn\r\ni\r\np\r\nO\r\n\r\ns\r\nc\r\ni\r\nh\r\nt\r\nE\r\n\r\ny\r\nc\r\na\r\nv\r\ni\r\nr\r\np\r\n\r\n,\r\nt\r\n\r\nfi\r\no\r\nr\r\np\r\n\r\n,\r\n\r\nm\r\ns\r\ni\r\nx\r\ne\r\ns\r\n\r\n,\r\n\r\nm\r\ns\r\ni\r\nc\r\na\r\nr\r\n\r\n,\r\ns\r\na\r\ni\r\nB\r\n\r\n?\r\nd\r\ne\r\ns\r\nu\r\n\r\ne\r\nb\r\n\r\nI\r\n\r\nA\r\nd\r\nl\r\nu\r\no\r\nh\r\ns\r\nw\r\no\r\nH\r\n\r\nn\r\no\r\ni\r\nn\r\ni\r\np\r\nO\r\n\r\n?\r\nI\r\nA\r\ne\r\nv\r\ni\r\ne\r\nc\r\nr\r\ne\r\np\r\n\r\ne\r\nl\r\np\r\no\r\ne\r\np\r\n\r\no\r\nd\r\nw\r\no\r\nH\r\n\r\n\fEducation and Information Technologies\r\n\r\n4.1   Children\u2019s Understanding of\u00a0AI\r\n\r\nAfter  a  brief  conversation  on  whether  or  not  the  students  enjoyed  the  AI  lessons,\r\nthe  researcher  opened  the  interviews  by  asking  if  students  could  explain  what  AI\r\nis. This question led to some initial discomfort in most groups, manifesting in the\r\nform of silences, exchanged glances, or laughter. In some cases, students would even\r\nexplicitly  share  that  this  was  a  difficult  question  to  answer.  However,  in  the  end,\r\nmost groups provided a collective answer, that all group members contributed to and\r\nagreed with. For example, Sascha, Julia, Feline, and Rachel shared:\r\n\r\nResearcher: Could you try to explain to me what AI is?\r\nSascha: Julia can start.\r\nResearcher:  There are no right or wrong answers, everything is ok.\r\nJulia: Well, ehm\u2026\r\n[\u2026]\r\n[all group members laugh]\r\nJulia: It is hard to explain\r\nSascha: Shall I start?\r\nJulia: Yes please. Sascha will start.\r\nSascha: Well, I will try. AI is actually, well, a device or something, which has been developed by humans but which can actually\r\nmake its own decisions.\r\nResearcher: okay\r\nSascha: Something like that\u2026\r\nResearcher: Does anybody want to add something to that? Or, has other ideas about what AI is?\r\nFeline: Maybe that they can decide that, for example, a self-driving car, they can decide where they want to go. Well, not exactly\r\ndecide, but they can describe the route and then decide which one to take.\r\nRachel: They choose themselves\r\nJulia: They can think on their own, but they are programmed, so it is not actually by themselves.\r\nResearcher: okay,, so they can think on their own, and decide on their own.\r\nJulia: Yes\r\n\r\nAs apparent in the extract, after Sascha started answering the question, all other\r\ngroup  members  felt  comfortable  adding  to  the  explanation.  As  can  be  seen  in  the\r\nextract,  the  group  described  AI  as  a  device  that  is  programmed  or  developed  by\r\nhumans and that can think and decide on its own. This is a typical description that\r\noccurred more or less in all group interviews. Some other typical descriptions from\r\nthe  interviews  were  AI  as  an  \u2018algorithm\u2019,  or  \u2018computer  system\u2019,  that  is  \u2018smart\u2019  or\r\n\u2018intelligent\u2019 because it can \u2018learn\u2019, \u2018think\u2019, or \u2018do things\u2019 on its own. For example,\r\nwhen Bobby was asked why he called AI \u2018smart\u2019, he answered:\r\n\r\nBobby: Well, it can do a lot of things. AI can do things by itself. I think that is smart of AI.\r\n\r\nIn one group, all group members reacted to the researcher\u2019s question by turn-\r\ning their heads to Fred who interpreted this non-verbal behavior as inviting him\r\nto  answer  this  question.  At  the  beginning  of  the  interview,  Fred  already  posi-\r\ntioned himself as an expert on AI and felt comfortable answering this question\r\non his own.", "mimetype": "text/plain", "start_char_idx": 35688, "end_char_idx": 38944, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "879028d7-6a5e-4ff5-8475-277216851565": {"__data__": {"id_": "879028d7-6a5e-4ff5-8475-277216851565", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1b9baa5e-f17a-4668-9317-d777f61eba07", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "29ed64d22eccc61c969ef4860146a372f917b9a87c57fd7ecd29b203b4dce5b7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c867cd2f-a109-4341-a075-173704be328b", "node_type": "1", "metadata": {}, "hash": "29363d6182f85ccdc482ab919e68b91be2e9f17abacbeebf89d711b4ff9a2f2e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Some other typical descriptions from\r\nthe  interviews  were  AI  as  an  \u2018algorithm\u2019,  or  \u2018computer  system\u2019,  that  is  \u2018smart\u2019  or\r\n\u2018intelligent\u2019 because it can \u2018learn\u2019, \u2018think\u2019, or \u2018do things\u2019 on its own. For example,\r\nwhen Bobby was asked why he called AI \u2018smart\u2019, he answered:\r\n\r\nBobby: Well, it can do a lot of things. AI can do things by itself. I think that is smart of AI.\r\n\r\nIn one group, all group members reacted to the researcher\u2019s question by turn-\r\ning their heads to Fred who interpreted this non-verbal behavior as inviting him\r\nto  answer  this  question.  At  the  beginning  of  the  interview,  Fred  already  posi-\r\ntioned himself as an expert on AI and felt comfortable answering this question\r\non his own. His group members agreed with his explanation, but didn\u2019t add any-\r\nthing to it:\r\n\r\n\fEducation and Information Technologies\r\n\r\nResearcher: Can you tell me what AI is?\r\n[all group members looked at Fred]\r\nFred: Well, I think I will take this one if everybody is looking at me. But I don\u2019t mind. Artificial Intelligence,  also known\r\nas AI, is a computer or a computer program that can independently perform certain tasks, independently decide things,\r\nor decide how to do them. For example, when you say something to a Google Assistant, like \u2018Hey Google, turn on the\r\nlights\u2019, it will turn on the lights.\r\nResearcher: Okay. Lars, do you want to add something to that?\r\nLars: No, I think he said everything.\r\n\r\nAlthough  all  children  seemed  to  understand  that  AI  can  \u2018think\u2019  or  \u2018learn\u2019\r\nby  itself,  nobody  was  able  to  answer  follow-up  questions  such  as  \u2018how  does  it\r\nthink?\u2019 or \u2018how does it learn?\u2019. Nevertheless, students had some misconceptions\r\nabout recognizing Artificial Intelligence, as can be seen in the following conver-\r\nsation prompted by the researcher asking if the students have AI at home:\r\n\r\nErica: I have a phone and my sister has a tablet. My father has two phones. One for work and one for at home. And my mum has a\r\nphone. I have another one.\r\nResearcher:  And, do all mobile phones use AI?\r\nStella: Yes, I think so.\r\nErica: yes\r\nStella: well actually, when you ask it like that, I don\u2019t think it has.\r\n[Stella and Erica laugh]\r\nStella: oh yes, a phone is electric\r\n\r\nThe extract shows how both Erica and Stella think that all phones use AI, later\r\ndoubting that. Similarly, in a different group, Fred and Lars suggested automated\r\ncalendar notifications might also be instances of AI, but weren\u2019t sure about this:\r\n\r\nResearcher: How do you use AI at home?\r\nFred: Well for example, ehm\u2026, for example when you cannot remember things very well, then you can look things up. For example,\r\nwhen my birthday is, or a calendar, an online calendar. My grandma does that sometimes.\r\nLars: Yes, very helpful as a calendar\r\nResearcher: And what do you mean by calendar? What is AI about the calendar?\r\nLars: For example, a calendar. Well, I am not sure if that is AI.\r\nLars: When you put something on your calendar, then it will send you a reminder one day in advance of when that will happen. I\r\nam not sure if that is AI\r\n\r\nAs apparent in this dialogue, students tend to label electronic devices or auto-\r\nmated functions, such as online calendars and reminders, as instances of artifi-\r\ncial intelligence, reflecting a limited understanding of AI.\r\n\r\n4.2   AI in\u00a0daily life\r\n\r\nWhen  prompted  to  share  examples  of  AI,  all  groups  stated  the  most  common  AI\r\napplications that children in the context of the study can come across in daily life.\r\nExamples included recommendation algorithms on social media and Netflix, voice\r\nassistants  like  Alexa  and  Hey  Google,  robotic  vacuum  cleaners  and  lawnmowers,\r\nand self-driving cars. For example, Rachel, Feline, Sascha, and Julia shared:\r\n\r\n\fEducation and Information Technologies\r\n\r\nResearcher:  And do you know examples of AI?\r\nRachel: self-driving cars, Siri, Alexa, Google Assistant, Corta,\r\nFeline: Corta?", "mimetype": "text/plain", "start_char_idx": 38214, "end_char_idx": 42152, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c867cd2f-a109-4341-a075-173704be328b": {"__data__": {"id_": "c867cd2f-a109-4341-a075-173704be328b", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "879028d7-6a5e-4ff5-8475-277216851565", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "efdc3dd4bac95495c7bd69d531efbfb6393e754654faae977b9d7d97d0cbed80", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e18b633f-9838-4a7b-973a-5c2a06fb1121", "node_type": "1", "metadata": {}, "hash": "6e6899130eaf36fca24b8f2edb0d86822fa6c05b6d293860ebad729880146eca", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4.2   AI in\u00a0daily life\r\n\r\nWhen  prompted  to  share  examples  of  AI,  all  groups  stated  the  most  common  AI\r\napplications that children in the context of the study can come across in daily life.\r\nExamples included recommendation algorithms on social media and Netflix, voice\r\nassistants  like  Alexa  and  Hey  Google,  robotic  vacuum  cleaners  and  lawnmowers,\r\nand self-driving cars. For example, Rachel, Feline, Sascha, and Julia shared:\r\n\r\n\fEducation and Information Technologies\r\n\r\nResearcher:  And do you know examples of AI?\r\nRachel: self-driving cars, Siri, Alexa, Google Assistant, Corta,\r\nFeline: Corta?\r\nRachel: that\u2019s from Windows\r\nSascha: Netflix\r\nResearcher:  And what exactly is AI on Netflix?\r\nSascha: Well, for example\r\nJulia: Cookies\r\nSascha: No,  but if you have watched a certain series, then it tells you, you may also like this\u2019\r\nFeline: and it says you can watch this, examples of what you can watch, and usually there is something fun in there that you want\r\nto watch\r\nSascha: because you,\r\nFeline: because you already watched certain things, and because you watch things, or you searched for specific things, it suggests\r\nthings that are kind of similar. Yes.\r\nJulia: Also on TikTok\r\nFeline: TikTok and Snapchat\r\n\r\nIn all groups, children named Netflix, TikTok, and YouTube as AI. Through fol-\r\nlow-up  questions,  they  would  specify  how  such  platforms  use  AI  to  identify  what\r\nvideos they like to suggest content of a similar nature. For example:\r\n\r\nBetty: On TikTok for example, when you watch a certain video, and you like it, that the next few videos will be the exact same videos.\r\nWhich can be strange as well\u2026\r\nResearcher: Could it also be boring?\r\nBetty, Sarah, Rose: Yes!\r\nRose: You never get something different\r\nI: And do you have solutions for this? Do you ever use each other\u2019s phones to see something else?\r\nRose: when you press \u2018not interested\u2019 you will see those videos less\r\nSarah: yes\r\nResearcher: Oh, I didn\u2019t know that was possible\r\nRose: Yes, and you can also, I do this sometimes, when I don\u2019t like a video, I would like it, so I would get other types of videos.\r\nRose: Or, if you scroll over a nice video, or don\u2019t watch it until the end\r\nBetty: yes, that\u2019s right\r\n\r\nIn this dialogue, Sarah, Betty, and Rose describe how they interact with AI sys-\r\ntems when they watch videos on TikTok. All three shared their scrolling and liking\r\nbehavior to manipulate the AI in providing other types of TikTok content. In another\r\ngroup, Tom and Erica, shared similar strategies for manipulating the algorithm:\r\n\r\nTom: What I have done is like a video [on TikTok] that I didn\u2019t like, because that would give me other types of videos.\r\nResearcher:  you mean you are tricking the AI system in giving you other content?\r\nTom: yes, and for example, immediately scrolling through videos that you like.\r\nErica: Yes, that is right.\r\nTom: Or when you watch a video, but don\u2019t finish it, or don\u2019t watch it for a long time.\r\n\r\nThis  particular  use  of  the  AI  recommendation  software  shows  a  good  under-\r\nstanding of how such platforms track their behavior (e.g. likes, scrolling, watch-\r\ning)  and  use  it  to  provide  tailored  content.  However,  children  did  not  explicitly\r\nrecognize  AI  recommendation  algorithms  responsible  for  this  function;  rather,\r\nthey  generally  attributed  this  capability  to  the  platforms,  such  as  Netflix  and\r\n\r\n\fEducation and Information Technologies\r\n\r\nTikTok. When asked to share what they thought about AI recommendations, chil-\r\ndren reported mixed feelings: both boring and convenient.\r\n\r\nBesides  experiences  with  recommendation  software,  experiences  with  voice\r\nassistants were shared in all groups, showing examples of how children use voice\r\nassistants. For example:\r\n\r\nAron: We had a Hey Google at home\r\nResearcher: And what would you use it for?\r\nAron: Ehm,\u2026 Usually, for example, to change the volume of music. Asking it for jokes is also fun.", "mimetype": "text/plain", "start_char_idx": 41530, "end_char_idx": 45498, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e18b633f-9838-4a7b-973a-5c2a06fb1121": {"__data__": {"id_": "e18b633f-9838-4a7b-973a-5c2a06fb1121", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c867cd2f-a109-4341-a075-173704be328b", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "140e54c24a641554d2f875fad55028c7ecd06b9026542aef5417caebeeb88f44", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7cb5625b-c285-4efc-83c4-59a0bd212154", "node_type": "1", "metadata": {}, "hash": "05ca429b13b31671b7efb4add283f6c430ff07e01cde510051e3b99f10187d1e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "However,  children  did  not  explicitly\r\nrecognize  AI  recommendation  algorithms  responsible  for  this  function;  rather,\r\nthey  generally  attributed  this  capability  to  the  platforms,  such  as  Netflix  and\r\n\r\n\fEducation and Information Technologies\r\n\r\nTikTok. When asked to share what they thought about AI recommendations, chil-\r\ndren reported mixed feelings: both boring and convenient.\r\n\r\nBesides  experiences  with  recommendation  software,  experiences  with  voice\r\nassistants were shared in all groups, showing examples of how children use voice\r\nassistants. For example:\r\n\r\nAron: We had a Hey Google at home\r\nResearcher: And what would you use it for?\r\nAron: Ehm,\u2026 Usually, for example, to change the volume of music. Asking it for jokes is also fun.\r\nBobby: \u2018Hey Google, a joke.\u2019 And then it will tell you a joke.\r\n\r\nAs the extract shows, Aron used the voice assistant at his home for both prac-\r\ntical  tasks  and  entertainment.  In  three  groups,  students  also  shared  how  they\r\nbelieve  voice  assistants  can  be  helpful  for  sick,  disabled,  or  lazy  people.  For\r\nexample, Ruben, Bobby, and Julia all said similar things in different groups:\r\n\r\nRuben: I think AI is convenient for lazy people, or people who are sick, because they can close the curtains with their voice.\r\n\r\nBobby: It can help you with things. For example, with things that some people cannot do on their own. For example, people who\r\nhave two broken legs, or no legs. Ehm\u2026 Yes, it can help them by automatically closing the curtains, or turning on lights.\r\n\r\nThe  most  common  tasks  that  the  students  reported  using  voice  assistants  for\r\nwere related to listening to music, turning on and off the lights, opening and clos-\r\ning windows, or telling jokes.\r\n\r\nAll groups mentioned robot vacuum cleaners and lawnmowers as an AI exam-\r\nple. A few students shared that they had these applications at home, while others\r\nmentioned they had seen them at friends\u2019 houses. Similar to the voice assistants,\r\nstudents thought such robots could be helpful:\r\n\r\nStan: A robot lawn mower is pretty convenient too. It can save you time.\r\n\r\nJulia: I think the same as Sascha. It can be convenient, for example, if you are sick and you cannot vacuum every day, a robot  can\r\ndo it for you. Or a robot lawn mower. But it can also be used in a bad way.\r\n\r\n4.3   Ethical risks of\u00a0AI\r\n\r\nDuring  the  interviews,  students  extensively  talked  about  various  ethical  issues.\r\nIn the introductory course, one lesson specifically discussed the topic of AI and\r\nEthics. In this lesson, the teacher discussed with the students why platforms such\r\n\r\n\fEducation and Information Technologies\r\n\r\nas YouTube and TikTok use AI recommendation software. During the interviews,\r\nit became evident students have a clear understanding and strong opinions on this\r\nmatter.\r\n\r\nStella: you know that YouTube gets money when we are watching videos. So they make money off my data.\r\nResearcher: You mean they make money when you use YouTube?\r\nStella: Yes, I think they should share their profits with me. Because it is my data. They have things that are mine, it is about me.\r\nResearcher: so how does it work?\r\nStella: Well, if you are watching videos that you don\u2019t like, you will probably stop watching videos on YouTube. So you will have\r\nless screen time, and then YouTube will get less money because of that.\r\nResearcher: and you think it is not fair that they make money through you?\r\nStella, Erica, and Tom [simultaneously]: Yes!\r\nStella: The money should come to us, they already have enough money, why don\u2019t they share it? It is our money. No, it is our data,\r\nand they get the money.\r\nResearcher: ok\r\nStella: Do you get it? I mean, I don\u2019t necessarily have to make money, but that they make money with my data, that\u2019s not ok\r\n\r\nStella  understands  that  YouTube  used  the  algorithm  to  make  sure  she  spends\r\nmore  time  on  their  platform  which  will  eventually  make  her  behavior  profitable\r\nfor YouTube.", "mimetype": "text/plain", "start_char_idx": 44725, "end_char_idx": 48730, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7cb5625b-c285-4efc-83c4-59a0bd212154": {"__data__": {"id_": "7cb5625b-c285-4efc-83c4-59a0bd212154", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e18b633f-9838-4a7b-973a-5c2a06fb1121", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "64ab8acf924eedaf8d4676da69937ef5334496b95837dc5a0ecf5f479acdb1ae", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e51166be-9e55-4a7c-9d56-7363dbb8805f", "node_type": "1", "metadata": {}, "hash": "302ee646eff3bf60cd0f35620b9254f20dc590ad3a82f2219fb3e6391a24d2e8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "So you will have\r\nless screen time, and then YouTube will get less money because of that.\r\nResearcher: and you think it is not fair that they make money through you?\r\nStella, Erica, and Tom [simultaneously]: Yes!\r\nStella: The money should come to us, they already have enough money, why don\u2019t they share it? It is our money. No, it is our data,\r\nand they get the money.\r\nResearcher: ok\r\nStella: Do you get it? I mean, I don\u2019t necessarily have to make money, but that they make money with my data, that\u2019s not ok\r\n\r\nStella  understands  that  YouTube  used  the  algorithm  to  make  sure  she  spends\r\nmore  time  on  their  platform  which  will  eventually  make  her  behavior  profitable\r\nfor YouTube. Stella and her group members believe it is unfair that YouTube uses\r\nher data to make a profit, touching upon the ethical issue of ownership. Stella felt\r\nvery strongly about this, even asking the researcher in the end \u2018Do you get it?\u2019 to\r\nmake sure her point had come across. Another group had fewer problems with the\r\nidea that YouTube makes money by using this algorithm:\r\n\r\n Researcher: And why do you think YouTube or TikTok use AI?\r\nRachel: so you will keep watching videos\r\nFeline: Yes, they make money, so when you watch more videos, they make more money\r\nSascha: commercials, because of the commercials. You watch more videos and also more commercials, and they earn money with\r\nthat\r\nResearchers: And what do you think about that? That they earn money.\r\nSascha: it\u2019s a little annoying, but in some way it is convenient\r\nFeline: Yes\r\nJulia: I mean, they have to eat too. I think it is smart. They have to earn money too.\r\nRachel: I don\u2019t mind it. I mean, I am not complaining when my mum is going to work to make money, right?\r\nFeline: I think it is pretty smart. Smart that they came up with this idea. Because we watch more videos so that they can make more\r\nmoney. Very smart of those people.\r\n\r\nIn this group, all children believed it was YouTube\u2019s right to earn money and they\r\n\r\ndidn\u2019t feel they needed to be compensated for that.\r\n\r\nA second ethical issue they were concerned with is privacy issues, being afraid\r\nthat personal data might be sold to other parties or used for other purposes than for\r\nrecommending new videos. For example, Rogier shared:\r\n\r\nRogier: Well, AI is governed by very big companies and you cannot always trust those.\r\nResearcher: And why, what do you mean by \u2018we cannot trust those\u2019?\r\nRogier: Well, Facebook, for example, they have a lot of private data, and they use it for commercials, but that data can be easily\r\nused for bad things.\r\n\r\nRogier shows a certain distrust of big tech companies, stating that such compa-\r\n\r\nnies might misuse their private data. Sarah had similar worries:\r\n\r\n\fEducation and Information Technologies\r\n\r\nSarah: I think it is important that our personal information is not used to make money [by selling it to other companies], but only\r\nto recommend new videos, but they [YouTube] cannot misuse our data.\r\nResearcher: And what do you mean with personal data?\r\nSarah: Ehm.. Like your address and phone number.\r\n\r\nAnother  ethical  issue,  extensively  present  in  the  data  is  that  of  AI  bias.  All  the\r\nchildren  talked  a  lot  about  the  issue  of  AI  bias.  During  the  AI  and  Ethics  lesson,\r\nthe students took part in an exercise where they would search for biases in Google\r\nImages.  As  an  example,  the  teacher  googled  \u2018baby\u2019,  and  the  students  noticed  that\r\nGoogle  would  mostly  show  Caucasian  babies.  After  this  example,  children  had\r\nto  search  for  such  biases  in  Google  Images  themselves.  During  the  interviews,  it\r\nbecame clear that children were unfamiliar with the term AI bias but did remember\r\nthe concept vividly.\r\n\r\nResearcher: I believe you did an exercise where you had to look for images on Google. Your teacher used the example of googling\r\n\u2018baby\u2019 and you would only see white babies.\r\nRose: Ah, yes, we talked about this.\r\nBetty: yes!\r\nSarah: we did this!", "mimetype": "text/plain", "start_char_idx": 48026, "end_char_idx": 52023, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e51166be-9e55-4a7c-9d56-7363dbb8805f": {"__data__": {"id_": "e51166be-9e55-4a7c-9d56-7363dbb8805f", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7cb5625b-c285-4efc-83c4-59a0bd212154", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "cfedbf047abcee07d51ad0bd5b26a73c3d8024c68492b12c9af2661053e1bc19", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2e81daf5-96cb-474a-9bb0-946e584387ff", "node_type": "1", "metadata": {}, "hash": "9063446e0109ac3f061ea300b14b85f66f283ff420551878ff9f1401bdb3e8df", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "During  the  AI  and  Ethics  lesson,\r\nthe students took part in an exercise where they would search for biases in Google\r\nImages.  As  an  example,  the  teacher  googled  \u2018baby\u2019,  and  the  students  noticed  that\r\nGoogle  would  mostly  show  Caucasian  babies.  After  this  example,  children  had\r\nto  search  for  such  biases  in  Google  Images  themselves.  During  the  interviews,  it\r\nbecame clear that children were unfamiliar with the term AI bias but did remember\r\nthe concept vividly.\r\n\r\nResearcher: I believe you did an exercise where you had to look for images on Google. Your teacher used the example of googling\r\n\u2018baby\u2019 and you would only see white babies.\r\nRose: Ah, yes, we talked about this.\r\nBetty: yes!\r\nSarah: we did this!\r\nResearcher: Do you remember the lesson? What happened?\r\nRose: I remember this because I thought this lesson was super interesting. We talked about, for example, if you have face id, it\r\nworks better on white people than people of color. And for example, if you look for pictures of \u2018fights\u2019, you usually get pictures of\r\npeople of color instead of white people.\r\nSarah: And also with \u2018kidnapping\u2019 you \u2026\r\nRose: yes\r\nSarah: you will see mostly men, but they could also be women.\r\nResearcher: And do you know why this happens?\r\nBetty: ehm\u2026\r\nSarah: Because maybe this sounds more logical to them. It is the same in cartoons.\r\n\r\nOther groups shared other examples of biased results, for example that search-\r\ning for \u2018married\u2019 mostly showed heterosexual couples and not \u2018boy with boy or\r\ngirl with girl\u2019. Some children explicitly called such biases \u2018racist\u2019 and \u2018sexist\u2019. For\r\nexample, Aron shared:\r\n\r\nAron: I think AI is racist, because when you search for \u2018monkey holding a box\u2019 [in Google Images], you will see a baby of color\r\nwith a box.\r\n\r\nAll  groups  disapproved  of  such  biases  and  believed  they  needed  to  be  fixed.\r\nand  that  they  should  be  fixed.  However,  when  asked  about  the  origins  of  such\r\nbiases  or  potential  solutions,  a  large  majority  of  students  struggled  to  respond.\r\nOne exception was Stella, who shared an idea:\r\n\r\n\fEducation and Information Technologies\r\n\r\nResearcher:  So how do you think we can change this [biases in Google Images]\r\nStella: well, that more people from, more foreigners, and people who are attracted to other genders, also just start working on  AI.\r\nI don\u2019t think it\u2019s meant to be that way, because there are those white people who work on it and they kind of forget about the other\r\npeople. So I think that also just a little more foreigners can contribute to the research or whatever happens. I think maybe more\r\nforeigners can join. Because look, for example, you don\u2019t see Moroccans there on Google when you search for people. You don\u2019t\r\nsee it.\r\n\r\nStella\u2019s words \u2018or whatever happens\u2019 indicate that she does not understand how AI\r\nalgorithms are exactly made, but she realizes that there are people who develop such AI\r\nalgorithms. More specifically, Stella believes that there are mostly \u2018white people\u2019 who\r\nwork on such algorithms who unconsciously forget that there are other-looking people,\r\nor in Stella her words \u2018foreigners\u2019. As a solution to AI bias, Stella believes development\r\nteams should be more diverse to make sure nobody is overlooked or not represented. In\r\nsaying this, Stella places the responsibility for such biases on the developers and holds\r\nthem  accountable  for  this  issue.  Other  ethical  topics  that  were  briefly  mentioned  by\r\nchildren were: fake news, misinformation, AI taking over the world, and people becom-\r\ning too dependent, and therefore lazy because AI takes over too many tasks.\r\n\r\n5   Discussion\r\n\r\nThis study aimed to explore young children\u2019s understanding of AI as both a tech-\r\nnology and a socio-cultural tool. Through semi-structured group interviews, chil-\r\ndren  were  inquired  about  what  AI  is,  how  they  use  it,  and  the  risks  they  see  in\r\nusing it.", "mimetype": "text/plain", "start_char_idx": 51274, "end_char_idx": 55219, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2e81daf5-96cb-474a-9bb0-946e584387ff": {"__data__": {"id_": "2e81daf5-96cb-474a-9bb0-946e584387ff", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e51166be-9e55-4a7c-9d56-7363dbb8805f", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "9bad33d3e9c0a108932f97e2ac1adb89a284540f30b8007377ec49eeb29f71bc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3c5f30ad-86a0-48d1-bd46-a4bd21f0a1eb", "node_type": "1", "metadata": {}, "hash": "363e07138f0eeb8a484ffe6774faa86505e724b2ed2f4fcdaf9193898905521c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "As a solution to AI bias, Stella believes development\r\nteams should be more diverse to make sure nobody is overlooked or not represented. In\r\nsaying this, Stella places the responsibility for such biases on the developers and holds\r\nthem  accountable  for  this  issue.  Other  ethical  topics  that  were  briefly  mentioned  by\r\nchildren were: fake news, misinformation, AI taking over the world, and people becom-\r\ning too dependent, and therefore lazy because AI takes over too many tasks.\r\n\r\n5   Discussion\r\n\r\nThis study aimed to explore young children\u2019s understanding of AI as both a tech-\r\nnology and a socio-cultural tool. Through semi-structured group interviews, chil-\r\ndren  were  inquired  about  what  AI  is,  how  they  use  it,  and  the  risks  they  see  in\r\nusing it. The findings are presented with accompanying data extracts to provide\r\ninsights  into  students\u2019  views  and  are  structured  around  three  main  themes:  AI\r\nunderstanding, AI awareness, and AI ethics.\r\n\r\nThe findings carry various similarities with recent studies on students\u2019 prior AI\r\nknowledge  and  conceptions.  The  first  similarity  is  that  on  an  abstract  level,  stu-\r\ndents conceptualize AI as a computer system that is programmed by humans and\r\nis intelligent because it can carry out tasks independently or autonomously engage\r\nin  decision-making  (Henry  et\u00a0 al.,  2021;  Mertala  et\u00a0 al.,  2022;  Ottenbreit-Leftwich\r\net\u00a0al., 2022; Williams et\u00a0al., 2022). This abstract conceptualization lacked depth, as\r\nevidenced  by  students\u2019  misconception  of  labeling  electrical  devices  or  automated\r\nprocesses  as  AI  (see  also  Kim  et\u00a0 al.,  2023;  Williams  et\u00a0 al.,  2022;  Zhang  et\u00a0 al.,\r\n2022) and a lack of understanding of how AI works (see also Mertala et\u00a0al., 2022;\r\nOttenbreit-Leftwich et\u00a0al., 2022).\r\n\r\nIn terms of AI use, the findings reveal a collective awareness among all students\r\nregarding common AI applications in their daily lives, such as voice assistants, rec-\r\nommendation  algorithms,  and  robot  vacuum  cleaners.  Students  recognized  AI\u2019s\r\npotential in assisting with household chores and physical tasks, while also acknowl-\r\nedging  its  capacity  to  help  individuals  with  disabilities  or  illnesses.  These  results\r\ncontribute to existing research, indicating that children perceive AI as a facilitator,\r\nstreamlining  tasks,  saving  time,  and  offering  support  to  those  less  abled  (Mertala\r\net\u00a0al., 2022; Ottenbreit-Leftwich et\u00a0al., 2022; Zhang et\u00a0al., 2022).\r\n\r\n\fEducation and Information Technologies\r\n\r\nThe findings show high engagement with and nuanced awareness of the ethics of\r\nAI.  Students  expressed  concerns  about  AI  bias  such  as  discrimination  against  peo-\r\nple  of  color.  Moreover,  students  actively  shared  opinions  about  issues  of  privacy\r\nand data ownership, drawing on personal experiences with platforms like YouTube\r\nand TikTok. Zhang et\u00a0al., (2022) found similar results among slightly older students\r\n(11\u201314\u00a0years). Similarly, Dipaola et\u00a0al. (2022) found nuanced views on the ethics of\r\nAI when it concerns AI technologies that students aged 11 to 14 are familiar with.\r\nAnother  general  concern  of  students  regards  the  increasing  reliance  on  AI,  conse-\r\nquently making people lazy (Mertala et\u00a0al., 2022; Zhang et\u00a0al., 2022).\r\n\r\nA  notable  difference  between  our  findings  from  the  existing  literature  is  the\r\nabsence of AI understanding as robots (e.g., Kim et\u00a0al., 2023; Mertala et\u00a0al., 2022;\r\nOttenbreit-Leftwich  et\u00a0 al.,  2022;  Williams  et\u00a0 al.,  2022;  Zhang  et\u00a0 al.,  2022).", "mimetype": "text/plain", "start_char_idx": 54433, "end_char_idx": 58033, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3c5f30ad-86a0-48d1-bd46-a4bd21f0a1eb": {"__data__": {"id_": "3c5f30ad-86a0-48d1-bd46-a4bd21f0a1eb", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2e81daf5-96cb-474a-9bb0-946e584387ff", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "fc6579dec2cc9aa5e4dc813a06e73eab05e3133c08abf0460ee42a1f0d3298ad", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6bd9c571-702b-4b4e-bdcf-b1b6f10369d0", "node_type": "1", "metadata": {}, "hash": "13e942c6bb1c447e030157da09e9148e7d9a7803dc4d7be26148d39d1bcdb516", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Similarly, Dipaola et\u00a0al. (2022) found nuanced views on the ethics of\r\nAI when it concerns AI technologies that students aged 11 to 14 are familiar with.\r\nAnother  general  concern  of  students  regards  the  increasing  reliance  on  AI,  conse-\r\nquently making people lazy (Mertala et\u00a0al., 2022; Zhang et\u00a0al., 2022).\r\n\r\nA  notable  difference  between  our  findings  from  the  existing  literature  is  the\r\nabsence of AI understanding as robots (e.g., Kim et\u00a0al., 2023; Mertala et\u00a0al., 2022;\r\nOttenbreit-Leftwich  et\u00a0 al.,  2022;  Williams  et\u00a0 al.,  2022;  Zhang  et\u00a0 al.,  2022).  As\r\na  matter  of  fact,  no  one  used  the  term  \"robot\"  in  abstract  AI  conceptualizations.\r\nReferences to robots were only limited to specific AI examples like robot vacuum\r\ncleaners, lawnmowers, or two distinct provided by two individual students: educa-\r\ntional toys or companionship robots in the home of a grandmother with dementia.\r\nIn  literature,  conceptualizations  of  AI  as  robots  are  often  present  and  assigned  to\r\nunrealistic AI media portrayals (DiPaola et\u00a0al., 2022; Kim et\u00a0al., 2023). This might\r\nsuggest a more nuanced understanding of Artificial Intelligence.\r\n\r\nA  possible  explanation  for  the  absence  of  robot-related  references  may  stem\r\nfrom  the  fact  that  in  socio-cultural  context  of  the  study  it  is  uncommon  to  have\r\ninteractions with robots, whereas for example in Japan, personal and service robots\r\nco-exist with people in Japanese society, where robots work together with people\r\nin restaurants and shops (Eguchi et\u00a0al., 2021). Another possible explanation of this\r\ndiscrepancy might be that children\u2019s understanding was dominantly framed within\r\nthe context of their own experiences and use of AI within their homes, whereas for\r\nexample in Zhang et\u00a0al\u2019s. (2022) study, students engaged in ways in which careers\r\nwill be impacted by AI, resulting in kids imagining AI being able to take over dan-\r\ngerous jobs or perform tasks with more efficiency.\r\n\r\nOur findings suggest that children develop an understanding of AI through the use\r\nof AI technologies in their everyday lives. This is demonstrated in the findings through\r\nchildren\u2019s  various  strategies  to  manipulate  TikTok\u2019s  recommendation  algorithms  to\r\ncurate diverse content, such as intentionally liking videos that they don\u2019t enjoy. Although\r\nchildren do not explicitly link these actions to the workings of AI, students\u2019 everyday\r\nexperiences and observations lay the groundwork for a preliminary understanding. This\r\nunderscores the influential role of personal encounters in shaping students\u2019 early percep-\r\ntions of AI, aligning with the socio-cultural framework proposed by Vygotsky.\r\n\r\nFurthermore,  our  findings  indicate  that  children  perceive  AI  as  first  and  foremost\r\nas a tool rather than a technology. Unlike framing AI abilities in terms of its technical\r\ncapabilities, such as sensing or hearing through sensors, students focused on how AI\r\nfunctions in the context of their homes. Examples included AI abilities to manage lights\r\nand curtains, perform cleaning activities, or aid less abled in the context of their homes.\r\nThis perspective highlights the practical, hands-on role students attribute to AI, empha-\r\nsizing its utility as a tool within their immediate living environments or those of others.\r\nFinally,  the  findings  indicate  that  children  exhibit  a  high  level  of  engagement\r\nwith  the  ethics  of  AI,  showing  a  keen  interest  in  the  socio-cultural  implications,\r\n\r\n\fEducation and Information Technologies\r\n\r\nparticularly about AI applications with which they are familiar. Platforms like You-\r\nTube and TikTok provide appropriate and relatable contexts to start discussions on\r\ncrucial topics such as privacy, data ownership, and how AI influences behavior.\r\n\r\n6   Conclusions and\u00a0recommendations\r\n\r\nThe rapid integration of AI in our daily lives has turned AI literacy into a necessary\r\nskill set and kicked off the development of AI education for schools.", "mimetype": "text/plain", "start_char_idx": 57446, "end_char_idx": 61482, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6bd9c571-702b-4b4e-bdcf-b1b6f10369d0": {"__data__": {"id_": "6bd9c571-702b-4b4e-bdcf-b1b6f10369d0", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3c5f30ad-86a0-48d1-bd46-a4bd21f0a1eb", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "48422daa4eef81d09b2370bb5ec00d8f0bd8642fb44d1f042e938595d6d7bd35", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c0417223-e681-4a65-b403-2970cfd41540", "node_type": "1", "metadata": {}, "hash": "9c839dd077ecfcf9251c4e8077055c91470a9b7763d338a017ed91e792d4c809", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This perspective highlights the practical, hands-on role students attribute to AI, empha-\r\nsizing its utility as a tool within their immediate living environments or those of others.\r\nFinally,  the  findings  indicate  that  children  exhibit  a  high  level  of  engagement\r\nwith  the  ethics  of  AI,  showing  a  keen  interest  in  the  socio-cultural  implications,\r\n\r\n\fEducation and Information Technologies\r\n\r\nparticularly about AI applications with which they are familiar. Platforms like You-\r\nTube and TikTok provide appropriate and relatable contexts to start discussions on\r\ncrucial topics such as privacy, data ownership, and how AI influences behavior.\r\n\r\n6   Conclusions and\u00a0recommendations\r\n\r\nThe rapid integration of AI in our daily lives has turned AI literacy into a necessary\r\nskill set and kicked off the development of AI education for schools. To inform the\r\ndesign of effective educational resources, we took a qualitative research approach to\r\nexplore young children\u2019s understanding of AI as a technology and a tool with socio-\r\ncultural impact. This approach offered a deeper understanding of how students under-\r\nstand AI, its uses, as well as issues related to ethics. The findings suggest that chil-\r\ndren\u2019s  understanding  of  AI  is  grounded  in  their  personal  experiences  and  habits  as\r\npart of their everyday lives. Furthermore, we found that children have a socio-cultural\r\napproach to AI in which they experience AI as first and foremost a tool that can help,\r\nbut also influence their behavior. The goal of this exploratory study was not to draw\r\ngeneralizable conclusions but rather to construct an in-depth understanding of young\r\nchildren\u2019s sense-making of AI. Based on our findings, and supporting evidence from\r\nthe growing literature on both students\u2019 prior AI conceptions and experiences with AI\r\nethics curricula, we offer a set of recommendations for the design of engaging and per-\r\nsonally relevant AI education curriculum materials for primary school students.\r\n\r\nFirst, to tackle the common misconception among students that AI is robots, we\r\nrecommend  focusing  on  software  applications  of  AI  by  providing  students  with\r\nalternative, more realistic, and above all recognizable applications derived from their\r\ncontexts.  Such  an  emphasis  not  only  broadens  their  understanding  of  AI  beyond\r\nrobotic portrayals but also grounds the concept in relatable, real-world scenarios.\r\n\r\nSecondly, in curriculum design, careful consideration of the socio-cultural con-\r\ntext  of  students  is  essential.  Integrating  learning  activities  that  connect  with  com-\r\nmon daily life AI experiences to which students may already have been exposed is\r\ncrucial. A practical implementation of this recommendation is to use AI recommen-\r\ndation  software,  such  as  those  found  on  platforms  like  TikTok  or  YouTube,  as  an\r\naccessible entry point for students to grasp what role data has in the working of AI.\r\nBy contextualizing AI learning within students\u2019 everyday life experiences, educators\r\ncan enhance engagement and foster critical AI literacy.\r\n\r\nHowever, as highlighted by Eguchi et\u00a0al. (2021) and Druga et\u00a0al. (2019), prior AI\r\nexperiences  are  not  universal  and  can  differ  based  on  several  factors,  such  as  geo-\r\ngraphical context, socio-economic status, or family interests. This leads to our third\r\nrecommendation:  to  create  AI  experiences  in  the  classroom,  as  a  collective  experi-\r\nence that can be used as an entry point for other learning activities. For example, by\r\nplacing a Hey Google in the classroom and integrating it into the teaching by using\r\nit to set timers during class activities asking it to share a weather report before going\r\noutside, or using a robot vacuum cleaner to clean the classroom. This way, instead\r\nof  assuming  individual  AI  experiences,  the  teacher  can  create  collective  classroom\r\nexperiences that can be central to the AI lessons.\r\n\r\n\fEducation and Information Technologies\r\n\r\nLastly, our final recommendation proposes to develop  critical AI literacy that places\r\njustice at the forefront and approaches AI as a socio-cultural tool (Avraamidou,  2024).\r\nAlthough many AI literacy frameworks incorporate an element of AI ethics, the emphasis\r\noften centers on AI as a technology (e.g., Long & Magerko, Touretzky et\u00a0al., 2019).", "mimetype": "text/plain", "start_char_idx": 60616, "end_char_idx": 64992, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c0417223-e681-4a65-b403-2970cfd41540": {"__data__": {"id_": "c0417223-e681-4a65-b403-2970cfd41540", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6bd9c571-702b-4b4e-bdcf-b1b6f10369d0", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "fba11dab5c377b2433e542ab5a4c57003d626119e8fe3a607f851b4e69295017", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4081bba7-26db-4870-8b94-14ca780d9f39", "node_type": "1", "metadata": {}, "hash": "2c44d7ae765e1d87476799219f8d4162c7f1e472233eb40e5245622c0bfe403e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "For example, by\r\nplacing a Hey Google in the classroom and integrating it into the teaching by using\r\nit to set timers during class activities asking it to share a weather report before going\r\noutside, or using a robot vacuum cleaner to clean the classroom. This way, instead\r\nof  assuming  individual  AI  experiences,  the  teacher  can  create  collective  classroom\r\nexperiences that can be central to the AI lessons.\r\n\r\n\fEducation and Information Technologies\r\n\r\nLastly, our final recommendation proposes to develop  critical AI literacy that places\r\njustice at the forefront and approaches AI as a socio-cultural tool (Avraamidou,  2024).\r\nAlthough many AI literacy frameworks incorporate an element of AI ethics, the emphasis\r\noften centers on AI as a technology (e.g., Long & Magerko, Touretzky et\u00a0al., 2019). How-\r\never,  both  our  findings  and  existing  literature  illustrate  that  students\u2019  engagement  with\r\nAI is especially intertwined with ethical considerations and socio-cultural implications.\r\nTherefore, adopting a critical AI literacy framework appears to be a promising direction.\r\n\r\nAppendix\r\n\r\nSemi-structured interview questions:\r\n\r\nThese questions served as the base for the semi-structured interviews. It\u2019s important\r\nto note that the order of the questions was adjusted based on the flow of the conversation\r\nand  the  responses  of  the  young  children.  In  many  instances,  while  responding  to  one\r\nquestion, students often addressed other questions, or multiple questions simultaneously.\r\n\r\nAI as a technology\r\n\r\n\u2013  Can you explain what AI is?\r\n\u2013  How does AI work?\r\n\u2013  What are examples of AI?\r\n\u2013  Where can we find AI?\r\n\r\nAI as a tool\r\n\r\n\u2013  Do you use AI at home?\r\n\u2013  What do you use AI for?\r\n\u2013  What can AI do?\r\n\u2013  Can AI help us?\r\n\r\nAI and ethics\r\n\r\n\u2013  Does AI also affect you?\r\n\u2013  Is AI always good for us?\r\n\u2013  Can AI make mistakes?\r\n\u2013  Can AI be dangerous?\r\n\r\nDuring  the  interviews,  the  first  two  groups  eagerly  discussed  an  exercise  at\r\nschool  on  AI  biases.  The  students  spoke  about  this  exercise  with  such  emotion\r\nthat  the  researcher  decided  to  ask  the  other  groups  about  it  as  well,  to  further\r\nexplore the children\u2019s engagement with the topic.\r\n\r\n\u2013  Do you remember the exercise where you had to look for \u2018baby\u2019 in Google Images?\r\n\r\n\fEducation and Information Technologies\r\n\r\nAcknowledgements  This project has received funding from the European Union\u2019s Horizon 2020 research\r\nand  innovation  programme  under  grant  agreement  number  101070285  for  the  project  \u201cMAMMOth\u2014\r\nMulti-Attribute, Multimodal Bias Mitigation in AI Systems\u201d. This work reflects only the authors\u2019 views\r\nand the European Research Executive Agency (REA) is not responsible for any use that may be made of\r\nthe information it contains.\r\n\r\nData availability  The datasets gathered and analyzed during the current study are available from the cor-\r\nresponding author upon reasonable request.\r\n\r\nDeclarations\r\n\r\nCompeting interests  The authors declare that they have no competing interests.\r\n\r\nOpen Access  This  article  is  licensed  under  a  Creative  Commons  Attribution  4.0  International  License,\r\nwhich permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long\r\nas  you  give  appropriate  credit  to  the  original  author(s)  and  the  source,  provide  a  link  to  the  Creative\r\nCommons licence, and indicate if changes were made. The images or other third party material in this\r\narticle are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line\r\nto the material. If material is not included in the article\u2019s Creative Commons licence and your intended\r\nuse is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permis-\r\nsion directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/\r\nlicenses/by/4.0/.\r\n\r\nReferences\r\n\r\nAli, S., DiPaola, D., Lee, I., Sindato, V., Kim, G., Blumofe, R., & Breazeal, C. (2021). Children as crea-\r\ntors, thinkers and citizens in an AI-driven future. Computers and Education: Artificial Intelligence,\r\n2, 100040\u2013100051.", "mimetype": "text/plain", "start_char_idx": 64175, "end_char_idx": 68369, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4081bba7-26db-4870-8b94-14ca780d9f39": {"__data__": {"id_": "4081bba7-26db-4870-8b94-14ca780d9f39", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c0417223-e681-4a65-b403-2970cfd41540", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "97331dc1db18cc82058ce2eca4a404189d9c3388862037253034c535c19d0604", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d12f10c0-f1d5-4b34-8688-c66f3d11cbf5", "node_type": "1", "metadata": {}, "hash": "46f03c9d3a124b899dc1193ae2baa8beb3de78cffec811683c44b612fe0cf97b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The images or other third party material in this\r\narticle are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line\r\nto the material. If material is not included in the article\u2019s Creative Commons licence and your intended\r\nuse is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permis-\r\nsion directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/\r\nlicenses/by/4.0/.\r\n\r\nReferences\r\n\r\nAli, S., DiPaola, D., Lee, I., Sindato, V., Kim, G., Blumofe, R., & Breazeal, C. (2021). Children as crea-\r\ntors, thinkers and citizens in an AI-driven future. Computers and Education: Artificial Intelligence,\r\n2, 100040\u2013100051. https:// doi. org/ 10. 1016/j. caeai. 2021. 100040\r\n\r\nAvraamidou,  L.  (2013).  Superheroes  and  supervillains:  Reconstructing  the  mad-scientist  stereotype  in\r\nschool science. Research in Science and Technological Education, 31(1), 90\u2013115. https:// doi. org/ 10.\r\n1080/ 02635 143. 2012. 761605\r\n\r\nHeeg,  D.  M.,  Smith,  T.,  &  Avraamidou,  L.  (2022).  Children\u2019s  experiences  and  self-identification  with\r\nscience in the context of an out-of-school stem program. EURASIA Journal of Mathematics, Science\r\nand Technology Education, 18(4), Article em2091. https:// doi. org/ 10. 29333/ ejmste/ 11888\r\n\r\nHeeg, D. M., & Avraamidou, L. (2023). The use of artificial intelligence in school science: A systematic\r\nliterature  review.  Educational  Media  International,  60(2),  125\u2013150.  https:// doi. org/ 10. 1080/ 09523\r\n987. 2023. 22649 90\r\n\r\nAvraamidou,  L.  (2024).  Can  we  disrupt  the  momentum  of  the  AI  colonization  of  science  education?\r\nJournal  of  Research  in  Science  Teaching.  Advance  online  publication.  https:// doi. org/ 10. 1002/ tea.\r\n21961\r\n\r\nBurgsteiner, H., Kandlhofer, M., & Steinbauer, G. (2016). Irobot: Teaching the basics of artificial intel-\r\nligence in high schools. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 30,\r\nNo. 1). https:// doi. org/ 10. 1609/ aaai. v30i1. 9864\r\n\r\nCasal-Otero, L., Catala, A., Fern\u00e1ndez-Morante, C., Taboada, M., Cebreiro, B., & Barro, S. (2023). AI\r\nliteracy in K-12: A systematic literature review. International Journal of STEM Education, 10(1),\r\n29. https:// doi. org/ 10. 1186/ s40594- 023- 00418-7\r\n\r\nChen, Y., & Tang, X. (2018). Fundamentals of Artificial Intelligence for High Schools. East China Nor-\r\n\r\nmal University Press.\r\n\r\nDiPaola, D., Payne, B. H., & Breazeal, C. (2020). Decoding design agendas: an ethical design activity for\r\nmiddle school students. Proceedings of the Interaction Design and Children conference, (pp. 1\u201310).\r\nhttps:// doi. org/ 10. 1145/ 33920 63. 33943 96\r\n\r\nDiPaola, D., Payne, B. H., & Breazeal, C. (2022). Preparing children to be conscientious consumers and\r\ndesigners of Ai technologies. In S. Kong & H. Abelson (Eds.), Computational Thinking Education\r\nin K-12: Artificial Intelligence Literacy and Physical Computing. MIT Press.", "mimetype": "text/plain", "start_char_idx": 67625, "end_char_idx": 70646, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d12f10c0-f1d5-4b34-8688-c66f3d11cbf5": {"__data__": {"id_": "d12f10c0-f1d5-4b34-8688-c66f3d11cbf5", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4081bba7-26db-4870-8b94-14ca780d9f39", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "c671e88d394ac882ac170602c1e84880beb0307431e6f76b3eb6db0be07c521f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7e8ac85d-c80b-484c-a206-d779e8e6dc07", "node_type": "1", "metadata": {}, "hash": "e37003c3e07fc7ef950b554a414e252039efd1b49d116e1b74852c8f300a025c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "(2018). Fundamentals of Artificial Intelligence for High Schools. East China Nor-\r\n\r\nmal University Press.\r\n\r\nDiPaola, D., Payne, B. H., & Breazeal, C. (2020). Decoding design agendas: an ethical design activity for\r\nmiddle school students. Proceedings of the Interaction Design and Children conference, (pp. 1\u201310).\r\nhttps:// doi. org/ 10. 1145/ 33920 63. 33943 96\r\n\r\nDiPaola, D., Payne, B. H., & Breazeal, C. (2022). Preparing children to be conscientious consumers and\r\ndesigners of Ai technologies. In S. Kong & H. Abelson (Eds.), Computational Thinking Education\r\nin K-12: Artificial Intelligence Literacy and Physical Computing. MIT Press.\r\n\r\n\fEducation and Information Technologies\r\n\r\nDruga,  S.,  Williams,  R.,  Breazeal,  C.,  &  Resnick,  M.  (2017).  Hey  Google  is  it  ok  if  I  eat  you?  Initial\r\nexplorations  in  child-agent  interactions.  In  Proceedings  of  the  2017  Conference  on  Interaction\r\nDesign and Children, 595\u2013600. ACM. https:// doi. org/ 10. 1145/ 30780 72. 30843 30\r\n\r\nDruga, S., Vu, S. T., Likhith, E., & Qiu, T. (2019). Inclusive AI literacy for kids around the world. In P.\r\nBlikstein  &  N.  Holberts  (Eds).,  Proceedings  of  FabLearn  2019  8th  Annual  Conference  on  Maker\r\nEducation (pp. 104\u2013111). The Association for Computing Machinery. https:// doi. org/ 10. 1145/ 33118\r\n90. 33119 04\r\n\r\nEguchi, A., Okada, H., & Muto, Y. (2021). Contextualizing AI education for K-12 students to enhance\r\ntheir  learning  of  AI  literacy  through  culturally  responsive  approaches.  KI-K\u00fcnstliche  Intelligenz,\r\n35(2), 153\u2013161. https:// doi. org/ 10. 1007/ s13218- 021- 00737-3\r\n\r\nHenry, J., Hernalesteen, A., & Collard, A. S. (2021). Teaching artificial intelligence to K-12 through a\r\nrole-playing game questioning the intelligence concept. KI-K\u00fcnstliche Intelligenz, 35(2), 171\u2013179.\r\nhttps:// doi. org/ 10. 1007/ s13218- 021- 00733-7\r\n\r\nKandlhofer,  M.,  Steinbauer,  G.,  Hirschmugl-Gaisch,  S.,  &  Huber,  P.  (2016).  Artificial  intelligence  and\r\ncomputer science in education: From kindergarten to university. In 2016 IEEE Frontiers in Educa-\r\ntion Conference (FIE) (pp. 1\u20139). IEEE. https:// doi. org/ 10. 1109/ FIE. 2016. 77575 70\r\n\r\nKim,  K.,  Kwon,  K.,  Ottenbreit-Leftwich,  A.,  Bae,  H.,  &  Glazewski,  K.  (2023).  Exploring  middle\r\nschool  students\u2019  common  naive  conceptions  of  artificial  intelligence  concepts,  and  the  evolu-\r\ntion of these ideas. Education and Information Technologies, (20230118). https:// doi. org/ 10. 1007/\r\ns10639- 023- 11600-3\r\n\r\nKong, S. C., & Zhang, G. (2021). A Conceptual framework for designing artificial intelligence literacy\r\nprogrammes for educated citizens.", "mimetype": "text/plain", "start_char_idx": 70002, "end_char_idx": 72664, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7e8ac85d-c80b-484c-a206-d779e8e6dc07": {"__data__": {"id_": "7e8ac85d-c80b-484c-a206-d779e8e6dc07", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d12f10c0-f1d5-4b34-8688-c66f3d11cbf5", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "ea1700d9b2b77101890af78e8f9a0b70866e3e79908355a07bc115893ed89768", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9eb92c92-5e1b-45a1-9f4a-7ec310567818", "node_type": "1", "metadata": {}, "hash": "855579349f94ae8e3f0702f1f414f50a2f4b226304f8dc66c3fa9823ac00fa27", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "1\u20139). IEEE. https:// doi. org/ 10. 1109/ FIE. 2016. 77575 70\r\n\r\nKim,  K.,  Kwon,  K.,  Ottenbreit-Leftwich,  A.,  Bae,  H.,  &  Glazewski,  K.  (2023).  Exploring  middle\r\nschool  students\u2019  common  naive  conceptions  of  artificial  intelligence  concepts,  and  the  evolu-\r\ntion of these ideas. Education and Information Technologies, (20230118). https:// doi. org/ 10. 1007/\r\ns10639- 023- 11600-3\r\n\r\nKong, S. C., & Zhang, G. (2021). A Conceptual framework for designing artificial intelligence literacy\r\nprogrammes for educated citizens. In S. C. Kong, Q. Wang, R. Huang, Y. Li, & T. C. Hse (eds).,\r\nConference  Proceedings  (English  Track)  of  the  25th  Global  Chinese  Conference  on  Computers  in\r\nEducation, GCCCE 2021 (pp. 11-15). The Education University of Hong Kong\r\n\r\nLee, I., Ali, S., Zhang, H., DiPaola, D., & Breazeal, C. (2021). Developing middle school students\u2019 AI\r\nliteracy. In Proceedings of the 52nd ACM technical symposium on computer science education (pp.\r\n191\u2013197). https:// doi. org/ 10. 1145/ 34088 77. 34325 13\r\n\r\nLong,  D.,  &  Magerko,  B.  (2020).  What  is  AI  literacy?  Competencies  and  design  considerations.  In  R.\r\nBernhaupt, F. F. Muller, D. Verweij & J. Andres (Eds)., Proceedings of the 2020 CHI conference on\r\nhuman factors in computing systems (pp. 1\u201316). Association for Computing Machinery. https:// doi.\r\norg/ 10. 1145/ 33138 31. 33767 27\r\n\r\nMerriam,  S.  B.,  &  Tisdell,  E.  J.  (2015).  Qualitative  research:  A  guide  to  design  and  implementation.\r\n\r\nWiley.\r\n\r\nMertala,  P.,  Fagerlund,  J.,  &  Calderon,  O.  (2022).  Finnish   5th  and   6th-grade  students\u2019  pre-instructional\r\nconceptions of artificial intelligence (AI) and their implications for AI literacy education. Comput-\r\ners and Education: Artificial Intelligence, 100095. https:// doi. org/ 10. 1016/j. caeai. 2022/ 100095\r\nMicheuz, P. (2020). Approaches to Artificial Intelligence as a Subject in School Education. In T. Brinda,\r\nD. Passey, & T. Keane (Eds), Empowering Teaching for Digital Equity and Agency. OCCE 2020.\r\nIFIP Advances in Information and Communication Technology, 595. Springer.\r\n\r\nNg,  D.  T.  K.,  Leung,  J.  K.  L.,  Chu,  S.  K.  W.,  &  Qiao,  M.  S.  (2021).  Conceptualizing  AI  literacy  an\r\nexploratory review. Computers and Education: Artificial Intelligence, 2, 100041. https:// doi. org/ 10.\r\n1016/j. caeai. 2021. 100041\r\n\r\nNg, D. T. K., Leung, J. K. L., Su, M. J., Yim, I. H. Y., Qiao, M. S., & Chu, S. K. W. (2022a). AI literacy\r\nfor All. AI literacy in K-16 classrooms (pp. 21\u201330). Springer International Publishing. https:// doi.\r\norg/ 10.", "mimetype": "text/plain", "start_char_idx": 72122, "end_char_idx": 74729, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9eb92c92-5e1b-45a1-9f4a-7ec310567818": {"__data__": {"id_": "9eb92c92-5e1b-45a1-9f4a-7ec310567818", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7e8ac85d-c80b-484c-a206-d779e8e6dc07", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "44a1710a45ce578f9cd249059ac227f09bec660e764f13fb09e9fc19fe7dc79d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fb56e114-803e-4063-a803-a95bbaa198fa", "node_type": "1", "metadata": {}, "hash": "17d9792afa5ff4e40a03b215cf1dc71e4ed87cf183f4b1b07f7e3e2611f656f0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "(2021).  Conceptualizing  AI  literacy  an\r\nexploratory review. Computers and Education: Artificial Intelligence, 2, 100041. https:// doi. org/ 10.\r\n1016/j. caeai. 2021. 100041\r\n\r\nNg, D. T. K., Leung, J. K. L., Su, M. J., Yim, I. H. Y., Qiao, M. S., & Chu, S. K. W. (2022a). AI literacy\r\nfor All. AI literacy in K-16 classrooms (pp. 21\u201330). Springer International Publishing. https:// doi.\r\norg/ 10. 1007/ 978-3- 031- 18880-0_3\r\n\r\nNg, D. T. K., Leung, J. K. L., Su, M. J., Yim, I. H. Y., Qiao, M. S., & Chu, S. K. W. (2022b). The Land-\r\nscape of AI Literacy. AI literacy in K-16 classrooms (pp. 31\u201362). Springer International Publishing.\r\nhttps:// doi. org/ 10. 1007/ 978-3- 031- 18880-0_4\r\n\r\nOECD.  (2021).  AI  and  the  Future  of  Skills,  Volume  1:  Capabilities  and  Assessments.  Educational\r\n\r\nResearch and Innovation, OECD Publishing, Paris. https:// doi. org/ 10. 1787/ 5ee71 f34- en\r\n\r\nOttenbreit-Leftwich, A., Glazewski, K., Jeon, M., Jantaraweragul, K., Hmelo-Silver, C. E., Scrinber, A.,\r\nLee, S., Mott, B., & Lester, J. (2022). Lessons Learned for AI Education with Elementary Students\r\nand Teachers. International Journal of Artificial Intelligence in Education, 1\u201323. https:// doi. org/ 10.\r\n1007/ s40593- 022- 00304-3\r\n\r\nPayne, B. H. (2020). Can my algorithm be my opinion?: An AI + Ethics curriculum for Middle School\r\nStudents.  Master\u2019s  thesis,  Massachusetts  Institute  of  Technology,  Media  Lab,  Cambridge,  MA,\r\nUSA.\r\n\r\n\fEducation and Information Technologies\r\n\r\nPedro, F., Subosa, M., Rivas, A., & Valverde, P. (2019) Artificial intelligence in education: Challenges\r\nand opportunities for sustainable development. Paris: UNESCO . Retrieved January 30, 2023 from\r\nhttps:// unesd oc. unesco. org/ ark:/ 48223/ pf000 03669 94\r\n\r\nRedecker, C. (2017). European framework for the digital competence of educators. Office of the Euro-\r\n\r\npean Union.\r\n\r\nSchepman,  A.,  &  Rodway,  P.  (2023).  The  General  Attitudes  towards  Artificial  Intelligence  Scale\r\n(GAAIS): Confirmatory Validation and Associations with Personality, Corporate Distrust, and Gen-\r\neral Trust. International Journal of Human-Computer Interaction, 39(13), 2724\u20132741. https:// doi.\r\norg/ 10. 1080/ 10447 318. 2022. 20854 00\r\n\r\nSu,  J.,  Ng,  D.  T.  K.,  &  Chu,  S.  K.  W.  (2023a).  Artificial  intelligence  (AI)  literacy  in  early  childhood\r\neducation:  The  challenges  and  opportunities.\u00a0 Computers  and  Education:  Artificial  Intelligence,\u00a0 4.\r\nhttps:// doi. org/ 10. 1016/j. caeai. 2023. 100124\r\n\r\nSu, J., Guo, K., Chen, X., & Chu, S. K. W. (2023b). Teaching artificial intelligence in K\u201312 classrooms:\r\na scoping review.\u00a0Interactive Learning Environments, 1\u201320. https:// doi. org/ 10. 1080/ 10494 820. 2023.", "mimetype": "text/plain", "start_char_idx": 74330, "end_char_idx": 77053, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fb56e114-803e-4063-a803-a95bbaa198fa": {"__data__": {"id_": "fb56e114-803e-4063-a803-a95bbaa198fa", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9eb92c92-5e1b-45a1-9f4a-7ec310567818", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "609ac17e4b73f00797b7e37050dab926ebb50d47889e2d0aefe06b4f3c7f2f9a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b7afd206-c9cd-4137-844c-076e2a9a6b0b", "node_type": "1", "metadata": {}, "hash": "54213cb0b34aafbd9a7288441e81c822c3bf30a2330e425dc90970f211a60b73", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2022. 20854 00\r\n\r\nSu,  J.,  Ng,  D.  T.  K.,  &  Chu,  S.  K.  W.  (2023a).  Artificial  intelligence  (AI)  literacy  in  early  childhood\r\neducation:  The  challenges  and  opportunities.\u00a0 Computers  and  Education:  Artificial  Intelligence,\u00a0 4.\r\nhttps:// doi. org/ 10. 1016/j. caeai. 2023. 100124\r\n\r\nSu, J., Guo, K., Chen, X., & Chu, S. K. W. (2023b). Teaching artificial intelligence in K\u201312 classrooms:\r\na scoping review.\u00a0Interactive Learning Environments, 1\u201320. https:// doi. org/ 10. 1080/ 10494 820. 2023.\r\n22127 06\r\n\r\nSzczuka,  J.  M.,  Starthmann,  C.,  Szymczyk,  N.,  Mavrina,  L.  &  Kr\u00e4mer,  N.C.  (2022).  How  do  children\r\nacquire knowledge about voice assistants? A longitudinal field study on children\u2019s knowledge about\r\nhow voice assistants store and process data. International Journal of Child-Computer Interaction,\r\n33. https:// doi. org/ 10. 1016/j. ijcci. 2022. 100460\r\n\r\nSu, J., & Zhong, Y. (2022). Artificial Intelligence (AI) in early childhood education: Curriculum design\r\nand future directions. Computers and Education: Artificial Intelligence, 3. https:// doi. org/ 10. 1016/j.\r\ncaeai. 2022. 100072\r\n\r\nTouretzky, D., Gardner-McCune, C., Martin, F., & Seehorn, D. (2019). Envisioning AI for K12: What\r\nshould  every  child  know  about  AI?  In  Proceedings  of  the  AAAI  Conference  on  Artificial  Intelli-\r\ngence., 33, 9795\u20139799. https:// doi. org/ 10. 1609/ aaai. v33i01. 33019 795\r\n\r\nUNESCO. (2019). Artificial intelligence for sustainable development programme. Retrieved February 2,\r\n\r\n2023, from: https:// en. unesco. org/ sites/ defau lts/ files/ mlw20 19- progr amme. pdf\r\n\r\nUNESCO. (2022). K-12 AI curricula A mapping of government-endorsed AI curricula. Retrieved January\r\n\r\n30, 2023, from https:// unesd oc. unesco. org/ ark:/ 48223/ pf000 03806 02\r\n\r\nUNICEF.  (2021).  Policy  guidance  on  AI  for  children.  Retrieved  February  2,  2023  from:  https:// www.\r\n\r\nunicef. org/ globa linsi ght/ media/ 2356/ file\r\n\r\nVan  Brummelen,  J.,  Heng,  T.,  &  Tabunshschyk,  V.  (2021).  Teaching  tech  to  talk:  K-12  conversational\r\nartificial intelligence literacy curriculum and development tools. Proceedings of the AAAI Confer-\r\nence on Artificial Intelligence, 35(17), 15655\u201315663. https:// doi. org/ 10. 1609/ aaai. v35i17. 17844\r\nVanover,  C.,  Mihas,  P.,  &  Johnny,  Salda\u00f1a  (Eds.).  (2022).  Analyzing  and  interpreting  qualitative\r\n\r\nresearch : after the interview (First). SAGE Publications.\r\n\r\nWang,  B.,  Rau,  P.-L.P.,  &  Yuan.  (2023).  Measuring  user  competence  in  using  artificial  intelligence:\r\nValidity and reliability of artificial intelligence literacy scale. Behaviour & Information Technology,\r\n42(9), 1324\u20131337. https:// doi. org/ 10. 1080/ 01449 29X. 2022.", "mimetype": "text/plain", "start_char_idx": 76539, "end_char_idx": 79278, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b7afd206-c9cd-4137-844c-076e2a9a6b0b": {"__data__": {"id_": "b7afd206-c9cd-4137-844c-076e2a9a6b0b", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c6354d0-ff8f-40c4-aee4-4bbe56da614f", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "1db02b8f538533928cd0dd89bb68fd23c06138bbae906d0376fda961c1714ec3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fb56e114-803e-4063-a803-a95bbaa198fa", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}, "hash": "b7e2c865108939a2069b490c1f5b1f943c7ef83a86902c323dcb9b685762d6e0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "https:// doi. org/ 10. 1609/ aaai. v35i17. 17844\r\nVanover,  C.,  Mihas,  P.,  &  Johnny,  Salda\u00f1a  (Eds.).  (2022).  Analyzing  and  interpreting  qualitative\r\n\r\nresearch : after the interview (First). SAGE Publications.\r\n\r\nWang,  B.,  Rau,  P.-L.P.,  &  Yuan.  (2023).  Measuring  user  competence  in  using  artificial  intelligence:\r\nValidity and reliability of artificial intelligence literacy scale. Behaviour & Information Technology,\r\n42(9), 1324\u20131337. https:// doi. org/ 10. 1080/ 01449 29X. 2022. 20727 68\r\n\r\nWilliams,  R.,  Ali,  S.,  Devasia,  N.,  Dipaola,  D.,  Hong,  J.,  Kaputsos,  S.  P.,  Jodan,  B.,  &  Breazeal,  C.\r\n(2022). AI ethics curricula for middle school youth: Lessons learned from three project-based cur-\r\nricula.\u00a0 International  Journal  of  Artificial  Intelligence  in  Education,  1\u201359.  https:// doi. org/ 10. 1007/\r\ns40593- 022- 00298-y\r\n\r\nWilliams, R., Park, H. W., Oh, L., & Breazeal, C. (2019). Popbots: Designing an artificial intelligence\r\ncurriculum  for  early  childhood  education.  In  33rd  AAAI  Conference  on  Artificial  Intelligence  (pp.\r\n9829\u20139736). https:// doi. org/ 10. 1609/ aaai. v33i01. 33019 729\r\n\r\nXiong, Y., Wang, J., & Huang, J. (2018). Textbook Series on Artificial Intelligence for Elementary and\r\n\r\nMiddle Schools. East China Normal University Press.\r\n\r\nYue, M., Jong, M. S. Y., & Dai, Y. (2022). Pedagogical design of K-12 artificial intelligence education: A\r\n\r\nsystematic review. Sustainability, 14(23), 15620. https:// doi. org/ 10. 3390/ su142 315620\r\n\r\nZhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., & Breazeal, C. (2022). Integrating ethics and career\r\nfutures  with  technical  learning  to  promote  AI  literacy  for  middle  school  students:  An  exploratory\r\nstudy. International Journal of Artificial Intelligence in Education, 33(2), 290\u2013324. https:// doi. org/\r\n10. 1007/ s40593- 022- 00293-3\r\n\r\nPublisher\u2019s Note  Springer Nature remains neutral with regard to jurisdictional claims in published maps\r\nand institutional affiliations.", "mimetype": "text/plain", "start_char_idx": 78772, "end_char_idx": 80797, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "482c0c20-8dda-4301-b468-d3924227fe3a": {"__data__": {"id_": "482c0c20-8dda-4301-b468-d3924227fe3a", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b06720f1-3105-424a-99b9-e8d0ab76344a", "node_type": "1", "metadata": {}, "hash": "67926ed9fc12405066a008c0119ab6218b6a0b1b630164e6d2d13365d3679ccf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Contents lists available at ScienceDirect\r\n\r\nBiomedical Signal Processing and Control\r\n\r\njournal homepage: www.elsevier.com/locate/bspc\r\n\r\nEnhanced-TransUNet for ultrasound segmentation of thyroid nodules\r\nAlper Ozcan a, \u00d6m\u00fcr Tosun b,\u2217, Emrah Donmez c, Muhammad Sanwal a\r\na Akdeniz University, Department of Computer Engineering, Turkey\r\nb Akdeniz University, Department of Management Information Systems, Turkey\r\nc Bandirma Onyedi Eylul University, Department of Software Engineering, Turkey\r\n\r\nA R T I C L E I N F O\r\n\r\nA B S T R A C T\r\n\r\nKeywords:\r\nArtificial learning\r\nDeep learning\r\nImage processing\r\nThyroid nodule segmentation\r\nUltrasound image segmentation\r\n\r\nMedical image segmentation plays a key role in the early diagnosis and treatment of medical diseases. Thyroid\r\nnodule segmentation is a critical step in early thyroid cancer identification. Accurately segmenting thyroid\r\nnodule areas from ultrasound images is critical for clinical diagnosis and maintaining good health. Because\r\nof the fragile borders of ultrasound images and the complicated structure of thyroid tissue, it is difficult\r\nto correctly separate the delicate outlines of thyroid nodules to provide adequate segmentation findings,\r\nsince they either cannot establish exact edges or segment smaller parts. The segmentation of thyroid nodule\r\nimages presents some fundamental difficulties. First, the intrinsic locality of convolutional neural network\r\nmodels places constraints on their ability to capture information about the whole context. Second, the size of\r\nthe data sets used for thyroid nodule segmentation frequently makes overfitting more likely. Finally, low-\r\nlevel characteristics that are important in displaying thyroid borders eventually disappear throughout the\r\nfeature encoding process. We provide an effective model called Enhanced-TransUNet for thyroid nodule image\r\nsegmentation to overcome these difficulties. The Transformer and UNet concepts are combined in Enhanced-\r\nTransUNet. While the UNet can successfully segregate tiny items, the Transformer can collect information about\r\nthe overall environment. In order to condense superfluous characteristics and lower the chance of overfitting,\r\nEnhanced-TransUNet also makes use of an information bottleneck. Comparing our model to contemporary CNN\r\nor UNET based models, experimental findings on the TN3K and DDTI datasets for brain tumor segmentation\r\ntasks show that our model gets equivalent or better results. For the two datasets, the average Dice Score and\r\nHD95 are 82.92, 95.45, and 13.19, 1.09, respectively. Overall, the Enhanced-TransUNet model for thyroid\r\nnodule image segmentation is promising. Even with weak edges and a complicated tissue structure, it can\r\nprecisely segment thyroid nodules in ultrasound pictures. Due to its usage of the information bottleneck,\r\nEnhanced-TransUNet is also less prone to overfitting than other models. As a result, an AI-based decision\r\nsupport system based on this model can be built to reduce workload and misdiagnosis. This system has\r\nsignificant potential for clinical application by radiologists and surgeons, which can increase clinical diagnostic\r\naccuracy and efficiency.\r\n\r\n1. Introduction\r\n\r\nThe thyroid is located just below the cartilage structure, which\r\nreveals itself with its butterfly-like structure, moves up and down with\r\nswallowing. The thyroid is responsible for the production of hormones\r\nthat regulate many functions in the body. The regularity of thyroid\r\ngland functions, which is very important for body health, affects almost\r\nall metabolic processes in the body. The most known of the thyroid\r\ndisorders is the formation of nodules. Although a significant portion of\r\nthyroid nodules are benign, it is an important disorder that should be\r\ndiagnosed early, as it carries various risks, including cancer.\r\n\r\nToday, the use of computer-aided systems in the field of health\r\nis becoming more and more widespread. These systems, as a deci-\r\nsion support system, can provide the specialist physician with the\r\nopportunity to evaluate and diagnose faster. In these systems, machine\r\nlearning approaches are generally used. Machine learning approaches\r\nhave evolved from machine learning to deep learning methods that\r\nprovide more detailed learning. Deep learning accurately processes fea-\r\ntures in a multi-layered network structure instead of traditional feature\r\nextraction approaches in machine learning. Thus, it is possible to obtain\r\nhigh-level features that better represent the data.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4523, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b06720f1-3105-424a-99b9-e8d0ab76344a": {"__data__": {"id_": "b06720f1-3105-424a-99b9-e8d0ab76344a", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "482c0c20-8dda-4301-b468-d3924227fe3a", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "ecfd0d7ce905d6207d297ef02796c07544aa1fe70710dd96cd5f2c278331bfa6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "722b2acf-3ecd-44e5-aa5c-c90727c597d2", "node_type": "1", "metadata": {}, "hash": "d36a187bcd5a8fa23ae0361e377138484062c5e5132c4ecb29cec5fca99c50d0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The most known of the thyroid\r\ndisorders is the formation of nodules. Although a significant portion of\r\nthyroid nodules are benign, it is an important disorder that should be\r\ndiagnosed early, as it carries various risks, including cancer.\r\n\r\nToday, the use of computer-aided systems in the field of health\r\nis becoming more and more widespread. These systems, as a deci-\r\nsion support system, can provide the specialist physician with the\r\nopportunity to evaluate and diagnose faster. In these systems, machine\r\nlearning approaches are generally used. Machine learning approaches\r\nhave evolved from machine learning to deep learning methods that\r\nprovide more detailed learning. Deep learning accurately processes fea-\r\ntures in a multi-layered network structure instead of traditional feature\r\nextraction approaches in machine learning. Thus, it is possible to obtain\r\nhigh-level features that better represent the data. Convolutional neural\r\n\r\n\u2217 Corresponding author.\r\n\r\nE-mail addresses: alperozcan@akdeniz.edu.tr (A. Ozcan), omurtosun@akdeniz.edu.tr (\u00d6. Tosun), emrahdonmez@bandirma.edu.tr (E. Donmez),\r\n\r\n202151075006@ogr.akdeniz.edu.tr (M. Sanwal).\r\n\r\nhttps://doi.org/10.1016/j.bspc.2024.106472\r\nReceived 18 September 2023; Received in revised form 5 March 2024; Accepted 15 May 2024\r\n\r\nBiomedicalSignalProcessingandControl95(2024)106472Availableonline24May20241746-8094/\u00a92024ElsevierLtd.Allrightsarereserved,includingthosefortextanddatamining,AItraining,andsimilartechnologies.\fA. Ozcan et al.\r\n\r\nnetworks (CNN), one of the deep learning methods, are used on image\r\ndata. CNN models are also a very efficient approach that can be used on\r\nhealth image data. In this study, it was aimed to segment the thyroid\r\nnodules in the image with U-Net, which is a CNN-based segmentation\r\nnetwork, using a dataset consisting of thyroid ultrasound images and\r\nmasks.\r\n\r\nThyroid nodules are abnormal lumps or masses of different struc-\r\ntures and sizes that occur within the thyroid tissue. Thyroid nodule is a\r\ncondition that is usually seen in advanced ages. Although most of these\r\nnodules are harmless and benign, they also carry various health risks.\r\nThese risks include pressure on the trachea due to excessive enlarge-\r\nment, hyperthyroidism caused by excessive hormone production as a\r\nresult of autonomous work, and cancerization. For all these reasons,\r\nan accurate diagnosis of a thyroid nodule in the early stages is an\r\nimportant issue.\r\n\r\nConsidering its success in the field of health, the use of computer de-\r\ncision support systems in the detection of thyroid nodules can produce\r\neffective results. Recently, it is seen that convolutional neural networks\r\nhave been used more frequently in these systems.\r\n\r\nBecause of their powerful feature extraction capabilities and capac-\r\nity for adaptive learning, convolutional neural networks (CNNs) are an\r\nexcellent choice for segmenting medical images. The application of seg-\r\nmentation models based on full convolutional neural networks (FCNs),\r\nas proposed by [1], has been shown to yield substantial enhancements\r\nin the outcomes of medical picture segmentation. However, it is crucial\r\nto acknowledge that FCNs, although efficient, may occasionally provide\r\nambiguous boundaries in their segmentation results due to the upscal-\r\ning procedure, resulting in a reduction of precise high-level semantic\r\ndetails.\r\n\r\nIn the literature U-NET architecture is known for its superiority in\r\nthe image classification tasks [2]. It is renowned for its capacity to use\r\nskip links to combine semantic and geographical information. Skip con-\r\nnections enable the U-Net to learn both low-level texture information\r\nand high-level semantic properties. This is crucial for medical picture\r\nsegmentation because it enables the model to recognize items in the\r\nimage properly while still maintaining their spatial connections [3].\r\nNumerous elements contribute to the U-Net architecture\u2019s success.\r\nFirst, the model can learn both high-level and low-level characteristics\r\nbecause of the usage of skip connections. Second, the symmetry of the\r\nU-Net architecture facilitates training and generalization. Third, the\r\nU-Net design is rather straightforward deploy.", "mimetype": "text/plain", "start_char_idx": 3600, "end_char_idx": 7810, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "722b2acf-3ecd-44e5-aa5c-c90727c597d2": {"__data__": {"id_": "722b2acf-3ecd-44e5-aa5c-c90727c597d2", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b06720f1-3105-424a-99b9-e8d0ab76344a", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "1fd76c800f2156fd9899a38a2bd056db25f5c90579bc5ecec31bed77ca2d88d6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f0127283-2c54-4b9d-8462-35224105c0b4", "node_type": "1", "metadata": {}, "hash": "b3f207a0f2989176906b51e835a2d929609fae60846a58edd492b1329a53c9d4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In the literature U-NET architecture is known for its superiority in\r\nthe image classification tasks [2]. It is renowned for its capacity to use\r\nskip links to combine semantic and geographical information. Skip con-\r\nnections enable the U-Net to learn both low-level texture information\r\nand high-level semantic properties. This is crucial for medical picture\r\nsegmentation because it enables the model to recognize items in the\r\nimage properly while still maintaining their spatial connections [3].\r\nNumerous elements contribute to the U-Net architecture\u2019s success.\r\nFirst, the model can learn both high-level and low-level characteristics\r\nbecause of the usage of skip connections. Second, the symmetry of the\r\nU-Net architecture facilitates training and generalization. Third, the\r\nU-Net design is rather straightforward deploy.\r\n\r\nBy adding additional features, several academics have attempted to\r\nenhance the U-Net design. To gain more discriminative characteristics,\r\nU-Net++ [4] employs a hierarchical design and dense skip connections.\r\nAttention techniques are used by U-Net [5] and Channel U-Net [6]\r\nto improve the discriminative features obtained from the encoder and\r\ndecoder, respectively. An attention-guided upsampling module is sug-\r\ngested by AUNet [7] to enhance the skip connection process, which\r\neliminates extraneous spatial information and closes the semantic gap.\r\nIn the processing of medical images nowadays, U-shaped models\r\nare frequently employed [8\u201312]. The inclusion of skip connections is\r\ncrucial to their success, as it facilitates the integration of lower-level\r\nfeature maps obtained from the encoder, as discussed by [4], with\r\nhigher-level feature maps generated by the decoder. The recollection\r\nof accurate information regarding target objects is facilitated by this\r\ndistinctive combination, even in the presence of complex backgrounds,\r\nas elucidated by [13].\r\n\r\nHowever, the CNN-derived UNet model has trouble capturing global\r\ncontextual variables. This is due to the restrictions of the convolution\r\nprocess it employs [14]. The size of the kernel affects how localized the\r\nfocus is, and a convolution kernel in the UNet model can only focus on\r\na tiny local region. The lower and middle layers still struggle to capture\r\nglobal features and are restricted to localized locations, despite the\r\nUNet model\u2019s ability to extend the reach of the convolution kernel by\r\nadding more convolution layers, enabling higher layers to concentrate\r\non global features. The Transformer model works effectively when\r\n\r\ntaking into account information from a broad context. The Transformer\r\nis being used as an encoder in research on medical picture segmentation\r\nas a consequence.\r\n\r\nIn comparison to CNNs, Transformers have a distinctive capability\r\nto efficiently gather comprehensive contextual information at a global\r\nlevel, while also accurately identifying detailed local features. The\r\nincreasing significance of Transformers in the domain of NLP has\r\nmotivated scholars to investigate their potential utilization in the field\r\nof computer vision. The Vision Transformer (ViT) is an architectural\r\nbreakthrough in the field, as evidenced by the work of [15], as it\r\nonly utilizes self-attention processes. The Vision Transformer (ViT) has\r\ndemonstrated exceptional performance in image identification tasks,\r\nsurpassing current state-of-the-art approaches. Subsequently, Trans-\r\nformers have consistently demonstrated their exceptional skills in a\r\nrange of computer vision applications.\r\n\r\nIn order to leverage the benefits of global context modeling and\r\nin-depth knowledge acquisition, scholars have embarked on the inte-\r\ngration of U-Net and Transformer models. The integration described\r\nin this context improves the functionality of the encoder by combining\r\nthe local characteristics obtained from the CNN module with the global\r\ndependencies obtained from the Transformer module. The efficacy of\r\nthis methodology has attracted considerable interest, as evidenced by\r\nmany extensive investigations, as cited in [14].\r\n\r\nVision transformers have rapidly gained popularity as they enable\r\nto model the context of images by establishing long-term relationships.\r\nNevertheless, the transformers do not apply convolution and only\r\nuse the global attention mechanisms since they are computationally\r\nexpensive which is not suitable for medical image processing tasks.\r\nTransformers have issues in acquiring fine details of medical images,\r\nwhich most of the approaches of today seem to ignore. Considering a\r\nto-state discriminant data mining, optimization allows getting the most\r\nof the information.", "mimetype": "text/plain", "start_char_idx": 6978, "end_char_idx": 11624, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f0127283-2c54-4b9d-8462-35224105c0b4": {"__data__": {"id_": "f0127283-2c54-4b9d-8462-35224105c0b4", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "722b2acf-3ecd-44e5-aa5c-c90727c597d2", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "bc6893f1e8ca9ef0c221531a86c33bbf7ae8190ae7c3e0c89f03c30721199b0e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "adae4129-8643-4794-bbe6-da452a809df6", "node_type": "1", "metadata": {}, "hash": "53f68b9596885b6fe6c2960e8787c441895d112201db9c33999d9b0efb985591", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In order to leverage the benefits of global context modeling and\r\nin-depth knowledge acquisition, scholars have embarked on the inte-\r\ngration of U-Net and Transformer models. The integration described\r\nin this context improves the functionality of the encoder by combining\r\nthe local characteristics obtained from the CNN module with the global\r\ndependencies obtained from the Transformer module. The efficacy of\r\nthis methodology has attracted considerable interest, as evidenced by\r\nmany extensive investigations, as cited in [14].\r\n\r\nVision transformers have rapidly gained popularity as they enable\r\nto model the context of images by establishing long-term relationships.\r\nNevertheless, the transformers do not apply convolution and only\r\nuse the global attention mechanisms since they are computationally\r\nexpensive which is not suitable for medical image processing tasks.\r\nTransformers have issues in acquiring fine details of medical images,\r\nwhich most of the approaches of today seem to ignore. Considering a\r\nto-state discriminant data mining, optimization allows getting the most\r\nof the information. To solve this, some experiments have combined\r\nattributes of convolutional neural networks (CNN) and transformers\r\nto capture both spatial and global features while using fewer param-\r\neters when being applied to medical image processing. It is the latest\r\ndiscovery that the consideration of the frame of the whole medical\r\nimage is more clarified when applying the Transformer in models\r\nlike TransUnet [14] and TransAttUnet [16]. This assists in detecting\r\nlesions that express their form and have more relevant and specific\r\ncharacteristics, thus leading to more precise and extensive findings.\r\n\r\nGenerally, there are many approaches to thyroid ultrasound image\r\nsegmentation, but there is no one-size-fits-all model. As a result, it is\r\ncrucial to apply the best method for the unique situation and condition.\r\nThere are many ways the application can be employed depending on\r\nsample size, time cost, accuracy, autonomy and model size.\r\n\r\nThis study is motivated by two points. Firstly, it is very hard\r\nto tackle the blurred boundaries of ultrasound images. Secondly, the\r\nclassical UNet architecture has the deficiency of small object sensibility.\r\nIn order to find small targets more precisely, multi-scale representation\r\nand contextual information are the main aspects of this paper. Our main\r\ngoal is to extract data from pictures to improve model\u2019s localization\r\nand, at the end, to achieve better lesion segmentations.\r\n\r\nIn this paper, we present Enhanced-TransUNet, a novel segmenta-\r\ntion model created especially for the detection of thyroid nodules. Four\r\nmajor contributions are made in this paper:\r\n\r\n(i) To properly separate thyroid nodules in ultrasound pictures,\r\nwe provide a novel segmentation model called Enhanced-Tran-\r\nsUNet.\r\n\r\n(ii) Integrate vision transformers with UNet structure to increase its\r\n\r\nefficiency on segmentation problems.\r\n\r\n(iii) When compared to current state-of-the-art techniques for seg-\r\nmenting thyroid nodules, Enhanced-TransUNet shows promising\r\nsegmentation accuracy and works well on image segmentation.\r\n(iv) We present a thorough assessment of the proposed model TN3K\r\ndata set, demonstrating its efficacy through both qualitative\r\nanalysis and numerical measures.\r\n\r\nBiomedicalSignalProcessingandControl95(2024)1064722\fA. Ozcan et al.\r\n\r\nThe subsequent parts of this paper are organized in the following\r\nstructural arrangement: In Section 2, a comprehensive review of the\r\nrelevant literature is presented. Sections 3 and 4 provide an in-depth\r\nanalysis of the process, including a thorough and detailed explana-\r\ntion. Sections 5 and 6 are devoted to a comprehensive analysis of\r\nthe experimental findings, whilst Section 7 enlightens the practical\r\nimplications and future scope of the study. Finally Section 8 constitutes\r\nthe concluding section of this work.\r\n\r\n2. Related work\r\n\r\nThe literature review highlights various studies for segmentation\r\ntechniques, concentrating specifically on the medical field, and net-\r\nworks like U-Net and SegNet are frequently used for this purpose.\r\nThe importance of segmentation in health image analysis has been\r\nacknowledged widely in the research area, especially for detecting\r\nthyroid nodules. Accurate, manual measurements by specialists are\r\ntime-consuming. This has driven research into autonomous segmenta-\r\ntion systems for health images. Notable among these is the Transformer\r\nU-Net proposed by Yan et al. [17], which merges convolutional lay-\r\ners (feature), and transformers\u2019 long-sequence modeling equipment.", "mimetype": "text/plain", "start_char_idx": 10511, "end_char_idx": 15153, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "adae4129-8643-4794-bbe6-da452a809df6": {"__data__": {"id_": "adae4129-8643-4794-bbe6-da452a809df6", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f0127283-2c54-4b9d-8462-35224105c0b4", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "d3cb9c60b0c8605f488b3a8c50589b3a456f15a79573b0039a43833e4c46a8fa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "15bd2350-b0d8-4938-a1d1-0c8c1f870da6", "node_type": "1", "metadata": {}, "hash": "f5b6b10c2d234b3d20a093644a01b169fa3129c9af612aa2c3953527fa8c1ac7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Sections 5 and 6 are devoted to a comprehensive analysis of\r\nthe experimental findings, whilst Section 7 enlightens the practical\r\nimplications and future scope of the study. Finally Section 8 constitutes\r\nthe concluding section of this work.\r\n\r\n2. Related work\r\n\r\nThe literature review highlights various studies for segmentation\r\ntechniques, concentrating specifically on the medical field, and net-\r\nworks like U-Net and SegNet are frequently used for this purpose.\r\nThe importance of segmentation in health image analysis has been\r\nacknowledged widely in the research area, especially for detecting\r\nthyroid nodules. Accurate, manual measurements by specialists are\r\ntime-consuming. This has driven research into autonomous segmenta-\r\ntion systems for health images. Notable among these is the Transformer\r\nU-Net proposed by Yan et al. [17], which merges convolutional lay-\r\ners (feature), and transformers\u2019 long-sequence modeling equipment. It\r\npromises parametric compactness and conservation of GPU memory.\r\nMaji et al. [18] suggested an early generator design with custom\r\nloss functions. They also implemented attention gates to the decoders\r\nto privilege learning features and design better mapping. Further-\r\nmore, Wang et al. [19] investigated the use of Vision Transformer\r\n(ViT) in semantic segmentation for medical images. The methodology\r\nemployed by the researchers includes the application of sophisticated\r\nSemi-Supervised Learning (SSL) methodologies, including MixUp-based\r\ninterpolation consistency training and the incorporation of adversarial\r\ntraining. Furthermore, Sagar [20] proposed a Vision Transformer for\r\nbiomedical image segmentation. The encoder and decoder components\r\nof the network use convolutions of varying sizes (1 \u00d7 1, 3 \u00d7 3, and\r\n5 \u00d7 5) to split the input feature maps in which features are merged\r\nusing the concatenation operator and then fed into three transformer\r\nblocks with attention mechanisms. Skip connections are used to connect\r\nthe transformer blocks in the encoder and decoder sections.\r\n\r\nAzad et al. [21] have introduced a Trans-Norm framework that\r\nis based on the standard UNET models encoder and skip connec-\r\ntions. To fuse features from the expanding and contracting routes,\r\nstrong skip connections are used for segmentation. Liu et al. [22] pre-\r\nsented a TransUNet+ framework for medical image segmentation that\r\nuses a modified skip connection including an enhancement module,\r\nwhich boosts the skip features by employing the transformer block\u2019s\r\nscore matrix. This modification leads to improved global attention.\r\nIB-TransUNet Li et al. [23] integrates Transformer and information\r\nbottlenecks into the UNet paradigm. This framework can extract crucial\r\ncontextual data from a wider region resulting in better accuracy.\r\n\r\nFurther, Vadhiraj et al. [24] conducted research to identify benign\r\nor malignant thyroid nodules. It uses a median filter and image bi-\r\nnarization to preprocess and segment the images, and the grey-level\r\nco-occurrence matrix (GLCM) is utilized to extract specific features\r\nfrom the ultrasound images which results in better accuracy. Nguyen\r\net al. [25] used enhancement segmentation networks to improve the\r\naccuracy. Tao et al. [26] utilized a context-attention module based\r\non transformers to tackle the problem of low-clarity images around\r\nthe edges. The proposed method can gather more comprehensive as-\r\nsociative information for the network, helping to capture the edge\r\ndetails of the nodule contour. Moreover, Gong et al. [27] proposed\r\nThyroid Region Prior Guided Feature Enhancement Network (TRFE+)\r\nto correctly segment thyroid nodules where the network has insufficient\r\nprior knowledge about the particular location of the thyroid gland. This\r\nmethod utilizes a normalization method that considers the channel size\r\nas well as an adaptive module to improve attributes connected to the\r\ngland area.\r\n\r\nConvolutional operations are pivotal in computer vision problems\r\nthat offer contextual understanding and resilience in changing postures.\r\nUNet has emerged as a promising segmentation method that employs\r\nskip connections to capture long-range relationships to preserve the\r\ninformation which is a prominent problem in CNN models [14]. The\r\nproblem arises in the convolutional process which fundamentally pri-\r\noritizes localized regions limiting its ability to capture global features\r\neffectively.", "mimetype": "text/plain", "start_char_idx": 14208, "end_char_idx": 18622, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "15bd2350-b0d8-4938-a1d1-0c8c1f870da6": {"__data__": {"id_": "15bd2350-b0d8-4938-a1d1-0c8c1f870da6", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "adae4129-8643-4794-bbe6-da452a809df6", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "8bf7857f36cffcba0500d3215a9d485cabaf9f79ad889f17fd20752d784c86e5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "678f81fc-05b3-4b72-8520-e7220d9072a7", "node_type": "1", "metadata": {}, "hash": "979117e5c350ebd4d6ae53d8f4575964f7905611bd77e05dd2f806d77fc469d8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The proposed method can gather more comprehensive as-\r\nsociative information for the network, helping to capture the edge\r\ndetails of the nodule contour. Moreover, Gong et al. [27] proposed\r\nThyroid Region Prior Guided Feature Enhancement Network (TRFE+)\r\nto correctly segment thyroid nodules where the network has insufficient\r\nprior knowledge about the particular location of the thyroid gland. This\r\nmethod utilizes a normalization method that considers the channel size\r\nas well as an adaptive module to improve attributes connected to the\r\ngland area.\r\n\r\nConvolutional operations are pivotal in computer vision problems\r\nthat offer contextual understanding and resilience in changing postures.\r\nUNet has emerged as a promising segmentation method that employs\r\nskip connections to capture long-range relationships to preserve the\r\ninformation which is a prominent problem in CNN models [14]. The\r\nproblem arises in the convolutional process which fundamentally pri-\r\noritizes localized regions limiting its ability to capture global features\r\neffectively. Despite the considerable achievements of the U-Net archi-\r\ntecture, there exists an opportunity for enhancing the performance\r\nof segmentation. The lack of enough attention given to the semantic\r\ngap between the encoding and decoding stages is responsible for this\r\nphenomenon. The presence of a semantic gap poses a challenge to\r\nthe seamless integration of features, which is crucial for successful\r\nobject identification. Deep-level characteristics are essential for this\r\nintegration, whereas low-level traits are particularly important for edge\r\nsegmentation. Identifying these efficacious characteristics, despite the\r\ninherent difficulties, results in notable progress, as expounded upon\r\nby [28].\r\n\r\nTransformers were first utilized to create text-based models, and as\r\na result of their success, they are also employed for image processing\r\ntasks [14]. The input to Transformer models (comprising different\r\nblocks) is often a series of vectors that are embeddings of input tokens.\r\nEach block consists of two primary parts: (1) a multi-head self-attention\r\nlayer that uses dot-product attention to acquire data from various\r\ntokens in the sequence. This aids the model\u2019s comprehension of the\r\nconnections and interdependence among the various input components.\r\n(2) an MLP, or token-wise feed-forward layer, which treats each token\r\nseparately and performs modifications. To provide reliable and efficient\r\nprocessing of the input sequence, this layer combines layer normaliza-\r\ntion and residual connections. The basic architecture of the Transformer\r\nis a feed-forward module that converts features into a latent space and\r\na self-attention module that records long-range relationships. The input\r\ndata in the Transformer technique consists of tokenized segments of the\r\npicture, which are derived from feature maps of a convolutional neural\r\nnetwork. This strategy is elaborated by [29]. The decoder assumes a\r\ncritical function in enhancing the resolution of the encoded characteris-\r\ntics and integrating them with the high-resolution CNN feature maps to\r\nget accurate localization. In contrast, Transformers employ a methodol-\r\nogy wherein they examine data as 1D sequences and give precedence to\r\nthe aggregation of global context across all phases. The prioritization\r\nof global context results in the production of low-resolution features\r\nthat exhibit a deficiency in exact localization details. Unfortunately, the\r\nact of only augmenting the resolution by upsampling does not possess\r\nthe capability to restore the missing data, hence leading to fragmented\r\noutputs that exhibit a deficiency in intricate particulars. As argued\r\nby [14], the exclusive reliance on the Transformer mechanism leads\r\nto unsatisfactory outcomes.\r\n\r\nTransformers need a large amount of data to pre-train, which might\r\nbe problematic for datasets with less data. Vision Transformers (ViTs)\r\ncan now perform effectively on limited datasets [28] as [30] introduced\r\nan effective training technique and knowledge distillation. Transform-\r\ners served as the basis for ViTs, however, the picture pre-processing\r\nlayer is significantly different. The photos are first divided into a\r\nnumber of separate, non-overlapping sections. Then, each patch is\r\nsubjected to a learned linear projection. A series of tokens are produced\r\nas a consequence, which are supplied to the Transformer. To categorize\r\nthe picture, the Transformer computes global information between each\r\ntoken [15]. The number of filters used in the procedure, which uses\r\na 2D convolution, defines the hidden size of the sequence fed to the\r\nTransformer.", "mimetype": "text/plain", "start_char_idx": 17562, "end_char_idx": 22235, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "678f81fc-05b3-4b72-8520-e7220d9072a7": {"__data__": {"id_": "678f81fc-05b3-4b72-8520-e7220d9072a7", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "15bd2350-b0d8-4938-a1d1-0c8c1f870da6", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "529b67be9afdd859be88be9aa989825ddd4b4c507fc5252b32de7a9e7c977008", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "27a24b71-8d27-45f6-895b-424ab6677414", "node_type": "1", "metadata": {}, "hash": "5aea9cb1e05066b72812e1c9d448f3eaf1aa26bdc9e9d6696f89120324dadddd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Transformers need a large amount of data to pre-train, which might\r\nbe problematic for datasets with less data. Vision Transformers (ViTs)\r\ncan now perform effectively on limited datasets [28] as [30] introduced\r\nan effective training technique and knowledge distillation. Transform-\r\ners served as the basis for ViTs, however, the picture pre-processing\r\nlayer is significantly different. The photos are first divided into a\r\nnumber of separate, non-overlapping sections. Then, each patch is\r\nsubjected to a learned linear projection. A series of tokens are produced\r\nas a consequence, which are supplied to the Transformer. To categorize\r\nthe picture, the Transformer computes global information between each\r\ntoken [15]. The number of filters used in the procedure, which uses\r\na 2D convolution, defines the hidden size of the sequence fed to the\r\nTransformer.\r\n\r\nTrans-UNET is a novel paradigm that combines transformers with\r\nthe U-NET architecture [14]. By utilizing skip connections between\r\nappropriate layers, the U-NET design is renowned for its capacity to\r\nenhance local features in feature maps. TransUNet is the first effective\r\nattempt to segment medical imaging using the Transformer, a potent\r\nneural network design. The Transformer takes the input as a collection\r\n\r\nBiomedicalSignalProcessingandControl95(2024)1064723\fA. Ozcan et al.\r\n\r\nTable 1\r\nAn overview of the medical image segmentation methods.\r\n\r\nStudy\r\n\r\nMethod\r\n\r\nStrengths\r\n\r\nWeaknesses\r\n\r\nProposed model\r\n\r\n[2]\r\n\r\n[31]\r\n\r\n[4]\r\n\r\n[32]\r\n\r\n[5]\r\n\r\n[33]\r\n\r\n[14]\r\n\r\n[34]\r\n\r\n[35]\r\n\r\n[36]\r\n\r\nEnhanced UNet with\r\ntransformers\r\nUNet\r\n\r\nSkip connections Vision transformers Better IoU\r\n\r\nEasy to implement and produces high accuracy\r\n\r\nResidual UNet\r\n\r\nUNet++\r\n\r\nUNet with\r\nTransformers\r\nAttention UNet\r\n\r\nUNet 3+\r\n\r\nTransUNet\r\n\r\nSGUNet\r\n\r\nH-TUNet\r\n\r\nSK-Unet++\r\n\r\nMore easy to train than UNet and also can increase\r\nthe depth of UNet\r\nBetter segmentation accuracy using a nested\r\narchitecture\r\nUses transformer block to model the long-range\r\ncontextual information of input images\r\nAssociates the information of salient maps with\r\nfeature maps\r\nImproves the segmentation performance of Unet and\r\nUnet++ with full-scale skip connections\r\nAddition of transformers retaining higher-resolution\r\nfeature maps capturing distant spatial interactions\r\nutilization of skip connections\r\nUtilization of encoder\u2013decoder network pixel-wise\r\nsemantic map for high-level semantic capturing\r\nImproved accuracy\r\nCombination of 2D and 3D Transformer UNets\r\nIntegration of multi-scale cross-attention transformer\r\n(MSCAT) intra-frame feature extraction and\r\ninter-frame feature aggregation\r\nUsage of the selective kernel (SK) attention\r\nmechanisms Replacement of original UNet++ encoder\r\nblocks with fine-tuned SK convolution blocks Usage of\r\nskip connections\r\n\r\nRequire large amounts of computational resources\r\nLonger training time\r\nOptimal depth of the network architecture is hard to\r\ndefine\r\nOptimal depth of the network architecture is hard to\r\ndefine\r\nLonger training time due to complex network\r\narchitecture\r\nLonger training time due to complex network\r\narchitecture\r\nSalient map is learned with complex method\r\n\r\nLonger training time due to complex network\r\narchitecture\r\nPotential decrease in segmentation accuracy\r\ncomplexity and computational cost\r\n\r\nHigh noise and blurry nodule boundaries Dependence\r\non the quality of image\r\n\r\nLoss of low-level features during feature encoding\r\nWeak representation of contextual features\r\n\r\nEnhanced segmentation accuracy Better performance\r\n\r\nof data and can produce feature maps that are smaller than those in the\r\noriginal picture, which could lower segmentation accuracy. TransUNet\r\nuses a combination of CNN and Transformer\u2019s encoding strengths to\r\nget over this problem. By aiding in the retention of higher-resolution\r\nfeature maps, the CNN enables the decoder to do more precise seg-\r\nmentation through skip connections. The Transformer, on the other\r\nhand, enables the model to focus more on capturing distant spatial\r\ninteractions. The skip connections are essential to TransUNet\u2019s success.\r\nIn order to facilitate efficient information flow throughout various\r\nphases of the model\u2019s design, they mix high-level feature maps from\r\nthe decoder with low-level feature maps from the encoder [16,22].\r\n\r\nTable 1 is a compilation of noteworthy research that centers on\r\ndeveloping approaches in the field of machine learning.", "mimetype": "text/plain", "start_char_idx": 21372, "end_char_idx": 25802, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "27a24b71-8d27-45f6-895b-424ab6677414": {"__data__": {"id_": "27a24b71-8d27-45f6-895b-424ab6677414", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "678f81fc-05b3-4b72-8520-e7220d9072a7", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "9571d620f46d494009839638c2ebef66c11da8fef063a404d57e282772361cf3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "efb6ce26-bd58-4ed5-8b8f-a060af19ed32", "node_type": "1", "metadata": {}, "hash": "9f14cfc45feb9082fcd94bed3251ced025f37f156590b03ca5845918559276a9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "TransUNet\r\nuses a combination of CNN and Transformer\u2019s encoding strengths to\r\nget over this problem. By aiding in the retention of higher-resolution\r\nfeature maps, the CNN enables the decoder to do more precise seg-\r\nmentation through skip connections. The Transformer, on the other\r\nhand, enables the model to focus more on capturing distant spatial\r\ninteractions. The skip connections are essential to TransUNet\u2019s success.\r\nIn order to facilitate efficient information flow throughout various\r\nphases of the model\u2019s design, they mix high-level feature maps from\r\nthe decoder with low-level feature maps from the encoder [16,22].\r\n\r\nTable 1 is a compilation of noteworthy research that centers on\r\ndeveloping approaches in the field of machine learning. Despite the\r\nnotable success of UNet-based network designs in diverse medical pic-\r\nture segmentation tasks, there persists a constraint in attaining optimal\r\nsegmentation performance. Furthermore, it is of utmost importance in\r\nthe field of medical image processing to ensure the constant provi-\r\nsion of high-performance outcomes. This work presents the Enhanced-\r\nTransUNet as a proposed approach to tackle the issues associated with\r\nmedical picture segmentation.\r\n\r\n3. Methodology\r\n\r\nIn this section, we introduce our proposed effective model called\r\nEnhanced-TransUNet for thyroid nodule image segmentation. Enhan-\r\nced-TransUNet architecture is a hybrid approach which was developed\r\nto perform the segmentation task of the thyroid nodules with the U-Net\r\nnetwork by utilizing the power of transformers. The main motivation of\r\nthe method is based on coding the global context of the image patches,\r\nas well as using low-level CNN features through UNet architecture.\r\n\r\n3.1. Transformers and image segmentation\r\n\r\nIn conventional CNN techniques, the algorithm first encodes the\r\npictures into high-level features and then decodes them to restore\r\nthe original spatial resolution. These processes show that CNN mod-\r\nels are architectures that have complex structures and require high\r\nperformance as major drawbacks. Transformers are used to incorpo-\r\nrate self-attention processes into the encoding stage, which helps to\r\n\r\novercome the drawbacks of this approach. Segmentation in computer\r\nvision is the division of an image into several segments or regions, each\r\nof which represents a distinct item or area of the scene. Additionally,\r\ntransformer-based models have been modified for use in image segmentation\r\ntasks.\r\n\r\nTransformers offer a promising infrastructure for image segmenta-\r\ntion with their powerful classification capabilities. There are four dif-\r\nferent basic components in the Transformer-based image segmentation\r\ntask.\r\n\r\n\u2022 Patch Embeddings: Instead of processing the entire image at\r\nonce, the image is divided into smaller patches, each of which\r\nis treated as a token. These patches are then embedded and\r\nprocessed by the transformer model.\r\n\r\n\u2022 Positional Encoding: The positional encoding is added to the\r\ninformation about each\r\n\r\npatch embeddings to provide spatial\r\npatch\u2019s location in the image.\r\n\r\n\u2022 Self-Attention Mechanism: The transformer model employs a\r\nself-attention mechanism to capture global dependencies between\r\ndifferent patches in the image.\r\n\r\n\u2022 Decoder for Segmentation: A decoder can be added to the\r\ntransformer architecture to produce segmentation masks for each\r\npatch, indicating the object or scene segment that the patch\r\nbelongs to.\r\n\r\nAn attention function generates an output based on a query and\r\nkey\u2013value pairs. This procedure represents the query, keys, values,\r\nand output as vectors. The Attention mechanism uses the following\r\nequation to calculate matrices.\r\n\r\n\ud835\udc34\ud835\udc61\ud835\udc61\ud835\udc52\ud835\udc5b\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b(\ud835\udc44, \ud835\udc3e, \ud835\udc49 ) = \ud835\udc60\ud835\udc5c\ud835\udc53 \ud835\udc61\ud835\udc5a\ud835\udc4e\ud835\udc65(\r\n\r\n\ud835\udc44\ud835\udc3e \ud835\udc47\r\n\u221a\ud835\udc51\ud835\udc58\r\n\r\n)\ud835\udc49\r\n\r\n(1)\r\n\r\nIn this equation, Q represents a set of queries, while K and V\r\n\u221a\ud835\udc51\ud835\udc58)\r\ncorrespond to the key and value parameters, respectively. The 1\u2215(\r\nis scaling factor. For each of these transformed versions of queries,\r\nkeys, and values, the attention function is applied simultaneously,\r\ngenerating output values of dimensionality \ud835\udc51\ud835\udc63. These outputs are then\r\ncombined and projected once more, ultimately producing the final set\r\nof values.", "mimetype": "text/plain", "start_char_idx": 25048, "end_char_idx": 29228, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "efb6ce26-bd58-4ed5-8b8f-a060af19ed32": {"__data__": {"id_": "efb6ce26-bd58-4ed5-8b8f-a060af19ed32", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "27a24b71-8d27-45f6-895b-424ab6677414", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "844cb489449129c05ff969411b3b1f65dbdc388d0d21d891d6a10ccf69de483e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0550f2aa-307a-4030-919f-ee71eca47ea6", "node_type": "1", "metadata": {}, "hash": "b2a55d475bf9b0b2eab5abb0f19a418901bfe8d3d87782bf071fc12d4c71c5f4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\ud835\udc34\ud835\udc61\ud835\udc61\ud835\udc52\ud835\udc5b\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b(\ud835\udc44, \ud835\udc3e, \ud835\udc49 ) = \ud835\udc60\ud835\udc5c\ud835\udc53 \ud835\udc61\ud835\udc5a\ud835\udc4e\ud835\udc65(\r\n\r\n\ud835\udc44\ud835\udc3e \ud835\udc47\r\n\u221a\ud835\udc51\ud835\udc58\r\n\r\n)\ud835\udc49\r\n\r\n(1)\r\n\r\nIn this equation, Q represents a set of queries, while K and V\r\n\u221a\ud835\udc51\ud835\udc58)\r\ncorrespond to the key and value parameters, respectively. The 1\u2215(\r\nis scaling factor. For each of these transformed versions of queries,\r\nkeys, and values, the attention function is applied simultaneously,\r\ngenerating output values of dimensionality \ud835\udc51\ud835\udc63. These outputs are then\r\ncombined and projected once more, ultimately producing the final set\r\nof values. Multi-head attention (MHA) enables the model to collectively\r\n\r\nBiomedicalSignalProcessingandControl95(2024)1064724\fA. Ozcan et al.\r\n\r\nTable 2\r\nVariable notation and definition table.\r\n\r\nVariable name\r\n\r\nNotation\r\n\r\nDefinition\r\n\r\nPicture\r\nSize\r\nChannel\r\nPatch\r\nDimension\r\nWeights\r\nFeatures\r\n\r\n\ud835\udc65\r\n\ud835\udc3b \u00d7 \ud835\udc4a\r\n\ud835\udc36\r\n\ud835\udc43\r\n\ud835\udc37\r\n\ud835\udc4a\ud835\udc5d\ud835\udc4e\ud835\udc61\ud835\udc50\u210e\r\n\ud835\udc39\ud835\udc56\ud835\udc5b, \ud835\udc39\ud835\udc5c\ud835\udc62\ud835\udc61\r\n\r\nA picture with C channel\r\nHeight and Weight\r\nTotal number of channels\r\nResolution of patches\r\nLatent vector size\r\nWeight matrix for patches\r\nInput and Output features\r\n\r\nfocus on details from various representation dimensions across different\r\npositions where \u210e\ud835\udc52\ud835\udc4e\ud835\udc51\ud835\udc56 = \ud835\udc34\ud835\udc61\ud835\udc61\ud835\udc52\ud835\udc5b\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b(\ud835\udc44\ud835\udc4a \ud835\udc44\r\n\ud835\udc56\r\n\r\n, \ud835\udc3e\ud835\udc4a \ud835\udc3e\r\n\ud835\udc56\r\n\r\n, \ud835\udc49 \ud835\udc4a \ud835\udc49\r\n\r\n\ud835\udc56 ).\r\n\r\n\ud835\udc40\ud835\udc3b\ud835\udc34(\ud835\udc44, \ud835\udc3e, \ud835\udc49 ) = \ud835\udc36\ud835\udc5c\ud835\udc5b\ud835\udc50\ud835\udc4e\ud835\udc61(\u210e\ud835\udc52\ud835\udc4e\ud835\udc511, \u210e\ud835\udc52\ud835\udc4e\ud835\udc512, \u2026 , \u210e\ud835\udc52\ud835\udc4e\ud835\udc51\u210e)\ud835\udc4a \ud835\udc42\r\nand \ud835\udc49 \ud835\udc4a \ud835\udc49\r\n\r\nThe \ud835\udc44\ud835\udc4a \ud835\udc44\r\n\ud835\udc56\r\n\r\n, \ud835\udc3e\ud835\udc4a \ud835\udc3e\r\n\ud835\udc56\r\n\r\n\ud835\udc56 values in the equation are the param-\r\n\r\n(2)\r\n\r\neter matrices corresponding to the projections.\r\n\r\n3.2. Proposed enhanced TransUNet model\r\n\r\nThis section presents the details of the proposed hybrid TransUNet\r\nmethod. The Table 2 below gives the variables, notations and defini-\r\ntions used within the scope of the proposed method.\r\n\r\nLet \ud835\udc65 \u2208 \ud835\udc45\ud835\udc3b\ud835\udc4a \ud835\udc36 represent a picture with \ud835\udc3b \u00d7 \ud835\udc4a and \ud835\udc36 channels\r\nproviding the spatial resolution. The goal of picture segmentation is to\r\nforecast a pixel-wise label map with dimensions \ud835\udc3b \u00d7 \ud835\udc4a .\r\n\r\nThe standard Transformer model commonly functions on a one-\r\ndimensional sequence of token embeddings. However, in the context\r\nof 2D pictures, it becomes imperative to employ a transformation.", "mimetype": "text/plain", "start_char_idx": 28739, "end_char_idx": 30699, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0550f2aa-307a-4030-919f-ee71eca47ea6": {"__data__": {"id_": "0550f2aa-307a-4030-919f-ee71eca47ea6", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "efb6ce26-bd58-4ed5-8b8f-a060af19ed32", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "2a0497357531c8f21167de565d57c838522fde4343e8799dd39c52cdf079e79b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3870e041-1120-4781-a9d7-ee9415b27279", "node_type": "1", "metadata": {}, "hash": "3a483fd41a0313f5c2b4b209b0c083dfa26946a6c8a4971151f8efa9c1821e13", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "3.2. Proposed enhanced TransUNet model\r\n\r\nThis section presents the details of the proposed hybrid TransUNet\r\nmethod. The Table 2 below gives the variables, notations and defini-\r\ntions used within the scope of the proposed method.\r\n\r\nLet \ud835\udc65 \u2208 \ud835\udc45\ud835\udc3b\ud835\udc4a \ud835\udc36 represent a picture with \ud835\udc3b \u00d7 \ud835\udc4a and \ud835\udc36 channels\r\nproviding the spatial resolution. The goal of picture segmentation is to\r\nforecast a pixel-wise label map with dimensions \ud835\udc3b \u00d7 \ud835\udc4a .\r\n\r\nThe standard Transformer model commonly functions on a one-\r\ndimensional sequence of token embeddings. However, in the context\r\nof 2D pictures, it becomes imperative to employ a transformation. To\r\nadapt the model, the images are reshaped from \ud835\udc65 \u2208 \ud835\udc45\ud835\udc3b\ud835\udc4a \ud835\udc36 into a\r\n\ud835\udc5d \u2208 \ud835\udc45\ud835\udc43 2.\ud835\udc36 , \ud835\udc56 = 1, \u2026 , \ud835\udc5b. Here, \ud835\udc36 repre-\r\nseries of flattened 2D patches \ud835\udc65\ud835\udc56\r\nsents the total number of channels, \ud835\udc43 signifies the resolution of each\r\nindividual image patch (\ud835\udc43 , \ud835\udc43 ) and \ud835\udc4a corresponds to the resolution of\r\nthe original image (\ud835\udc3b, \ud835\udc4a ), the total number of patches are given by\r\n\ud835\udc5b = \ud835\udc3b\ud835\udc4a \u2215\ud835\udc43 2 which also serves as an effective input sequence length\r\nfor the Transformers.\r\n\r\nThe patches undergo a process of flattening and are subsequently\r\nturned into a D-dimensional space by the utilization of a trainable linear\r\nprojection, as described in (3). The process of converting input data into\r\npatch embeddings, which guarantees a consistent latent vector size (D)\r\nthroughout the layers of the Transformer model, is commonly known\r\nas patch embedding.\r\n\r\n\ud835\udc670 = [\ud835\udc651\r\n\r\n\ud835\udc5d\ud835\udc38; \ud835\udc652\r\n\r\n\ud835\udc5d\ud835\udc38; ...; \ud835\udc65\ud835\udc5b\r\n\r\n\ud835\udc5d] + \ud835\udc38\ud835\udc5d\ud835\udc5c\ud835\udc60\r\n\r\n(3)\r\n\r\nA transformer block consists Multihead Self Attention (MSA) and\r\nMulti-Layer Perceptron (MLP) blocks which are shown by Eqs. (4) and\r\n(5). Consequently, the output of the \ud835\udc59th layer is written as follows:\r\n\r\n\ud835\udc67\u2032\r\n\ud835\udc59 = \ud835\udc40\ud835\udc46\ud835\udc34(\ud835\udc3f\ud835\udc41(\ud835\udc67\ud835\udc59\u22121)) + \ud835\udc67\ud835\udc59\u22121\r\n\r\n\ud835\udc67\ud835\udc59 = \ud835\udc40\ud835\udc3f\ud835\udc43 (\ud835\udc3f\ud835\udc41(\ud835\udc67\ud835\udc59)) + \ud835\udc67\ud835\udc59\r\n\r\n(4)\r\n\r\n(5)\r\n\r\nThe encoded picture representation is indicated by \ud835\udc67\ud835\udc59 and the layer\r\n\r\nnormalization operator is denoted by \ud835\udc3f\ud835\udc41(\u2219).\r\n\r\nA straightforward approach is to upscale the encoded feature repre-\r\nsentation \ud835\udc67\ud835\udc3f \u2208 R\ud835\udc3b\ud835\udc4a \u2215\ud835\udc43 2\u00d7\ud835\udc37 to the original resolution for generating the\r\ndense output. To maintain spatial integrity, the size of the encoded\r\nfeature needs to be initially reshaped from \ud835\udc3b\ud835\udc4a \u2215\ud835\udc43 2 to \ud835\udc3b\u2215\ud835\udc43 \u00d7 \ud835\udc4a \u2215\ud835\udc43 .\r\nA 1 \u00d7 1 convolution has been employed to decrease the channel size\r\nof the reshaped feature to several classes. Subsequently, the feature\r\nmap is directly bilinearly upsampled to the original resolution \ud835\udc3b \u00d7 \ud835\udc4a\r\nto predict the final segmentation result. Using a Transformer with\r\nbasic upsampling already achieves decent performance. However, this\r\nmethod does not fully leverage the potential of Transformers for seg-\r\nmentation because the downsampled size (\ud835\udc3b\u2215\ud835\udc43 \u00d7 \ud835\udc4a \u2215\ud835\udc43 ) is typically\r\nmuch smaller than the original image resolution (\ud835\udc3b \u00d7 \ud835\udc4a ), leading\r\n\r\nFig. 1. Proposed enhanced-TransUNet encoder module.\r\n\r\nto a loss of fine-grained details.", "mimetype": "text/plain", "start_char_idx": 30077, "end_char_idx": 32912, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3870e041-1120-4781-a9d7-ee9415b27279": {"__data__": {"id_": "3870e041-1120-4781-a9d7-ee9415b27279", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0550f2aa-307a-4030-919f-ee71eca47ea6", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "290a1e479ccf3e784f8a5714440f18c39eebd795fe172f4171dc27523c721684", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2fb3cce2-0f85-4f27-8479-d5295ab6d602", "node_type": "1", "metadata": {}, "hash": "b67e02cc045886984e6cd45bb577e887b913a011f6ced9d2dd89361ea3869ffa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A 1 \u00d7 1 convolution has been employed to decrease the channel size\r\nof the reshaped feature to several classes. Subsequently, the feature\r\nmap is directly bilinearly upsampled to the original resolution \ud835\udc3b \u00d7 \ud835\udc4a\r\nto predict the final segmentation result. Using a Transformer with\r\nbasic upsampling already achieves decent performance. However, this\r\nmethod does not fully leverage the potential of Transformers for seg-\r\nmentation because the downsampled size (\ud835\udc3b\u2215\ud835\udc43 \u00d7 \ud835\udc4a \u2215\ud835\udc43 ) is typically\r\nmuch smaller than the original image resolution (\ud835\udc3b \u00d7 \ud835\udc4a ), leading\r\n\r\nFig. 1. Proposed enhanced-TransUNet encoder module.\r\n\r\nto a loss of fine-grained details. Hence, to address this loss of infor-\r\nmation, TransUNet adopts a hybrid CNN-Transformer architecture as\r\nthe encoder and integrates a cascaded upsampler to ensure accurate\r\nlocalization.\r\n\r\nBased on the usage of transformers, the image is converted into\r\na series of smoothed image patches of equal size in the transformer\r\nencoder block. The vectorized patches are then put into a step called\r\npatch placement, where they are trained into a D-dimensional layout\r\nspace. The Fig. 1 below shows the construction of the transformer\r\nencoder block.\r\n\r\nTo further enhance the connections, an enhancement module is\r\ndeveloped to strengthen the skip features. An enhancement module\r\nfor improving the understanding of column vector relations has been\r\ncreated based on the column vector analysis. This module aims to\r\ncapture the relationships within the column vectors. The decoder fea-\r\ntures, which come into play after the transformer encoder, establish\r\nconnections over long-ranges. The process can be visualized in Fig. 2.\r\nInitially, the column vector generates patch weights, which are then\r\narranged into a matrix.\r\n\r\nIn the MSA phase of the Transformer architecture, the weight matri-\r\nces produced by the score matrices are aggregated to create a distinct\r\nweight matrix that is particular to each layer of the transformer. There\r\nare a total of \ud835\udc5b weight matrices, with each matrix corresponding to a\r\ntransformer layer. The suggested methodology involves combining the\r\nseparate weight matrices to obtain the final weight matrix. The process\r\nof merging in this context entails the utilization of the score matrix \ud835\udc46\ud835\udc56\r\nfrom the transformer layer, in combination with the weight assigned\r\nto each patch, represented as \ud835\udc4a . The function \ud835\udc53 (\u22c5) represents the\r\nmathematical operation done to the column vectors. The mathematical\r\nexpression guiding the computation of the weight patch is presented\r\nin Eq. (6).\r\n\r\n\ud835\udc4a\ud835\udc5d\ud835\udc4e\ud835\udc61\ud835\udc50\u210e =\r\n\r\n\ud835\udc5b\r\n\u2211\r\n\r\n\ud835\udc56=1\r\n\r\n\ud835\udc53 (\ud835\udc46\ud835\udc56)\r\n\r\n(6)\r\n\r\nThe weight matrix is resized to match the dimensions of the skip fea-\r\ntures. Subsequently, the weight matrix is used to enhance each encoder\r\nfeature, and the resulting skip features are passed on to the decoder,\r\n\ud835\udc39\ud835\udc5c\ud835\udc62\ud835\udc61 = \ud835\udc39\ud835\udc56\ud835\udc5b\u2219\ud835\udc62\ud835\udc5d\ud835\udc60(\ud835\udc4a\ud835\udc5d\ud835\udc4e\ud835\udc61\ud835\udc50\u210e). Before and after going through the enhancement\r\nmodule, the features are referred to as \ud835\udc39\ud835\udc56\ud835\udc5b and \ud835\udc39\ud835\udc5c\ud835\udc62\ud835\udc61, respectively. The\r\nweight matrix is denoted as \ud835\udc4a\ud835\udc5d\ud835\udc4e\ud835\udc61\ud835\udc50\u210e, and the upsampling operation is\r\nrepresented by \ud835\udc62\ud835\udc5d\ud835\udc60(\u22c5).\r\n\r\nThe second section uses CNN-based UNet for upsampling. As a\r\nresult, the transformer and UNet work together to generate a hybrid\r\nencoder. The method\u2019s cascaded upsampler (CUP) extracts the hidden\r\nfeatures for the final segmentation mask.", "mimetype": "text/plain", "start_char_idx": 32269, "end_char_idx": 35568, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2fb3cce2-0f85-4f27-8479-d5295ab6d602": {"__data__": {"id_": "2fb3cce2-0f85-4f27-8479-d5295ab6d602", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3870e041-1120-4781-a9d7-ee9415b27279", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "a2e82b524275778566d7f33eab2f66fcd0184c50ba1973abc4f7e0f70c76bb31", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8c054816-9f6f-4d49-99c6-e20eb5d9f0dc", "node_type": "1", "metadata": {}, "hash": "a337e765f202271e343af28313d66b02604618463d2934c8684baf2bdfcb3f3e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Before and after going through the enhancement\r\nmodule, the features are referred to as \ud835\udc39\ud835\udc56\ud835\udc5b and \ud835\udc39\ud835\udc5c\ud835\udc62\ud835\udc61, respectively. The\r\nweight matrix is denoted as \ud835\udc4a\ud835\udc5d\ud835\udc4e\ud835\udc61\ud835\udc50\u210e, and the upsampling operation is\r\nrepresented by \ud835\udc62\ud835\udc5d\ud835\udc60(\u22c5).\r\n\r\nThe second section uses CNN-based UNet for upsampling. As a\r\nresult, the transformer and UNet work together to generate a hybrid\r\nencoder. The method\u2019s cascaded upsampler (CUP) extracts the hidden\r\nfeatures for the final segmentation mask. After tweaking the hidden\r\nfeature \ud835\udc67\ud835\udc3f \u2208 \ud835\udc45((\ud835\udc3b\ud835\udc4a )\u2215\ud835\udc43 2)\ud835\udc37 \u00d7 \u00d7 to fit the form of (\ud835\udc3b\u2215\ud835\udc43 ) \u00d7 (\ud835\udc4a \u2215\ud835\udc43 ) \u00d7 \ud835\udc37,\r\nwe generate CUP by combining numerous upsampling blocks to obtain\r\nfull resolution from (\ud835\udc3b\u2215\ud835\udc43 ) \u00d7 (\ud835\udc4a \u2215\ud835\udc43 ) to \ud835\udc3b \u00d7 \ud835\udc4a . Each block includes a\r\n2\u00d7 upsampling operation, a 3 \u00d7 3 convolutional layer, and ultimately\r\na ReLU layer.The decoder module utilizes a cascaded upsampler to\r\nperform multi-level upsampling and decoding operations to generate\r\nthe segmentation output. The decoder block, as illustrated in Fig. 3,\r\n\r\nBiomedicalSignalProcessingandControl95(2024)1064725\fA. Ozcan et al.\r\n\r\nFig. 2. Proposed enhanced-transUNet approach for thyroid nodule segmentation.\r\n\r\nTable 3\r\nProperties of transformer module used in Vit-L16.\r\n\r\nModel\r\n\r\nLayers\r\n\r\nHidden size\r\n\r\nMLP Size\r\n\r\nHeads\r\n\r\nParams\r\n\r\nVit-Large/16\r\n\r\n24\r\n\r\n1024\r\n\r\n4096\r\n\r\n16\r\n\r\n307M\r\n\r\nwith matching dimensions are specifically enhanced by skip connec-\r\ntions throughout the first three stages when they are concatenated\r\nacross feature channels to improve the overall representation. In order\r\nto separate foregrounds from backgrounds, the final feature map is\r\nupsampled.\r\n\r\nFig. 3. Proposed enhanced-transUNet decoder module.\r\n\r\n4. Experimental setup\r\n\r\ncomprises a 2\u00d7 upsampling operation, a concatenation operation that\r\ncombines features from the encoder, and a convolution operation. Upon\r\ncompleting a decoder block, the feature\u2019s length and width are doubled,\r\nwhile the number of channels is halved. When all three decoder blocks\r\nare applied consecutively, the feature\u2019s width and length are reduced\r\nto half of the original picture size. Ultimately, the segmentation head\r\ngenerates the final segmentation result by combining a linear layer with\r\nan upsampling layer.\r\n\r\nIn the proposed approach, the thyroid image data is given to the\r\nencoder phase first. At this stage, the CNN encoder transmits the data\r\npatches it subsamples to the transformer encoder via linear projection.\r\nThe transformer encoder extracts the hidden features from the data it\r\nreceives and transmits it to the decoder stage. On the other hand, the\r\nfeatures taken from the subsampling layers of the CNN encoder are im-\r\nproved by processing the weight matrices in the designed enhancement\r\nmodule and transmitting them to the decoder. On the decoder side,\r\nboth the input transformer encoder features and the enhanced CNN\r\nencoder layer features are used as inputs at each stage of upsampling.\r\nIn the segmentation head layer, the final output is produced.\r\n\r\nWe use the Vit-L/16 model, a 16 \u00d7 16 input patch size \u2018\u2018Large\u2019\u2019\r\nvariation of the visual transformer module. Models with smaller patches\r\nrequire more processing power, as the Transformer\u2019s sequence length is\r\ninversely proportional to the square of the patch size. The underlying\r\nCNNs employed ResNet architecture, however normalizing layers were\r\nupdated by adopting Group normalizing as recommended by [37]\r\nand standardized convolutions in place of Batch Normalization layers,\r\nwhich were initially introduced. Kolesnikov et al. [38] found that these\r\nadjustments enhanced the capacity to transfer learning (see Table 3).\r\n\r\nThen, segmentation tokens go via a cascade-based upsampling pro-\r\ncedure after being subjected to n successive Transformer layers.", "mimetype": "text/plain", "start_char_idx": 35113, "end_char_idx": 38838, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8c054816-9f6f-4d49-99c6-e20eb5d9f0dc": {"__data__": {"id_": "8c054816-9f6f-4d49-99c6-e20eb5d9f0dc", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2fb3cce2-0f85-4f27-8479-d5295ab6d602", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "5bbdfdea7c83e0a610701a8276b956fba42bcb39c5862f0c9a13668dfb7f9bd1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9259b7cc-24f2-4a5f-a46f-920ab240b145", "node_type": "1", "metadata": {}, "hash": "5365b635909824c49007d35a596b1d93ccb39322f6eda2daf56bee847e1f75bb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In the segmentation head layer, the final output is produced.\r\n\r\nWe use the Vit-L/16 model, a 16 \u00d7 16 input patch size \u2018\u2018Large\u2019\u2019\r\nvariation of the visual transformer module. Models with smaller patches\r\nrequire more processing power, as the Transformer\u2019s sequence length is\r\ninversely proportional to the square of the patch size. The underlying\r\nCNNs employed ResNet architecture, however normalizing layers were\r\nupdated by adopting Group normalizing as recommended by [37]\r\nand standardized convolutions in place of Batch Normalization layers,\r\nwhich were initially introduced. Kolesnikov et al. [38] found that these\r\nadjustments enhanced the capacity to transfer learning (see Table 3).\r\n\r\nThen, segmentation tokens go via a cascade-based upsampling pro-\r\ncedure after being subjected to n successive Transformer layers. The\r\ntoken sizes are multiplied by four using bilinear interpolation and two\r\nconvolutional neural networks. The ResNet50 encoder\u2019s feature maps\r\n\r\nThe present section commences by presenting a comprehensive\r\nreview of the datasets utilized, explaining the assessment criteria ap-\r\nplied, and then providing an in-depth discussion of the implementation\r\naspects. Following this, a thorough examination is conducted using\r\nadvanced approaches to verify the effectiveness of each component\r\ninside the suggested architectural framework.\r\n\r\n4.1. Dataset\r\n\r\nTo the best of our current understanding, the sole thyroid nodule\r\ndataset that is openly available to the public without any usage limita-\r\ntions is commonly known as DDTI, which was made available by [39].\r\nNevertheless, it is important to acknowledge that DDTI does have\r\nseveral limitations, namely in terms of its relatively small dataset size,\r\nwhich comprises just 637 images together with corresponding pixel-\r\nwise lesion masks. The scale in question exhibits several limitations in\r\nits applicability for the purposes of training and testing deep learning\r\nmodels. In addition, it should be noted that the DDTI method does not\r\nadequately account for the frequently encountered situation of multi-\r\nnodules, which is a commonly observed phenomenon in ultrasonic\r\nthyroid examinations.\r\n\r\nIn order to further the progress of research in the field of computer-\r\naided diagnosis for automated identification of thyroid nodules, a\r\nsignificant dataset of ultrasound thyroid pictures has been integrated.\r\nThis dataset, referred to as TN3K, comprises a huge collection of\r\nreal-world scenarios. The dataset utilized in this study, obtained from\r\nZhujiang Hospital, South Medical University [27], presents significant\r\nchallenges in the task of thyroid nodule segmentation. The dataset\r\nconsists of a comprehensive collection of 3493 ultrasound pictures,\r\nwith each image accompanied by pixel-wise annotations. The TN3K\r\ndataset consists of a total of 3493 pictures, with 2879 photos designated\r\nfor training and the remaining 614 images used for testing.\r\n\r\nBiomedicalSignalProcessingandControl95(2024)1064726\fA. Ozcan et al.\r\n\r\n4.2. Implementation details\r\n\r\nThe execution of the suggested approach is implemented using the\r\nPyTorch framework. The experimental configuration utilized a single\r\nRTX3060 VENTUS 2X OC GPU equipped with 12 GB of RAM. The\r\nAdam optimizer [40] is utilized for the purpose of training the model,\r\nwith a consistent batch size of 16. The learning rate is initialized\r\nat 10\u22125 and follows a linear decrease, eventually reaching zero after\r\n40,000 iterations. It is worth mentioning that the initialization of\r\nour model entails pre-training the ResNet50 and Transformer layers\r\nusing the ImageNet dataset [41]. In the empirical configuration of\r\nhyperparameters, the values of \ud835\udf06\ud835\udc36 , \ud835\udf06\ud835\udc3f, and \ud835\udf06\ud835\udc34 were set to 0.25, 5.0,\r\nand 1.0, respectively. These hyperparameters play a crucial role in\r\ndetermining particular elements of our model\u2019s performance. In order\r\nto achieve the most efficient convergence, the parameter \ud835\udf06\ud835\udc37 follows\r\nan exponential ramp-up technique over a period of 40 iterations. The\r\nparameter k is allocated a value of 1500, and our model architecture\r\nincludes 24 Transformer layers, a move intended to improve feature\r\nextraction. Patch sizes are commonly denoted as 16 \u00d7 16 in academic\r\nliterature.", "mimetype": "text/plain", "start_char_idx": 38013, "end_char_idx": 42237, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9259b7cc-24f2-4a5f-a46f-920ab240b145": {"__data__": {"id_": "9259b7cc-24f2-4a5f-a46f-920ab240b145", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8c054816-9f6f-4d49-99c6-e20eb5d9f0dc", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "8d5ee6bb385e30a0f2890257e31b575e7473df6555ff533b70ef9484fa8dac0e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2b114964-bbb9-46ec-8661-bd77abd649df", "node_type": "1", "metadata": {}, "hash": "b9e7021ec11e0f8b6a3f5eff2f4e8276696f422b2547b6e6382d6cde141cd627", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "It is worth mentioning that the initialization of\r\nour model entails pre-training the ResNet50 and Transformer layers\r\nusing the ImageNet dataset [41]. In the empirical configuration of\r\nhyperparameters, the values of \ud835\udf06\ud835\udc36 , \ud835\udf06\ud835\udc3f, and \ud835\udf06\ud835\udc34 were set to 0.25, 5.0,\r\nand 1.0, respectively. These hyperparameters play a crucial role in\r\ndetermining particular elements of our model\u2019s performance. In order\r\nto achieve the most efficient convergence, the parameter \ud835\udf06\ud835\udc37 follows\r\nan exponential ramp-up technique over a period of 40 iterations. The\r\nparameter k is allocated a value of 1500, and our model architecture\r\nincludes 24 Transformer layers, a move intended to improve feature\r\nextraction. Patch sizes are commonly denoted as 16 \u00d7 16 in academic\r\nliterature. In the training phase, data augmentation techniques are\r\nemployed to enhance the dataset by randomly applying horizontal and\r\nvertical picture flips. All algorithms run for 50 epochs. The Enhanced-\r\nTransUNet model is optimized by employing the Dice loss function,\r\nwhich is supplemented with a thyroid nodule region mask for oversight.\r\nThe careful arrangement and systematic training routine adhere to\r\nwell-established academic conventions within the discipline.\r\n\r\n4.3. Evaluation metrics\r\n\r\nIn our study, we employed a comprehensive set of seven metrics to\r\nevaluate the segmentation performance. These metrics include Inter-\r\nsection Over Union (IoU), dice coefficient (DICE), Specificity, Precision\r\n(PR), Accuracy, F1-score, and Area Under the Receiver Operating Char-\r\nacteristic Curve (AUC). Notably, the DICE coefficient, as presented\r\nin Eq. (7), stands as a widely acknowledged similarity measurement\r\nmethod extensively utilized for object segmentation tasks, as referenced\r\nby [42].\r\n\r\nDICE = 2 \u2217 TP\u2215(FP + FN + 2 \u2217 TP)\r\n\r\n(7)\r\n\r\nAn increased DICE score indicates a higher level of similarity, hence\r\nsuggesting improved success in segmentation. To ensure a comprehen-\r\nsive and rigorous evaluation of the segmentation performance of our\r\nproposed technique, we have carefully selected the following metrics:\r\n\r\n\u2022 IoU (Intersection Over Union) = TP/(FP + FN)\r\n\u2022 Recall = TP/(TP + FN)\r\n\u2022 PR (Precision) = TP/(TP + FP)\r\n\u2022 Accuracy = (TN + TP)/(TN + TP + FN + FP)\r\n\u2022 F1-score = (2 \u2217 PR \u2217 RE)/(PR + RE)\r\n\u2022 The Area Under the (ROC) Curve, denoted as AUC, is calculated\r\nby evaluating the Intersection over Union (IoU) score for the\r\nsegmentation results acquired from all five folds.\r\n\r\n\u2022 The HD95 measure is utilized to evaluate the accuracy of seg-\r\nmentation borders. It involves calculating the greatest distance\r\nbetween the predicted boundaries and the ground truth, and then\r\nselecting the top 95% of these distances.\r\n\r\nThe abbreviations TP, FP, TN, and FN represent the terms true\r\npositive, false positive, true negative, and false negative, respectively.\r\nThe F1-score is defined as the harmonic mean of accuracy and recall.\r\n\r\nTable 4\r\nComparisons of our proposed segmentation model against with the state-of-the-art\r\nmodels on the TN3K testset. The best result is shown in bold.", "mimetype": "text/plain", "start_char_idx": 41483, "end_char_idx": 44538, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2b114964-bbb9-46ec-8661-bd77abd649df": {"__data__": {"id_": "2b114964-bbb9-46ec-8661-bd77abd649df", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9259b7cc-24f2-4a5f-a46f-920ab240b145", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "92494807cf8b2aadd65ced925fbde0932ce03dd8f62a4549c9d58d84a423bb38", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b388a9bc-7500-414b-b43b-094f50d1e0af", "node_type": "1", "metadata": {}, "hash": "8b67c5a1761820491caa2263018801146b79fe8575406d45879780215e40af9e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\u2022 The HD95 measure is utilized to evaluate the accuracy of seg-\r\nmentation borders. It involves calculating the greatest distance\r\nbetween the predicted boundaries and the ground truth, and then\r\nselecting the top 95% of these distances.\r\n\r\nThe abbreviations TP, FP, TN, and FN represent the terms true\r\npositive, false positive, true negative, and false negative, respectively.\r\nThe F1-score is defined as the harmonic mean of accuracy and recall.\r\n\r\nTable 4\r\nComparisons of our proposed segmentation model against with the state-of-the-art\r\nmodels on the TN3K testset. The best result is shown in bold.\r\n\r\nTN3K\r\n\r\nAUC\r\n\r\nF1-score\r\n\r\nIoU\r\n\r\nDice\r\n\r\nHD95\r\n\r\n\ud835\udc5d-value\r\n\r\nEnhanced-TransUNet\r\nUNet\r\nSGUNet\r\nFCN\r\nSegNet\r\nDeeplabv3+\r\nCPFNet\r\nAttention UNet\r\nAttention R2 UNet\r\n\r\n92.06\r\n87.17\r\n89.39\r\n88.98\r\n88.79\r\n89.36\r\n91.78\r\n91.73\r\n91.75\r\n\r\n80.55\r\n75.30\r\n76.57\r\n77.07\r\n76.46\r\n75.35\r\n80.65\r\n79.18\r\n77.68\r\n\r\n70.87\r\n64.67\r\n65.83\r\n66.16\r\n65.87\r\n64.86\r\n70.45\r\n69.38\r\n67.37\r\n\r\n82.92\r\n78.55\r\n79.39\r\n79.99\r\n79.42\r\n78.68\r\n82.67\r\n81.92\r\n80.50\r\n\r\n13.19\r\n18.39\r\n17.96\r\n17.06\r\n16.61\r\n17.45\r\n13.22\r\n15.67\r\n16.20\r\n\r\n< 0.001\r\n< 0.001\r\n< 0.001\r\n< 0.001\r\n< 0.001\r\n< 0.001\r\n< 0.001\r\n< 0.001\r\n< 0.001\r\n\r\nTable 5\r\nComparisons of our proposed segmentation model against with the state-of-the-art\r\nmodels on the DDTI testset. The best result is shown in bold.\r\n\r\nDDTI\r\n\r\nAUC\r\n\r\nF1-score\r\n\r\nIoU\r\n\r\nDice\r\n\r\nHD95\r\n\r\n\ud835\udc5d-value\r\n\r\nEnhanced-TransUNet\r\nUNet\r\nSGUNet\r\nFCN\r\nSegNet\r\nDeeplabv3+\r\nCPFNet\r\nAttention UNet\r\nAttention R2 UNet\r\n\r\n97.79\r\n93.98\r\n93.26\r\n94.02\r\n97.68\r\n96.70\r\n98.11\r\n96.46\r\n93.44\r\n\r\n95.41\r\n90.61\r\n89.47\r\n89.22\r\n93.68\r\n93.05\r\n96.60\r\n95.00\r\n75.40\r\n\r\n91.29\r\n83.20\r\n81.40\r\n81.03\r\n88.27\r\n87.25\r\n93.45\r\n91.20\r\n63.46\r\n\r\n95.45\r\n90.83\r\n89.75\r\n89.52\r\n93.76\r\n93.20\r\n96.61\r\n95.40\r\n77.65\r\n\r\n1.09\r\n5.19\r\n5.77\r\n6.60\r\n2.41\r\n2.75\r\n0.43\r\n1.72\r\n23.42\r\n\r\n< 0.001\r\n< 0.001\r\n< 0.001\r\n< 0.001\r\n< 0.001\r\n< 0.001\r\n< 0.001\r\n< 0.001\r\n< 0.001\r\n\r\n5. Experimental results and comparison with the state-of-the-art\r\nmethods\r\n\r\nThe approach employed in this study is subjected to a thorough\r\nexamination using the TN3K and DDTI test datasets. The outcomes\r\nof this evaluation are reported in Tables 4 and 5. It is important to\r\nacknowledge that all models are implemented in their original settings\r\nas given by the authors. By conducting thorough comparisons with\r\ncutting-edge segmentation approaches, we demonstrate the exceptional\r\nperformance of our Enhanced-TransUNet model.\r\n\r\nTo provide context, FCN and SegNet utilize the VGG architecture,\r\nwhich has been pretrained on the ImageNet dataset [43].", "mimetype": "text/plain", "start_char_idx": 43934, "end_char_idx": 46490, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b388a9bc-7500-414b-b43b-094f50d1e0af": {"__data__": {"id_": "b388a9bc-7500-414b-b43b-094f50d1e0af", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2b114964-bbb9-46ec-8661-bd77abd649df", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "67996efe4f9696a5678391bfcbda97715edd7aef2cbbb21e8e7482f62681eea8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f4669fd1-425f-4bfa-89b8-59b195bea2d7", "node_type": "1", "metadata": {}, "hash": "ea569a5b3f6afff5ba3c614ea1bae07ccc06fe297edd4099fa7e1fa7d049027a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Experimental results and comparison with the state-of-the-art\r\nmethods\r\n\r\nThe approach employed in this study is subjected to a thorough\r\nexamination using the TN3K and DDTI test datasets. The outcomes\r\nof this evaluation are reported in Tables 4 and 5. It is important to\r\nacknowledge that all models are implemented in their original settings\r\nas given by the authors. By conducting thorough comparisons with\r\ncutting-edge segmentation approaches, we demonstrate the exceptional\r\nperformance of our Enhanced-TransUNet model.\r\n\r\nTo provide context, FCN and SegNet utilize the VGG architecture,\r\nwhich has been pretrained on the ImageNet dataset [43]. On the other\r\nhand, Deeplabv3+ and CPFNet are equipped with the ResNet backbone,\r\nwhich has also been pretrained on ImageNet [44]. Furthermore, in\r\norder to enhance the process of comparing performance, we incorporate\r\nthree models: basic UNet, Attention UNet, and Attention R2 UNet, as\r\nmentioned in the work by [45].\r\n\r\nThe statistical significance of the comparisons is assessed by cal-\r\nculating p-values using t-tests. This analysis focuses on the differences\r\nin IoU between the proposed Enhanced-TransUNet model and the\r\nalternative models. A \ud835\udc5d-value below the threshold of 0.05 indicates a\r\nsignificant performance advantage in support of our suggested strategy\r\ncompared to the competing models.\r\n\r\nThe proposed technique demonstrates a significant enhancement\r\ncompared to the fundamental UNet design, as evidenced by a 6.20%\r\nincrease in the Jaccard score on the TN3K test set. Moreover, it may\r\nbe regarded as a prominent leader in comparison to the alternative\r\nalgorithms that have been presented. It is worth mentioning that our\r\napproach has superior performance compared to other advanced meth-\r\nods that utilize robust ImageNet pretrained backbones, owing to the\r\ncareful design of our learning framework. It is noteworthy to notice that\r\nour technique exhibits a little worse performance in terms of accuracy\r\nand F1-score compared to CPFNet, while the difference is negligible.\r\nAlso the performance of the proposed model on TN3K dataset can be\r\nseen at 4 and 5.\r\n\r\nIn Table 5, performance comparison of the algorithms for DDTI data\r\n\r\nset is given.\r\n\r\nAs it can be seen from the table we only used the DDTI dataset,\r\nin which 405 of the images are used for training purpose, 99 for\r\n\r\nBiomedicalSignalProcessingandControl95(2024)1064727\fA. Ozcan et al.\r\n\r\nFig. 4. ROC curve of the models for TN3K test set.\r\n\r\nFig. 6. ROC curve of the models for DDTI test set.\r\n\r\nFig. 5. Recall and accuracy values of the models for TN3K test set.\r\n\r\nFig. 7. Recall and accuracy values of the models for DDTI test set.\r\n\r\nvalidation, 129 for test, and all of them are randomly assigned. As being\r\na very small dataset, with the complex nature of the transformers, our\r\nproposed algorithm comes in second place just a little behind CPFNet.\r\nPerformance of the proposed model on DDTI dataset can be seen at 6\r\nand 7.\r\n\r\n6. Discussion\r\n\r\nThe visual representation of the qualitative comparison findings is\r\nshown in Figs. 8 and 9. The performance of the basic UNet model is no-\r\nticeably inferior, mostly due to its limited prior information concerning\r\nthe thyroid area. On the contrary, it becomes evident that alternative\r\nmodels discussed in the existing literature typically exhibit superior\r\nperformance compared to UNet within this particular situation.\r\n\r\nTo provide a comprehensive evaluation of segmentation perfor-\r\nmance utilizing ground truth photos, we give a tabular representation\r\nbelow. This analysis encompasses established approaches from exist-\r\ning literature as well as our proposed methodology. All evaluations\r\nare conducted using the TN3K dataset. The table has columns that\r\ndepict the original picture and the ground truth image in the first\r\nand second columns, respectively. Subsequently, the table showcases\r\nimages displaying segmentations accomplished by different techniques\r\noutlined in the existing literature, spanning from the third to the tenth\r\ncolumns. The segmentation results achieved by our suggested approach\r\nare displayed in the last column.\r\n\r\nThe majority of recently developed methodologies exhibit superior\r\nperformance in comparison to the UNet.", "mimetype": "text/plain", "start_char_idx": 45839, "end_char_idx": 50090, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f4669fd1-425f-4bfa-89b8-59b195bea2d7": {"__data__": {"id_": "f4669fd1-425f-4bfa-89b8-59b195bea2d7", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b388a9bc-7500-414b-b43b-094f50d1e0af", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "545e4d519c5f93ef461599c150f15ffa01fbe2eb13c036fb19092067abea0025", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4ef2e707-ffbb-432d-873f-7ef7eea7c719", "node_type": "1", "metadata": {}, "hash": "01b607d7383690d46fb4eb3938d6355b1530c2d33734ef199236a4dd2482fdaf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "On the contrary, it becomes evident that alternative\r\nmodels discussed in the existing literature typically exhibit superior\r\nperformance compared to UNet within this particular situation.\r\n\r\nTo provide a comprehensive evaluation of segmentation perfor-\r\nmance utilizing ground truth photos, we give a tabular representation\r\nbelow. This analysis encompasses established approaches from exist-\r\ning literature as well as our proposed methodology. All evaluations\r\nare conducted using the TN3K dataset. The table has columns that\r\ndepict the original picture and the ground truth image in the first\r\nand second columns, respectively. Subsequently, the table showcases\r\nimages displaying segmentations accomplished by different techniques\r\noutlined in the existing literature, spanning from the third to the tenth\r\ncolumns. The segmentation results achieved by our suggested approach\r\nare displayed in the last column.\r\n\r\nThe majority of recently developed methodologies exhibit superior\r\nperformance in comparison to the UNet. Nevertheless, there are still\r\n\r\nerrors observed in their identification of the non-nodule region as the\r\nthyroid nodule, and in certain instances, they have difficulties in accu-\r\nrately segmenting all the nodules. In instances where several nodules\r\nare present, the majority of algorithms exhibit suboptimal predictive\r\nperformance, occasionally failing to detect the second nodule. As a\r\nresult of the combination of Vit-Large/16 transformer and ResNet50\r\nCNN models developed in the proposed method, it can be stated that it\r\nproduces segmentation results close to ground truth reference images.\r\nIn contrast, the proposed modified technique showcases improved\r\nprecision in its outcomes, thereby reducing the occurrence of misclas-\r\nsified areas that are not thyroid nodules.\r\n\r\nIn the present work, we provide a new model that utilizes thyroid\r\nnodule images with separate labels to improve the accuracy of thyroid\r\nnodule segmentation. This approach has ensured significant impor-\r\ntance, especially when considering the inherent difficulties related to\r\nthe annotation of medical images. The improved system effectively\r\nutilizes a significant pool of annotated data, utilizing a common core\r\nstructure and independent decoding components. Automated segmenta-\r\ntion of thyroid nodules plays a crucial role in both streamlining clinical\r\noperations and facilitating thyroid nodule identification. Various fac-\r\ntors, including dimensions, morphology, and the quantity of nodules,\r\nexhibit statistical importance when assessing the grading of thyroid\r\nnodules.\r\n\r\n7. Practical implications and future scope of the work\r\n\r\nNumerous diagnostic imaging techniques which include computed\r\ntomography, magnetic resonance imaging, ultrasound, and radionu-\r\nclide imaging are some of those used to investigate thyroid disorders.\r\n\r\nBiomedicalSignalProcessingandControl95(2024)1064728\fA. Ozcan et al.\r\n\r\nFig. 8. Performance comparison of the models for TN3K test set.\r\n\r\nAmongst these imaging modalities, mainly ultrasound is usually em-\r\nployed in the diagnosis of thyroid diseases, for this imaging technique\r\nis real-time, inexpensive, non-invasive, and non-radioactive. However,\r\nlow image quality and speckle artifacts of ultrasound images distort\r\nthe optical properties of the tissues and result in the ultrasound image\r\nbeing homogeneous and inhomogeneous. In clinical diagnostics, the\r\nclinician has to utilize their experience in image interpretation. Besides,\r\none has a lengthy learning curve in an ultrasound examination and\r\n\r\nsubjective factors are difficult to remove in the diagnostic process. The\r\nultrasound images of the thyroid nodules may variably contain large\r\nand small areas as well as perform poorly due to spots and echoes. This\r\nnoise, however, harms the quality of the image, and the problem of an\r\naccurate determination is very important for young doctors: to find the\r\nfuzzy boundary between the thyroid parenchyma and nodules.\r\n\r\nThe extraction of the thyroid region of ultrasound images with\r\nconventional hand-crafted features in the feature-based method is very\r\n\r\nBiomedicalSignalProcessingandControl95(2024)1064729\fA. Ozcan et al.\r\n\r\nFig. 9. Performance comparison of the models for DDTI test images.\r\n\r\ndifficult because of the low contrast and fuzzy environment. This issue\r\nis mainly addressed by deep learning algorithms which perform better\r\nthan other approaches. However, the current deep learning methods\r\nhave some disadvantages. They are unable to fully satisfy all the\r\nrequirements, and the performance is currently too poor to be fully con-\r\nvincing.", "mimetype": "text/plain", "start_char_idx": 49065, "end_char_idx": 53692, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4ef2e707-ffbb-432d-873f-7ef7eea7c719": {"__data__": {"id_": "4ef2e707-ffbb-432d-873f-7ef7eea7c719", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f4669fd1-425f-4bfa-89b8-59b195bea2d7", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "5b9801d577f7f0006d305ec9444419cb87ff9bf050006172361a376af965c88e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b4ae219e-5363-4915-9710-92ed1e012a35", "node_type": "1", "metadata": {}, "hash": "5ca3ff7f404c6e8baa2cf21807d0684c1e9420b144e8523b8aa0d7928b06ae58", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This\r\nnoise, however, harms the quality of the image, and the problem of an\r\naccurate determination is very important for young doctors: to find the\r\nfuzzy boundary between the thyroid parenchyma and nodules.\r\n\r\nThe extraction of the thyroid region of ultrasound images with\r\nconventional hand-crafted features in the feature-based method is very\r\n\r\nBiomedicalSignalProcessingandControl95(2024)1064729\fA. Ozcan et al.\r\n\r\nFig. 9. Performance comparison of the models for DDTI test images.\r\n\r\ndifficult because of the low contrast and fuzzy environment. This issue\r\nis mainly addressed by deep learning algorithms which perform better\r\nthan other approaches. However, the current deep learning methods\r\nhave some disadvantages. They are unable to fully satisfy all the\r\nrequirements, and the performance is currently too poor to be fully con-\r\nvincing. The architectural flexibility of UNet and its learning techniques\r\nhave an impact on the correct multi-scale clinical analysis classifying\r\nthe thyroid. The initial design still has the encoder\u2013decoder structure\r\ninside which may lead to low-level features being lost further when\r\nexploring the high-level features which consequently causes confusion\r\nbetween thyroid structures and structures relevant. In addition, the\r\nencoder\u2013decoder structure is also responsible for incorrect recognition\r\nof anatomical areas close to the thyroid boundary.\r\n\r\nU-Net\u2019s poor extraction of high-resolution information will lead to\r\nits weak extraction of small targets and edges, which can be mitigated\r\nby the introduced attention block. The detection and segmentation of\r\nedges and small details becomes the key issue for the successful per-\r\nformance of this task. Because of the invasiveness of nodules, acoustic\r\nshadows, and the poor image resolution produced by old ultrasound de-\r\nvices, the risk of damaging some image edges during the segmentation\r\nprocess is relatively high. Furthermore, the small nodules are located in\r\nsome images and low-resolution shallow information extraction layers\r\nhave their segmentation effect confined.\r\n\r\nOur study approaches were chosen to harness the unsurpassed abil-\r\nities of the transformers and UNet segmentation networks. The intro-\r\nduction of automated segmentation can relieve doctors from the heavy\r\nand time-consuming workload of manual segmentation, which can\r\nincrease the accuracy, speed, and thus overall efficiency of detecting\r\nabnormalities.\r\n\r\nOur proposed approach is not limited to thyroid image segmentation\r\nsystems but can be applied to the segmentation and modeling of\r\ndifferent medical images (thorax, thyroid kidney, etc.) that are perfect\r\nfor anatomical or surgical planning.\r\n\r\nOne of the deficiencies in thyroid ultrasound image segmentation\r\nstudies lies in the current research area. Abnormal tissues may appear\r\nin different areas, seemingly different sizes, and associated with dif-\r\nferent textures, therefore deciding their delineation often involves new\r\nquestions. Furthermore, the lack of a well-designed thyroid ultrasound\r\ndataset and adequate evaluation metrics slows down research on the\r\ndiagnosis of thyroid diseases. In the future, there may be a convenient\r\nadjoining of research works to interpolate the shortcomings in current\r\nultrasound image segmentation in the thyroid.\r\n\r\nThe next step would be to delve deeper into this particular issue\r\nand conduct further research to determine the prospect of engineering\r\nother deep learning models capable of doing for medical imaging. As\r\nthe other one, the accuracy of the classification of deep nets requires\r\nperforming different imaging modalities. However, the limited samples\r\n\r\nBiomedicalSignalProcessingandControl95(2024)10647210\fA. Ozcan et al.\r\n\r\nthat are taken from a predetermined dataset is another reason to ques-\r\ntion this study. Hence for next studies; a real-life case can be applied.\r\nTo summarize, this interactive character of interdisciplinary research is\r\nwhat makes it such a powerful tool to determine crucial biomarkers and\r\nuse them with confidence for artificial intelligence-based diagnostics,\r\nallowing doctors to use them in their clinical practice. The following\r\nsentence should be noted as well, as we anticipate future work in hos-\r\npitals to improve our method, which will be based on the real clinical\r\nenvironment, and thus eventually it will become fully automatic and\r\nmore precise.\r\n\r\nMoving forward, we will try to use the current results to conduct an\r\nempirical study seeking different loss functions that could model area\r\nand border information. In addition, we try to train the deep learning\r\nmodels for different diseases, which will serve as tools on mobile and\r\nclinical devices.", "mimetype": "text/plain", "start_char_idx": 52842, "end_char_idx": 57550, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b4ae219e-5363-4915-9710-92ed1e012a35": {"__data__": {"id_": "b4ae219e-5363-4915-9710-92ed1e012a35", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4ef2e707-ffbb-432d-873f-7ef7eea7c719", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "58ecf9a1a72b11f6e6a760705fe15e13c52b8ed874c86e03a932a9807bb6d560", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "11b0240c-3a23-41d3-b80b-2f09143a93d7", "node_type": "1", "metadata": {}, "hash": "b6a2a1fbf41457ebc3672568deaacec1b9e03dab36c617e6340dfb8dd33e1466", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "that are taken from a predetermined dataset is another reason to ques-\r\ntion this study. Hence for next studies; a real-life case can be applied.\r\nTo summarize, this interactive character of interdisciplinary research is\r\nwhat makes it such a powerful tool to determine crucial biomarkers and\r\nuse them with confidence for artificial intelligence-based diagnostics,\r\nallowing doctors to use them in their clinical practice. The following\r\nsentence should be noted as well, as we anticipate future work in hos-\r\npitals to improve our method, which will be based on the real clinical\r\nenvironment, and thus eventually it will become fully automatic and\r\nmore precise.\r\n\r\nMoving forward, we will try to use the current results to conduct an\r\nempirical study seeking different loss functions that could model area\r\nand border information. In addition, we try to train the deep learning\r\nmodels for different diseases, which will serve as tools on mobile and\r\nclinical devices. Our goal is to realize that by using knowledge distil-\r\nlation, our models can be trained without huge complexity, number of\r\nparameters, and memory footprint.\r\n\r\nIn the future, we are ready to study different algorithms to cut the\r\nprocessing time while keeping the accurate segmentation. Moreover,\r\nwe aim to investigate ways to cut back the training period of our\r\nnetworks through the usage of other strategies.\r\n\r\n8. Conclusion\r\n\r\nThe development of accurate and automated segmentation in the\r\nfield of medical imaging is an essential requirement for clinical diag-\r\nnosis and comprehensive analysis. In the present study, we propose\r\na unique framework called Enhanced-Transunet, which enhances skip\r\ncharacteristics through a reconfigured skip connection. The suggested\r\nmethodology incorporates the score matrix and skip connection, result-\r\ning in an increased efficacy of skip features and thus improving the\r\noverall performance of segmentation.\r\n\r\nThe empirical evaluations done on various datasets provide clear\r\nevidence of the improved performance of Enhanced-TransUNet com-\r\npared to existing state-of-the-art models. Significantly, our tests reveal\r\na noticeable difference in performance between the two datasets used.\r\nThis shows that ViT models stand out in terms of model size and\r\nprovide greater scalability, especially when trained on large data sets.\r\nIn our comprehensive assessment, we utilize a variety of indica-\r\ntors as performance metrics to examine the segmentation Intersection\r\nover Union (IoU) of our approach in relation to alternative methods.\r\nThe aforementioned evaluations clearly demonstrate the competitive\r\nperformance of our suggested method.\r\n\r\nCRediT authorship contribution statement\r\n\r\nAlper Ozcan: Software, Supervision, Writing \u2013 original draft. \u00d6m\u00fcr\r\nTosun: Conceptualization, Software, Methodology, Writing \u2013 original\r\ndraft. Emrah Donmez: Validation, Visualization, Writing \u2013 review &\r\nediting. Muhammad Sanwal: Data curation, Formal analysis.\r\n\r\nDeclaration of competing interest\r\n\r\nThe authors declare that they have no known competing finan-\r\ncial interests or personal relationships that could have appeared to\r\ninfluence the work reported in this paper.\r\n\r\nData availability\r\n\r\nData will be made available on request.\r\n\r\nReferences\r\n\r\n[1] J. Long, E. Shelhamer, T. Darrell, Fully convolutional networks for semantic\r\nsegmentation, 2014, CoRR, arXiv:1411.4038, URL http://arxiv.org/abs/1411.\r\n4038.\r\n\r\n[2] O. Ronneberger, P. Fischer, T. Brox, U-net: Convolutional networks for biomed-\r\nical image segmentation, in: N. Navab, J. Hornegger, W.M. Wells, A.F. Frangi\r\n(Eds.), Medical Image Computing and Computer-Assisted Intervention \u2013 MICCAI\r\n2015, Springer International Publishing, 2015, pp. 234\u2013241.\r\n\r\n[3] M.D. Zeiler, D. Krishnan, G.W. Taylor, R. Fergus, Deconvolutional networks,\r\nin: 2010 IEEE Computer Society Conference on Computer Vision and Pat-\r\ntern Recognition, 2010, pp. 2528\u20132535, http://dx.doi.org/10.1109/CVPR.2010.\r\n5539957.\r\n\r\n[4] Z. Zhou, M.M.R.", "mimetype": "text/plain", "start_char_idx": 56578, "end_char_idx": 60573, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "11b0240c-3a23-41d3-b80b-2f09143a93d7": {"__data__": {"id_": "11b0240c-3a23-41d3-b80b-2f09143a93d7", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b4ae219e-5363-4915-9710-92ed1e012a35", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "ce1e7cc32037d8108a69e7615a0fc56947e104e1f742e60d37e5847e498ffc2b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0222e374-7a00-422e-b042-99c7dc877346", "node_type": "1", "metadata": {}, "hash": "d90d40b4cdfd99185cd26a12385f4d81917f56f48dad873b1c7fe7332faa1b4a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4038.\r\n\r\n[2] O. Ronneberger, P. Fischer, T. Brox, U-net: Convolutional networks for biomed-\r\nical image segmentation, in: N. Navab, J. Hornegger, W.M. Wells, A.F. Frangi\r\n(Eds.), Medical Image Computing and Computer-Assisted Intervention \u2013 MICCAI\r\n2015, Springer International Publishing, 2015, pp. 234\u2013241.\r\n\r\n[3] M.D. Zeiler, D. Krishnan, G.W. Taylor, R. Fergus, Deconvolutional networks,\r\nin: 2010 IEEE Computer Society Conference on Computer Vision and Pat-\r\ntern Recognition, 2010, pp. 2528\u20132535, http://dx.doi.org/10.1109/CVPR.2010.\r\n5539957.\r\n\r\n[4] Z. Zhou, M.M.R. Siddiquee, N. Tajbakhsh, J. Liang, Unet++: A nested U-net\r\narchitecture for medical image segmentation, in: Deep Learning in Medical Image\r\nAnalysis and Multimodal Learning for Clinical Decision Support, Springer, 2018,\r\nhttp://dx.doi.org/10.1007/978-3-030-00889-5_1.\r\n\r\n[5] O. Oktay, J. Schlemper, L.L. Folgoc, M.C.H. Lee, M.P. Heinrich, K. Misawa,\r\nK. Mori, S.G. McDonagh, N.Y. Hammerla, B. Kainz, B. Glocker, D. Rueckert,\r\nAttention U-net: Learning where to look for the pancreas, 2018, CoRR, arXiv:\r\n1804.03999, URL http://arxiv.org/abs/1804.03999.\r\n\r\n[6] Y. Chen, K. Wang, X. Liao, Y. Qian, Q. Wang, Z. Yuan, P.-A. Heng, Channel-\r\nunet: A spatial channel-wise convolutional neural network for liver and tumors\r\nsegmentation, Front. Genet. 10 (2019) http://dx.doi.org/10.3389/fgene.2019.\r\n01110, URL https://www.frontiersin.org/articles/10.3389/fgene.2019.01110.\r\n[7] H. Sun, C. Li, B. Liu, S. Wang, AUNet: Breast mass segmentation of whole\r\nmammograms, 2018, CoRR, arXiv:1810.10151, URL http://arxiv.org/abs/1810.\r\n10151.\r\n\r\n[8] G. Litjens, T. Kooi, B.E. Bejnordi, A.A.A. Setio, F. Ciompi, M. Ghafoorian,\r\nJ.A. van der Laak, B. van Ginneken, C.I. S\u00e1nchez, A survey on deep learning\r\nin medical image analysis, Med. Image Anal. 42 (2017) 60\u201388, http://dx.doi.\r\norg/10.1016/j.media.2017.07.005, URL https://www.sciencedirect.com/science/\r\narticle/pii/S1361841517301135.\r\n\r\n[9] N. Tajbakhsh, L. Jeyaseelan, Q. Li, J.N. Chiang, Z. Wu, X. Ding, Embracing\r\nimage\r\n\r\nimperfect datasets: A review of deep learning solutions for medical\r\nsegmentation, Med. Image Anal. 63 (2020) 101693.\r\n\r\n[10] D. Shen, G. Wu, H.-I. Suk, Deep learning in medical image analysis, Annu. Rev.\r\nBiomed. Eng. 19 (2017) 221248, http://dx.doi.org/10.1007/978-3-030-33128-\r\n3_1.\r\n\r\n[11] G. Chartrand, P.M. Cheng, E. Vorontsov, M. Drozdzal, S. Turcotte, C.J.", "mimetype": "text/plain", "start_char_idx": 60002, "end_char_idx": 62403, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0222e374-7a00-422e-b042-99c7dc877346": {"__data__": {"id_": "0222e374-7a00-422e-b042-99c7dc877346", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "11b0240c-3a23-41d3-b80b-2f09143a93d7", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "d3a524ec0a4d24f0274652e243d3ffcab7973f81a93136194e3690b25063522d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8c52318f-0801-491e-9c9e-aa194cc7cb41", "node_type": "1", "metadata": {}, "hash": "7c171df1c5f270c82127fa785334bd0d13a6541ceb1fff02b8cc2681568d2416", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[9] N. Tajbakhsh, L. Jeyaseelan, Q. Li, J.N. Chiang, Z. Wu, X. Ding, Embracing\r\nimage\r\n\r\nimperfect datasets: A review of deep learning solutions for medical\r\nsegmentation, Med. Image Anal. 63 (2020) 101693.\r\n\r\n[10] D. Shen, G. Wu, H.-I. Suk, Deep learning in medical image analysis, Annu. Rev.\r\nBiomed. Eng. 19 (2017) 221248, http://dx.doi.org/10.1007/978-3-030-33128-\r\n3_1.\r\n\r\n[11] G. Chartrand, P.M. Cheng, E. Vorontsov, M. Drozdzal, S. Turcotte, C.J. Pal, S.\r\nKadoury, A. Tang, Deep learning: A primer for radiologists, Radiographics 37\r\n(7) (2017) 21132131, http://dx.doi.org/10.1148/rg.2017170077.\r\n\r\n[12] T. Falk, D. Mai, R. Bensch, \u00d6. \u00c7i\u00e7ek, A. Abdulkadir, Y. Marrakchi, A. B\u00f6hm,\r\nJ. Deubner, Z. J\u00e4ckel, K. Seiwald, A. Dovzhenko, O. Tietz, C.D. Bosco, S.\r\nWalsh, D. Saltukoglu, T.L. Tay, M. Prinz, K. Palme, M. Simons, I. Diester, T.\r\nBrox, O. Ronneberger, U-Net: Deep learning for cell counting, detection, and\r\nmorphometry, Nature Methods 16 (1) (2019) 6770, http://dx.doi.org/10.1038/\r\ns41592-018-0261-2.\r\n\r\n[13] M. Drozdzal, E. Vorontsov, G. Chartrand, S. Kadoury, C. Pal, The importance of\r\nskip connections in biomedical image segmentation, in: Deep Learning and Data\r\nLabeling for Medical Applications, Springer, 2016, http://dx.doi.org/10.1007/\r\n978-3-319-46976-8_19.\r\n\r\n[14] J. Chen, Y. Lu, Q. Yu, X. Luo, E. Adeli, Y. Wang, L. Lu, A.L. Yuille, Y. Zhou,\r\nTransUNet: Transformers make strong encoders for medical image segmentation,\r\n2021, arXiv:2102.04306.\r\n\r\n[15] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner,\r\nM. Dehghani, M. Minderer, G. Heigold, S. Gelly, J. Uszkoreit, N. Houlsby, An\r\nimage is worth 16x16 words: Transformers for image recognition at scale, 2021,\r\narXiv:2010.11929.\r\n\r\n[16] B. Chen, Y. Liu, Z. Zhang, G. Lu, A.W.K. Kong, TransAttUnet: Multi-level\r\nattention-guided U-net with transformer for medical image segmentation, 2022,\r\narXiv:2107.05274.\r\n\r\n[17] X. Yan, H. Tang, S. Sun, H. Ma, D. Kong, X. Xie, AFTer-UNet: Axial fusion\r\ntransformer unet for medical image segmentation, 2021, arXiv:2110.10403.\r\n[18] D. Maji, P. Sigedar, M. Singh, Attention res-unet with guided decoder for\r\nsemantic segmentation of brain tumors, Biomed. Signal Process. Control 71\r\n(2022) 103077, http://dx.doi.org/10.1016/j.bspc.2021.103077, URL https://\r\nwww.sciencedirect.com/science/article/pii/S1746809421006741.", "mimetype": "text/plain", "start_char_idx": 61950, "end_char_idx": 64316, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8c52318f-0801-491e-9c9e-aa194cc7cb41": {"__data__": {"id_": "8c52318f-0801-491e-9c9e-aa194cc7cb41", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0222e374-7a00-422e-b042-99c7dc877346", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "80bfa31a792ebea9b1f10efb9d16f47ff79f0c4025d7710b9ab6ec7de9d55414", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4ae261cd-e675-421b-a243-9dc092fe5600", "node_type": "1", "metadata": {}, "hash": "e84b7ce85d1c2790c0b5c9c5c60ff5944e5faaff1454484c57803998ee68b31d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Kong, TransAttUnet: Multi-level\r\nattention-guided U-net with transformer for medical image segmentation, 2022,\r\narXiv:2107.05274.\r\n\r\n[17] X. Yan, H. Tang, S. Sun, H. Ma, D. Kong, X. Xie, AFTer-UNet: Axial fusion\r\ntransformer unet for medical image segmentation, 2021, arXiv:2110.10403.\r\n[18] D. Maji, P. Sigedar, M. Singh, Attention res-unet with guided decoder for\r\nsemantic segmentation of brain tumors, Biomed. Signal Process. Control 71\r\n(2022) 103077, http://dx.doi.org/10.1016/j.bspc.2021.103077, URL https://\r\nwww.sciencedirect.com/science/article/pii/S1746809421006741.\r\n[19] Z. Wang, C. Zhao, Z. Ni, Adversarial vision transformer for medical\r\n\r\nimage\r\n\r\nsemantic segmentation with limited annotations, 2022, p. 13.\r\n\r\n[20] A. Sagar, ViTBIS: Vision Transformer for Biomedical\r\n\r\nImage Segmentation,\r\nSpringer-Verlag, Berlin, Heidelberg, 2021, pp. 34\u201345, http://dx.doi.org/10.1007/\r\n978-3-030-90874-4_4.\r\n\r\n[21] R. Azad, M.T. AL-Antary, M. Heidari, D. Merhof, TransNorm: Transformer\r\nprovides a strong spatial normalization mechanism for a deep segmentation\r\nmodel, 2022, arXiv:2207.13415.\r\n\r\n[22] Y. Liu, H. Wang, Z. Chen, K. Huangliang, H. Zhang, TransUNet+: Redesign-\r\ning the skip connection to enhance features in medical image segmentation,\r\nKnowl.-Based Syst. 256 (2022) 109859, http://dx.doi.org/10.1016/j.knosys.\r\n2022.109859.\r\n\r\nBiomedicalSignalProcessingandControl95(2024)10647211\fA. Ozcan et al.\r\n\r\n[23] G. Li, D. Jin, Q. Yu, M. Qi, IB-TransUNet: Combining information bottleneck\r\nand transformer for medical image segmentation, J. King Saud Univ. Comput.\r\nInf. Sci. 35 (3) (2023) 249\u2013258, http://dx.doi.org/10.1016/j.jksuci.2023.02.012,\r\nURL https://www.sciencedirect.com/science/article/pii/S1319157823000411.\r\n\r\n[24] V.V. Vadhiraj, A. Simpkin, J. O\u2019Connell, N. Singh Ospina, S. Maraka,\r\nD.T. O\u2019Keeffe, Ultrasound image classification of thyroid nodules using ma-\r\nchine learning techniques, Medicina 57 (6) (2021) http://dx.doi.org/10.3390/\r\nmedicina57060527, URL https://www.mdpi.com/1648-9144/57/6/527.\r\n\r\n[25] D.T. Nguyen, J. Choi, K.R. Park, Thyroid nodule segmentation in ultrasound\r\nimage based on information fusion of suggestion and enhancement networks,\r\nMathematics 10 (19) (2022) http://dx.doi.org/10.3390/math10193484, URL\r\nhttps://www.mdpi.com/2227-7390/10/19/3484.\r\n\r\n[26] Z. Tao, H. Dang, Y. Shi, W. Wang, X. Wang, S. Ren, Local and context-attention\r\nadaptive LCA-net for thyroid nodule segmentation in ultrasound images, Sensors\r\n22 (16) (2022) http://dx.doi.org/10.3390/s22165984, URL https://www.mdpi.\r\ncom/1424-8220/22/16/5984.\r\n\r\n[27] H. Gong, J. Chen, G. Chen, H. Li, G. Li, F. Chen, Thyroid region prior guided\r\nattention for ultrasound segmentation of thyroid nodules, Comput. Biol. Med.", "mimetype": "text/plain", "start_char_idx": 63739, "end_char_idx": 66473, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4ae261cd-e675-421b-a243-9dc092fe5600": {"__data__": {"id_": "4ae261cd-e675-421b-a243-9dc092fe5600", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8c52318f-0801-491e-9c9e-aa194cc7cb41", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "3cce64cf05a487193a72192ddc1648efb8562e641ec9f2d61e3ab810b50240aa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "55708d71-a64a-41b8-b5d6-c6b75a8abc9f", "node_type": "1", "metadata": {}, "hash": "4102079a1e5c1b6ec1c5d6e1200442997df8c41f13f790a373badf4f8d7bbf91", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[26] Z. Tao, H. Dang, Y. Shi, W. Wang, X. Wang, S. Ren, Local and context-attention\r\nadaptive LCA-net for thyroid nodule segmentation in ultrasound images, Sensors\r\n22 (16) (2022) http://dx.doi.org/10.3390/s22165984, URL https://www.mdpi.\r\ncom/1424-8220/22/16/5984.\r\n\r\n[27] H. Gong, J. Chen, G. Chen, H. Li, G. Li, F. Chen, Thyroid region prior guided\r\nattention for ultrasound segmentation of thyroid nodules, Comput. Biol. Med.\r\n155 (2023) 106389, http://dx.doi.org/10.1016/j.compbiomed.2022.106389, URL\r\nhttps://www.sciencedirect.com/science/article/pii/S0010482522010976.\r\n[28] J. Zhang, Q. Qin, Q. Ye, T. Ruan, ST-Unet: Swin transformer boosted\r\nimage segmenta-\r\nU-Net with cross-layer feature enhancement\r\ntion, Comput. Biol. Med. 153 (2023) 106516, http://dx.doi.org/10.1016/j.\r\ncompbiomed.2022.106516, URL https://www.sciencedirect.com/science/article/\r\npii/S0010482522012240.\r\n\r\nfor medical\r\n\r\n[29] S. Guo, S. Sheng, Z. Lai, S. Chen, Trans-u: Transformer enhanced U-net for\r\nmedical image segmentation, in: 2022 3rd International Conference on Computer\r\nVision,\r\nImage and Deep Learning & International Conference on Computer\r\nEngineering and Applications (CVIDL & ICCEA), 2022, pp. 628\u2013631, http://dx.\r\ndoi.org/10.1109/CVIDLICCEA56201.2022.9824530.\r\n\r\n[30] H. Touvron, M. Cord, M. Douze, F. Massa, A. Sablayrolles, H. J\u00e9gou, Training\r\ndata-efficient image transformers & distillation through attention, 2021, arXiv:\r\n2012.12877.\r\n\r\n[31] A. Khanna, N.D. Londhe, S. Gupta, A. Semwal, A deep residual U-net convolu-\r\ntional neural network for automated lung segmentation in computed tomography\r\nimages, Biocybern. Biomed. Eng. 40 (3) (2020) 1314\u20131327, http://dx.doi.org/\r\n10.1016/j.bbe.2020.07.007, URL https://www.sciencedirect.com/science/article/\r\npii/S0208521620300887.\r\n\r\n[32] A. Lin, B. Chen, J. Xu, Z. Zhang, G. Lu, DS-TransUNet:Dual swin transformer\r\n\r\nU-net for medical image segmentation, 2021, arXiv:2106.06716.\r\n\r\n[33] H. Huang, L. Lin, R. Tong, H. Hu, Q. Zhang, Y. Iwamoto, X. Han, Y.-W. Chen,\r\nJ. Wu, UNet 3+: A full-scale connected unet for medical image segmentation,\r\n2020, arXiv:2004.08790.\r\n\r\n[34] H. Pan, Q. Zhou, L.J. Latecki, Sgunet: Semantic guided unet for thyroid nodule\r\nin: 2021 IEEE 18th International Symposium on Biomedical\r\n\r\nsegmentation,\r\nImaging, ISBI, IEEE, 2021, pp. 630\u2013634.\r\n\r\n[35] J. Chi, Z. Li, Z. Sun, X. Yu, H. Wang, Hybrid transformer unet for thyroid\r\n\r\nsegmentation from ultrasound scans, Comput. Biol. Med. 153 (2023) 106453.\r\n\r\n[36] H. Dai, W. Xie, E. Xia, SK-Unet++: An improved Unet++ network with adaptive\r\nreceptive fields for automatic segmentation of ultrasound thyroid nodule images,\r\nMed. Phys. (2023).", "mimetype": "text/plain", "start_char_idx": 66044, "end_char_idx": 68708, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "55708d71-a64a-41b8-b5d6-c6b75a8abc9f": {"__data__": {"id_": "55708d71-a64a-41b8-b5d6-c6b75a8abc9f", "embedding": null, "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "doc_0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "698fee471e0602f60634cee8e523eda034a995585cce719529c605b042b3b524", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4ae261cd-e675-421b-a243-9dc092fe5600", "node_type": "1", "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}, "hash": "f31bbe4c7cba6bdc858205ed5ae288888afb8485a5e6b1cc4f16d1c396b50bd9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[34] H. Pan, Q. Zhou, L.J. Latecki, Sgunet: Semantic guided unet for thyroid nodule\r\nin: 2021 IEEE 18th International Symposium on Biomedical\r\n\r\nsegmentation,\r\nImaging, ISBI, IEEE, 2021, pp. 630\u2013634.\r\n\r\n[35] J. Chi, Z. Li, Z. Sun, X. Yu, H. Wang, Hybrid transformer unet for thyroid\r\n\r\nsegmentation from ultrasound scans, Comput. Biol. Med. 153 (2023) 106453.\r\n\r\n[36] H. Dai, W. Xie, E. Xia, SK-Unet++: An improved Unet++ network with adaptive\r\nreceptive fields for automatic segmentation of ultrasound thyroid nodule images,\r\nMed. Phys. (2023).\r\n\r\n[37] Y. Wu, K. He, Group normalization, 2018, arXiv:1803.08494.\r\n[38] A. Kolesnikov, L. Beyer, X. Zhai, J. Puigcerver, J. Yung, S. Gelly, N. Houlsby, Big\r\ntransfer (BiT): General visual representation learning, 2020, arXiv:1912.11370.\r\n[39] L. Pedraza, C. Vargas, F. Narv\u00e1ez, O. Dur\u00e1n, E. Mu\u00f1oz, E. Romero, An open\r\naccess thyroid ultrasound image database,\r\nin: E. Romero, N. Lepore (Eds.),\r\n10th International Symposium on Medical Information Processing and Analysis,\r\nVol. 9287, International Society for Optics and Photonics, 2015, p. 92870W,\r\nhttp://dx.doi.org/10.1117/12.2073532.\r\n\r\n[40] D.P. Kingma, J. Ba, Adam: A method for stochastic optimization, 2017, arXiv:\r\n\r\n1412.6980.\r\n\r\n[41] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, F.-F. Li, ImageNet: A large-\r\nscale hierarchical image database, in: IEEE Conference on Computer Vision and\r\nPattern Recognition, 2009, pp. 248\u2013255, http://dx.doi.org/10.1109/CVPR.2009.\r\n5206848.\r\n\r\n[42] A. Vakanski, M. Xian, P.E. Freer, Attention-enriched deep learning model for\r\nbreast tumor segmentation in ultrasound images, Ultrasound Med. Biol. 46 (10)\r\n(2020) 2819\u20132833, http://dx.doi.org/10.1016/j.ultrasmedbio.2020.06.015, URL\r\nhttps://www.sciencedirect.com/science/article/pii/S0301562920302878.\r\n[43] K. Simonyan, A. Zisserman, Very deep convolutional networks for large-scale\r\nimage recognition, in: 3rd International Conference on Learning Representations\r\n(ICLR 2015), Computational and Biological Learning Society, 2015, pp. 1\u201314.\r\n\r\n[44] K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition,\r\nin: 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR,\r\n2016, pp. 770\u2013778, http://dx.doi.org/10.1109/CVPR.2016.90.\r\n\r\n[45] M.Z. Alom, M. Hasan, C. Yakopcic, T.M. Taha, V.K. Asari, Recurrent residual\r\nimage\r\nconvolutional neural network based on U-Net (R2U-net) for medical\r\nsegmentation, 2018, CoRR, arXiv:1802.06955, URL http://arxiv.org/abs/1802.\r\n06955.\r\n\r\nBiomedicalSignalProcessingandControl95(2024)10647212", "mimetype": "text/plain", "start_char_idx": 68163, "end_char_idx": 70718, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"2229d434-593e-479c-be51-13e40767a5bf": {"node_ids": ["e657955d-e382-43b6-a770-a2989aba17d6", "f470cb9c-12af-42b9-a00f-ad172f5b1fb2", "9c8b165f-ab9a-4afe-9c8b-865ae6f3b8be", "ad315987-3f1a-4bf1-ba0b-452f06637632", "507c9155-ded2-4f44-8b53-54979f10d12e", "343ef3be-59a7-4954-b099-001167dc48af", "0a3e4c0a-8853-4be7-997b-a94b5af462e8", "cbc6ae2d-29ff-494a-84a4-c8a8f3b1b5f8", "42a43ed8-4330-48df-b1b7-6697b74ec1e1", "46f35381-9992-4633-92fb-eaee689dc4a0", "7e0211b5-0d38-4907-b61c-c2daf80b6d3b", "63ad5fb8-79b0-437f-b378-0d8b9d10d1ea", "2c28ae6a-d489-47a6-b3d7-3a5fc587be1f", "58a3c753-e220-4fb1-8011-3ced243a5231", "2cde69d0-9b5d-4724-809b-a3dde0b87c0f", "37d262ac-2700-4276-941b-4f4a02489f36", "c0aae4eb-1537-402d-a0b6-c82722b038f5", "9f063266-4aaf-4e97-b1ec-7be5f1307f01", "d4e32535-5cc8-4d3d-a87f-aba20f49bfa4", "565ebbeb-d36c-47b9-a23d-1f1ff25ab89f", "cc28e627-2bff-4733-a2b6-ad62bff01b4a", "6a6c8417-944f-4929-b34b-653523fd3386", "7dce949b-f4c3-4e48-83da-4da2558e6ac4", "7afae2f4-a76a-4c8a-a2d4-186db18ce484", "e5411dac-0ace-4c41-a99e-891d51767b53", "9f35c193-e93d-4ed1-b44d-08ff36ddaf5d", "773ae079-133c-45a2-b9c6-9d9799aa8ca8", "329712ee-34d4-40e5-9b3e-8d3ff7d3c4a5", "356ed351-a55d-4634-9808-d78e3d9d6722", "c61c661f-ac4d-4b01-ac47-3b80110b890b", "a2479684-4814-470c-9420-c20402220582", "9d451dcf-3b3d-47ac-9929-82d912828895", "200a6b73-4e93-4166-8e90-a9fe08eed9d5", "32a8ce53-0e3e-4f8a-85eb-90a089c13a76", "53879d22-d433-4dce-9474-137cc79d7e18", "29a3d521-dc7f-488a-a8da-20de05f13d35", "2a0038d3-bf63-4179-8128-4bf07fcfffdf", "cb5bdcd9-9026-436c-b5ed-231f334b54dc"], "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_name": "Market impact of the bitcoin ETF introduction on bitcoin futures.md", "file_size": 106165, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}}, "e2ab657e-8ac1-43f7-945b-9980a8e9ee95": {"node_ids": ["4d57d10d-dec3-4319-b09e-079568c71b15", "9ac97102-5be5-4db4-bf81-15c660cf7a0e", "6ad8952e-6aa3-4e4d-823b-57e157185095", "0a4a161c-c208-43e5-97a8-8f75231f94de", "654e52b6-0538-4305-b719-8f25f1b96a93", "017cf284-efa9-43f8-8efb-3438ca8ab526", "7b7434ef-61f7-4853-83c9-5a42376ad2df", "7f28a954-ea6c-4e44-b783-9c8346113e18", "fccfd992-163e-445e-9391-a027dbd18a04", "4bce771b-8c79-4401-a0e4-5a6a8e334227", "8bff7753-8211-4486-9469-29cc002ff212", "da6eb826-48f7-4546-826b-d5a9e2c85d65", "225ab9dd-740d-4894-84d1-6b9dc362d3ac", "7d19aff2-ace2-467e-800a-686d47ab519b", "d03f4b53-cdfb-420b-b0c3-67a326a87a8b", "ec18cb2e-8f9e-4c3a-9fe1-98a404dca07f", "2b7ca07d-a1ac-4b2f-889a-cce7b1d390b3"], "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Segment anything in medical images.md", "file_name": "Segment anything in medical images.md", "file_size": 53032, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}}, "6c6354d0-ff8f-40c4-aee4-4bbe56da614f": {"node_ids": ["1695f3cd-7f0c-45cf-b40e-fffeb198943d", "9bfb63cb-3192-435e-96d4-ed9c95aba53f", "86b17884-16bb-46d7-92d3-094ec8dcfcc7", "480cb991-6583-422d-8cd9-ba9cb55fe9a8", "9f916a12-0c72-426d-8ddb-487b25506219", "220c3479-912f-465d-a016-8163e001695b", "4b75fde5-91b7-46f0-82e6-6d369703c068", "420add2b-8a70-4fbb-b98d-d06feeb0f9b8", "0e5d4827-a298-4c37-a190-3cd6d53468a6", "353be917-9355-4d06-bed0-5d0955221b6c", "e4eaa9e0-751e-455e-9690-ac6e13af67b4", "168b23cc-f5d4-4b27-b89b-5888022719c4", "1b9baa5e-f17a-4668-9317-d777f61eba07", "879028d7-6a5e-4ff5-8475-277216851565", "c867cd2f-a109-4341-a075-173704be328b", "e18b633f-9838-4a7b-973a-5c2a06fb1121", "7cb5625b-c285-4efc-83c4-59a0bd212154", "e51166be-9e55-4a7c-9d56-7363dbb8805f", "2e81daf5-96cb-474a-9bb0-946e584387ff", "3c5f30ad-86a0-48d1-bd46-a4bd21f0a1eb", "6bd9c571-702b-4b4e-bdcf-b1b6f10369d0", "c0417223-e681-4a65-b403-2970cfd41540", "4081bba7-26db-4870-8b94-14ca780d9f39", "d12f10c0-f1d5-4b34-8688-c66f3d11cbf5", "7e8ac85d-c80b-484c-a206-d779e8e6dc07", "9eb92c92-5e1b-45a1-9f4a-7ec310567818", "fb56e114-803e-4063-a803-a95bbaa198fa", "b7afd206-c9cd-4137-844c-076e2a9a6b0b"], "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_temp\\Young children\u2019s understanding of AI.md", "file_name": "Young children\u2019s understanding of AI.md", "file_size": 81404, "creation_date": "2025-01-14", "last_modified_date": "2025-01-05"}}, "doc_0": {"node_ids": ["482c0c20-8dda-4301-b468-d3924227fe3a", "b06720f1-3105-424a-99b9-e8d0ab76344a", "722b2acf-3ecd-44e5-aa5c-c90727c597d2", "f0127283-2c54-4b9d-8462-35224105c0b4", "adae4129-8643-4794-bbe6-da452a809df6", "15bd2350-b0d8-4938-a1d1-0c8c1f870da6", "678f81fc-05b3-4b72-8520-e7220d9072a7", "27a24b71-8d27-45f6-895b-424ab6677414", "efb6ce26-bd58-4ed5-8b8f-a060af19ed32", "0550f2aa-307a-4030-919f-ee71eca47ea6", "3870e041-1120-4781-a9d7-ee9415b27279", "2fb3cce2-0f85-4f27-8479-d5295ab6d602", "8c054816-9f6f-4d49-99c6-e20eb5d9f0dc", "9259b7cc-24f2-4a5f-a46f-920ab240b145", "2b114964-bbb9-46ec-8661-bd77abd649df", "b388a9bc-7500-414b-b43b-094f50d1e0af", "f4669fd1-425f-4bfa-89b8-59b195bea2d7", "4ef2e707-ffbb-432d-873f-7ef7eea7c719", "b4ae219e-5363-4915-9710-92ed1e012a35", "11b0240c-3a23-41d3-b80b-2f09143a93d7", "0222e374-7a00-422e-b042-99c7dc877346", "8c52318f-0801-491e-9c9e-aa194cc7cb41", "4ae261cd-e675-421b-a243-9dc092fe5600", "55708d71-a64a-41b8-b5d6-c6b75a8abc9f"], "metadata": {"file_path": "C:\\Users\\howar\\OneDrive\\\u684c\u9762\\RAG_Project_withUI_test\\web-app\\src\\MyMD_New\\Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_name": "Enhanced-TransUNet for ultrasound segmentation of thyroid nodules.md", "file_size": 71792, "creation_date": "2025-01-15", "last_modified_date": "2025-01-15"}}}}